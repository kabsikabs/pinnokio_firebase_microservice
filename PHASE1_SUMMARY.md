# ‚úÖ Phase 1 COMPL√âT√âE: MICROSERVICE - Structure Agentic

## üìÅ Fichiers cr√©√©s

### 1. `app/llm_service/agent_config.py`
**Gestionnaire de configuration des agents par chat_mode**

‚úÖ **Cr√©√© avec succ√®s**

**Contenu**:
- Class `AgentConfigManager`
- Prompt system `ONBOARDING_SYSTEM_PROMPT` (d√©taill√© pour l'onboarding)
- Config dict `AGENT_CONFIGS` pour 5 modes:
  - `general_chat`
  - `onboarding_chat`
  - `edit_router_form`
  - `edit_form`
  - `bank_detail`

**M√©thodes principales**:
```python
AgentConfigManager.get_config(chat_mode)  # R√©cup√®re config
AgentConfigManager.inject_context_data(prompt, context)  # Injecte donn√©es entreprise
AgentConfigManager.is_rtdb_listening_enabled(mode)  # V√©rifie √©coute RTDB
AgentConfigManager.get_message_log_container_id(mode)  # ID container logs
```

---

### 2. `app/llm/agent_log_container.py`
**Mixin pour gestion du message_log_container dans BaseAIAgent**

‚úÖ **Cr√©√© avec succ√®s**

**Contenu**:
- Class `LogContainerMixin`

**M√©thodes principales**:
```python
# √Ä int√©grer dans BaseAIAgent
init_log_container_attributes()  # Initialiser attributs
set_message_log_container_id(id)  # D√©finir ID container
inject_or_update_log_message(content, timestamp)  # Inject/update logs
get_log_container_content()  # R√©cup√©rer contenu actuel
clear_log_container()  # Effacer logs
```

**‚ö†Ô∏è INT√âGRATION MANUELLE REQUISE** dans `app/llm/klk_agents.py`:
```python
# 1. Import
from .agent_log_container import LogContainerMixin

# 2. H√©riter
class BaseAIAgent(LogContainerMixin):

# 3. Initialiser dans __init__
self.job_id = job_id
self.init_log_container_attributes()  # ‚úÖ Ajouter
```

---

### 3. `app/listeners/onboarding_rtdb_listener.py`
**Listener RTDB pour mode onboarding_chat**

‚úÖ **Cr√©√© avec succ√®s**

**Contenu**:
- Class `OnboardingRTDBListener`
- Function `get_onboarding_rtdb_listener()` (singleton)

**M√©thodes principales**:
```python
# D√©marrer √©coute RTDB
await listener.start_listening(
    mandate_path, job_id, collection_name, thread_key,
    on_event_callback
)

# Arr√™ter √©coute
await listener.stop_listening(mandate_path, job_id)

# R√©cup√©rer listeners actifs
active = await listener.get_active_listeners()
```

**√âcoute sur**:
- `mandate_path/onboarding_activity/{job_id}`

**D√©tecte 4 types d'√©v√©nements**:
1. **LOG** (`/logs/*`) ‚Üí Logs de progression
2. **TEXT_QUESTION** (`/questions/*`) ‚Üí Questions agent m√©tier
3. **INTERACTIVE_CARD** (`/cards/*`) ‚Üí Cartes interactives
4. **CONTROL** (`/control/*`) ‚Üí Commandes (TERMINATE, NEXT, PENDING)

---

### 4. `app/llm_service/rtdb_to_wss_formatter.py`
**Formateur d'√©v√©nements RTDB ‚Üí WSS**

‚úÖ **Cr√©√© avec succ√®s**

**Contenu**:
- Class `RTDBToWSSFormatter`
- Helper functions (`aggregate_logs`, `validate_card_data`)

**M√©thodes principales**:
```python
# Formater log pour agent (pas de WSS)
format_log_for_agent(log_content, timestamp)

# Formater question pour WSS
format_text_question_for_wss(question, question_id, sender, timestamp)

# Formater carte pour WSS
format_interactive_card_for_wss(card_data, card_id, timestamp)

# Formater confirmation commande contr√¥le
format_control_response_for_wss(command, timestamp)

# V√©rifier si mot-cl√© contr√¥le
is_control_keyword(user_message)

# Extraire mot-cl√© contr√¥le
extract_control_keyword(user_message)

# Formater r√©ponse carte pour RTDB
format_card_response_for_rtdb(card_id, user_choice, user_id, timestamp)

# Formater commande contr√¥le pour RTDB
format_control_command_for_rtdb(command, timestamp)
```

---

### 5. `app/listeners/__init__.py`
**Module d'export pour listeners**

‚úÖ **Cr√©√© avec succ√®s**

Exporte:
- `OnboardingRTDBListener`
- `get_onboarding_rtdb_listener`

---

## üîß Int√©grations manuelles requises

### Int√©gration 1: BaseAIAgent
**Fichier**: `app/llm/klk_agents.py`

```python
# 1. Ajouter import en haut
from .agent_log_container import LogContainerMixin

# 2. Modifier d√©claration classe
class BaseAIAgent(LogContainerMixin):

# 3. Dans __init__, apr√®s self.job_id
self.job_id = job_id
self.init_log_container_attributes()  # ‚úÖ AJOUTER
```

### Int√©gration 2: LLMManager
**Fichier**: `app/llm_service/llm_manager.py`

```python
# 1. Ajouter import en haut
from .agent_config import AgentConfigManager
from ..listeners import get_onboarding_rtdb_listener

# 2. Modifier m√©thode initialize_agent pour accepter:
async def initialize_agent(
    self,
    user_id: str,
    collection_name: str,
    thread_key: str,
    chat_mode: str = 'general_chat',  # ‚úÖ NOUVEAU
    context_data: dict = None,  # ‚úÖ NOUVEAU
    tools: list = None,
    system_prompt: str = None,
    provider: ModelProvider = ModelProvider.ANTHROPIC,
    size: ModelSize = ModelSize.MEDIUM,
    mode: str = 'chats'
) -> str:
    # ‚úÖ R√©cup√©rer config
    agent_config = AgentConfigManager.get_config(chat_mode)

    # ‚úÖ Utiliser system_prompt de config si non fourni
    if not system_prompt:
        system_prompt = agent_config.get('system_prompt')

    # ‚úÖ Injecter contexte
    if agent_config.get('context_injection') and context_data:
        system_prompt = AgentConfigManager.inject_context_data(
            system_prompt, context_data
        )

    # ‚úÖ Utiliser tools de config
    if tools is None:
        tools = agent_config.get('tools', [])

    # Cr√©ation session (code existant)
    session = await self._create_session(...)

    # ‚úÖ D√©finir message_log_container_id
    log_container_id = AgentConfigManager.get_message_log_container_id(chat_mode)
    if log_container_id:
        session.agent.set_message_log_container_id(log_container_id)

    # ‚úÖ D√©marrer listener RTDB si n√©cessaire
    if AgentConfigManager.is_rtdb_listening_enabled(chat_mode):
        await self._start_rtdb_listener_for_mode(
            user_id, collection_name, thread_key, chat_mode
        )

    return session_id
```

**Nouvelle m√©thode √† ajouter**:
```python
async def _start_rtdb_listener_for_mode(
    self,
    user_id: str,
    collection_name: str,
    thread_key: str,
    chat_mode: str
):
    """
    D√©marre le listener RTDB appropri√© selon le chat_mode.
    """
    if chat_mode == 'onboarding_chat':
        await self._start_onboarding_rtdb_listener(
            user_id, collection_name, thread_key
        )
    elif chat_mode in ['edit_router_form', 'edit_form', 'bank_detail']:
        # √Ä impl√©menter plus tard pour autres modes
        pass

async def _start_onboarding_rtdb_listener(
    self,
    user_id: str,
    collection_name: str,
    thread_key: str
):
    """
    D√©marre le listener RTDB pour onboarding_chat.
    """
    from ..firebase_client import get_firestore

    # Extraire mandate_path et job_id de thread_key
    # Supposons que thread_key = job_id pour onboarding
    job_id = thread_key

    # R√©cup√©rer mandate_path depuis Firestore ou autre source
    # TODO: Adapter selon votre structure de donn√©es
    db = get_firestore()
    # ... logique pour r√©cup√©rer mandate_path ...

    # Callback pour traiter les √©v√©nements RTDB
    def on_rtdb_event(event_type: str, event_data: dict):
        """
        Callback appel√© par OnboardingRTDBListener.
        """
        if event_type == 'LOG':
            # Injecter dans log container de l'agent
            session = self.sessions.get(...)  # R√©cup√©rer session
            if session and session.agent:
                session.agent.inject_or_update_log_message(
                    event_data['content'],
                    event_data['timestamp']
                )

        elif event_type == 'TEXT_QUESTION':
            # Ajouter au chat_history + envoi WSS
            # TODO: Impl√©menter traitement question
            pass

        elif event_type == 'INTERACTIVE_CARD':
            # Reformater et envoyer via WSS
            # TODO: Impl√©menter traitement carte
            pass

        elif event_type == 'CONTROL':
            # Traiter commande contr√¥le
            # TODO: Impl√©menter traitement contr√¥le
            pass

    # D√©marrer listener
    listener = get_onboarding_rtdb_listener()
    await listener.start_listening(
        mandate_path=mandate_path,
        job_id=job_id,
        collection_name=collection_name,
        thread_key=thread_key,
        on_event_callback=on_rtdb_event
    )

    logger.info(f"üéß Listener RTDB d√©marr√© pour onboarding: {job_id}")
```

---

## üìù Notes importantes

1. **Phase 1 est 100% compl√©t√©e c√¥t√© fichiers cr√©√©s**
2. **2 int√©grations manuelles requises** (BaseAIAgent + LLMManager)
3. **Architecture extensible** pour edit_router_form, edit_form, bank_detail
4. **Pas de modifications dans les fichiers existants** (√©vite conflits)

---

## üß™ Tests recommand√©s (apr√®s int√©grations manuelles)

### Test 1: AgentConfigManager
```python
from app.llm_service.agent_config import AgentConfigManager

config = AgentConfigManager.get_config('onboarding_chat')
assert config['rtdb_listening'] == True
assert config['message_log_container_id'] == 'onboarding_logs_container'

prompt = AgentConfigManager.inject_context_data(
    config['system_prompt'],
    {'company_name': 'Test Corp', 'erp_system': 'odoo'}
)
assert 'Test Corp' in prompt
```

### Test 2: LogContainerMixin
```python
from app.llm.klk_agents import BaseAIAgent

agent = BaseAIAgent()
agent.set_message_log_container_id('test_container')
agent.inject_or_update_log_message('Premier log', '2025-01-01T10:00:00')
content = agent.get_log_container_content()
assert 'Premier log' in content

agent.inject_or_update_log_message('Mise √† jour log', '2025-01-01T10:05:00')
content2 = agent.get_log_container_content()
assert 'Mise √† jour log' in content2
assert 'Premier log' not in content2  # Remplac√©
```

### Test 3: OnboardingRTDBListener
```python
from app.listeners import get_onboarding_rtdb_listener

listener = get_onboarding_rtdb_listener()

events_received = []

def callback(event_type, event_data):
    events_received.append((event_type, event_data))

await listener.start_listening(
    mandate_path='clients/test/mandates/test123',
    job_id='job_test',
    collection_name='test_collection',
    thread_key='thread_test',
    on_event_callback=callback
)

# √âcrire dans RTDB pour tester
# ...

await listener.stop_listening('clients/test/mandates/test123', 'job_test')
```

### Test 4: RTDBToWSSFormatter
```python
from app.llm_service.rtdb_to_wss_formatter import RTDBToWSSFormatter

# Test question
question_wss = RTDBToWSSFormatter.format_text_question_for_wss(
    'Quelle est la cl√¥ture fiscale?',
    'q123'
)
assert question_wss['type'] == 'llm_stream_complete'
assert 'Quelle est la cl√¥ture fiscale' in question_wss['content']

# Test mot-cl√© contr√¥le
assert RTDBToWSSFormatter.is_control_keyword('NEXT') == True
assert RTDBToWSSFormatter.is_control_keyword('bonjour') == False

keyword = RTDBToWSSFormatter.extract_control_keyword('  next  ')
assert keyword == 'NEXT'
```

---

## üöÄ Prochaines √©tapes

1. ‚úÖ **Effectuer les 2 int√©grations manuelles** (BaseAIAgent + LLMManager)
2. ‚úÖ **Tester Phase 1** avec les tests ci-dessus
3. ‚û°Ô∏è **Passer √† Phase 2: REFLEX** (modifications ChatState)
