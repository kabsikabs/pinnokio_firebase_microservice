"""
Gestionnaire LLM centralis√© utilisant Firebase Realtime Database.
G√®re les sessions LLM et l'int√©gration avec BaseAIAgent.
"""

import asyncio
import json
import uuid
import time
import logging
import threading
import copy
from typing import Dict, Optional, Any, Tuple, List, Awaitable, Callable, Set
from datetime import datetime, timezone, timedelta
from ..llm.klk_agents import BaseAIAgent, ModelProvider, ModelSize
from .llm_context import LLMContext
from .rtdb_message_formatter import RTDBMessageFormatter

logger = logging.getLogger("llm_service.manager")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# BUILDER DE CARTES INTERACTIVES POUR REFLEX
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ApprovalCardBuilder:
    """
    Constructeur de cartes interactives compatibles Reflex.

    Format standardis√© avec Google Chat Card API.
    Extensible pour nouveaux types de cartes.

    ‚úÖ MODIFICATIONS R√âCENTES :
    - Ajout du champ 'execution_mode' explicite dans cardsV2, message.cardParams et racine
    - Valeurs possibles : 'ON_DEMAND', 'SCHEDULED', 'ONE_TIME', 'NOW'
    - Maintien de la compatibilit√© ascendante (champs existants pr√©serv√©s)
    """
    
    @staticmethod
    def build_approval_card(
        card_id: str,
        title: str,
        subtitle: str = "",
        text: str = "",
        input_label: str = "Votre commentaire (optionnel)",
        button_text: str = "Approuver",
        button_action: str = "approve_four_eyes",
        additional_params: Dict[str, Any] = None,
        execution_mode: str = None
    ) -> Dict[str, Any]:
        """
        Construit une carte d'approbation standard.

        Args:
            card_id: Identifiant unique de la carte (ex: 'approval_card')
            title: Titre principal
            subtitle: Sous-titre (optionnel)
            text: Description d√©taill√©e
            input_label: Label du champ de saisie
            button_text: Texte du bouton principal
            button_action: Action du bouton (ex: 'approve_four_eyes')
            additional_params: Param√®tres additionnels pour extension
            execution_mode: Mode d'ex√©cution explicite ('ON_DEMAND', 'SCHEDULED', 'ONE_TIME', 'NOW')

        Returns:
            Dict compatible Reflex (cardsV2 + message.cardParams)
        """
        base_params = {
            "cardId": card_id,
            "title": title,
            "subtitle": subtitle,
            "text": text,
            "input_label": input_label,
            "button_text": button_text,
            "button_action": button_action
        }

        # ‚úÖ Ajouter le mode d'ex√©cution explicite si fourni
        if execution_mode:
            base_params["execution_mode"] = execution_mode

        if additional_params:
            base_params.update(additional_params)
        
        # ‚úÖ Construire le contenu de la carte
        card_content = {
            "cardsV2": [{
                "cardId": card_id,
                "card": {
                    "header": {
                        "title": title,
                        "subtitle": subtitle
                    },
                    "sections": [{
                        "widgets": [{
                            "textParagraph": {
                                "text": text
                            }
                        }]
                    }]
                }
            }],
            "message": {
                "cardType": card_id,
                "cardParams": base_params
            }
        }

        # ‚úÖ Ajouter execution_mode dans cardsV2 aussi pour coh√©rence
        if execution_mode:
            card_content["cardsV2"][0]["execution_mode"] = execution_mode
            card_content["execution_mode"] = execution_mode

        return card_content
    
    @staticmethod
    def build_text_modification_card(
        context_type: str,
        original_text: str,
        operations_log: List[Dict],
        final_text: str,
        warnings: List[str] = None
    ) -> Dict[str, Any]:
        """
        Carte d'approbation pour modifications de contexte texte.
        
        Affiche :
        - Type de contexte modifi√©
        - R√©sum√© des op√©rations (add/replace/delete)
        - Comparaison avant/apr√®s (preview)
        - Warnings √©ventuels
        
        Args:
            context_type: Type de contexte ("router", "accounting", "company")
            original_text: Texte original avant modification
            operations_log: Liste des op√©rations effectu√©es
            final_text: Texte final apr√®s modifications
            warnings: Liste d'avertissements (optionnel)
        
        Returns:
            Format carte compatible Reflex
        """
        
        # G√©n√©rer r√©sum√© des op√©rations
        operations_summary = []
        for i, op in enumerate(operations_log):
            op_args = op.get("args_from_llm", {})
            op_type = op_args.get("operation", "unknown")
            section = op_args.get("section_type", "unknown")
            
            if op_type == "add":
                icon = "‚ûï"
            elif op_type == "replace":
                icon = "üîÑ"
            elif op_type == "delete":
                icon = "‚ùå"
            else:
                icon = "‚Ä¢"
            
            operations_summary.append({
                "index": i + 1,
                "icon": icon,
                "operation": op_type.upper(),
                "section": section.upper(),
                "success": op.get("success", False)
            })
        
        # Calculer diff (simplifi√©e)
        diff_preview = {
            "added_chars": len(final_text) - len(original_text),
            "total_operations": len(operations_log),
            "successful_operations": sum(1 for op in operations_log if op.get("success"))
        }
        
        # Construire sections de la carte
        sections = [
            {
                "header": "üìã R√©sum√© des modifications",
                "widgets": [
                    {
                        "decoratedText": {
                            "topLabel": "Type de contexte",
                            "text": context_type.upper()
                        }
                    },
                    {
                        "decoratedText": {
                            "topLabel": "Changement de taille",
                            "text": f"{diff_preview['added_chars']:+d} caract√®res"
                        }
                    },
                    {
                        "decoratedText": {
                            "topLabel": "Op√©rations",
                            "text": f"{diff_preview['successful_operations']}/{diff_preview['total_operations']} r√©ussies"
                        }
                    }
                ]
            },
            {
                "header": "üîß Op√©rations propos√©es",
                "collapsible": True,
                "widgets": [{
                    "textParagraph": {
                        "text": "\n".join([
                            f"{op['icon']} **Op {op['index']}**: {op['operation']} ({op['section']}) {'‚úÖ' if op['success'] else '‚ùå'}"
                            for op in operations_summary
                        ])
                    }
                }]
            },
            {
                "header": "üëÅÔ∏è Aper√ßu",
                "collapsible": True,
                "widgets": [
                    {
                        "textParagraph": {
                            "text": f"**Avant** ({len(original_text)} caract√®res):\n```\n{original_text[:300]}{'...' if len(original_text) > 300 else ''}\n```"
                        }
                    },
                    {
                        "textParagraph": {
                            "text": f"**Apr√®s** ({len(final_text)} caract√®res):\n```\n{final_text[:300]}{'...' if len(final_text) > 300 else ''}\n```"
                        }
                    }
                ]
            }
        ]
        
        # Ajouter section warnings si pr√©sents
        if warnings:
            sections.append({
                "header": "‚ö†Ô∏è Avertissements",
                "widgets": [{
                    "textParagraph": {
                        "text": "\n".join([f"‚Ä¢ {w}" for w in warnings])
                    }
                }]
            })
        
        # Construire carte compl√®te
        return {
            "cardsV2": [{
                "cardId": "text_modification_approval",
                "card": {
                    "header": {
                        "title": f"üìù Modification contexte {context_type.upper()}",
                        "subtitle": f"{diff_preview['successful_operations']}/{diff_preview['total_operations']} op√©rations r√©ussies"
                    },
                    "sections": sections
                }
            }],
            "message": {
                "cardType": "text_modification_approval",
                "cardParams": {
                    "cardId": "text_modification_approval",
                    "context_type": context_type,
                    "original_text": original_text,
                    "final_text": final_text,
                    "operations_summary": operations_summary,
                    "diff_preview": diff_preview,
                    "warnings": warnings or [],
                    "input_label": "Commentaire sur la modification (optionnel)",
                    "button_text": "Approuver la modification"
                }
            }
        }


class StreamingController:
    """Contr√¥leur pour g√©rer les arr√™ts de streaming via WebSocket."""
    
    def __init__(self):
        self.active_streams: Dict[str, Dict[str, Any]] = {}  # {session_key: {thread_key: task_info}}
        self._lock = threading.Lock()
    
    async def register_stream(self, session_key: str, thread_key: str, task: asyncio.Task):
        """Enregistre un stream actif."""
        with self._lock:
            if session_key not in self.active_streams:
                self.active_streams[session_key] = {}
            
            self.active_streams[session_key][thread_key] = {
                "task": task,
                "started_at": datetime.now(timezone.utc),
                "status": "streaming"
            }
            logger.info(f"Stream enregistr√©: {session_key}:{thread_key}")
    
    async def stop_stream(self, session_key: str, thread_key: str) -> bool:
        """Arr√™te un stream sp√©cifique."""
        with self._lock:
            if session_key not in self.active_streams:
                return False
            
            if thread_key not in self.active_streams[session_key]:
                return False
            
            stream_info = self.active_streams[session_key][thread_key]
            
            # Arr√™ter la t√¢che
            if not stream_info["task"].done():
                stream_info["task"].cancel()
                logger.info(f"Stream arr√™t√©: {session_key}:{thread_key}")
            
            # Marquer comme interrompu
            stream_info["status"] = "interrupted"
            stream_info["interrupted_at"] = datetime.now(timezone.utc)
            
            return True
    
    async def stop_all_streams(self, session_key: str) -> int:
        """Arr√™te tous les streams d'une session."""
        with self._lock:
            if session_key not in self.active_streams:
                return 0
            
            stopped_count = 0
            for thread_key, stream_info in self.active_streams[session_key].items():
                if not stream_info["task"].done():
                    stream_info["task"].cancel()
                    stream_info["status"] = "interrupted"
                    stream_info["interrupted_at"] = datetime.now(timezone.utc)
                    stopped_count += 1
            
            logger.info(f"Tous les streams arr√™t√©s pour {session_key}: {stopped_count}")
            return stopped_count
    
    async def unregister_stream(self, session_key: str, thread_key: str):
        """D√©senregistre un stream termin√©."""
        with self._lock:
            if session_key in self.active_streams and thread_key in self.active_streams[session_key]:
                del self.active_streams[session_key][thread_key]
                if not self.active_streams[session_key]:
                    del self.active_streams[session_key]
                logger.info(f"Stream d√©senregistr√©: {session_key}:{thread_key}")
    
    async def get_active_streams(self, session_key: str) -> Dict[str, Any]:
        """Retourne les streams actifs d'une session."""
        with self._lock:
            return self.active_streams.get(session_key, {}).copy()


class LLMSession:
    """Session LLM isol√©e pour un utilisateur/soci√©t√©.
    
    G√®re l'agent BaseAIAgent et l'historique des conversations pour tous les threads
    de cet utilisateur dans cette soci√©t√©.
    """
    
    def __init__(self, session_key: str, context: LLMContext):
        self.session_key = session_key  # user_id:collection_name
        self.context = context
        
        # Lock pour cette session sp√©cifique (pas de conflit entre utilisateurs)
        self._lock = threading.Lock()
        
        # ‚≠ê NOUVELLE ARCHITECTURE: Donn√©es permanentes (charg√©es une fois)
        self.user_context: Optional[Dict] = None  # M√©tadonn√©es company (mandate_path, client_uuid, etc.)
        self.jobs_data: Optional[Dict] = None     # Jobs APBookkeeper, Router, Bank
        self.jobs_metrics: Optional[Dict] = None  # M√©triques pour system prompt
        
        # ‚≠ê BRAINS ACTIFS: 1 brain par thread/chat (isolation compl√®te)
        self.active_brains: Dict[str, Any] = {}  # {thread_key: PinnokioBrain}
        self._brain_locks: Dict[str, asyncio.Lock] = {}  # {thread_key: Lock}
        
        # T√¢ches actives par thread (pour tracking)
        self.active_tasks: Dict[str, list] = {}
        
        # √âtat par thread
        self.thread_states: Dict[str, str] = {}
        
        # ‚≠ê Cache contexte LPT par thread (pour √©viter requ√™tes Firebase redondantes)
        self.thread_contexts: Dict[str, Tuple[Dict[str, Any], float]] = {}  # {thread_key: (context, timestamp)}
        self.context_cache_ttl = 300  # 5 minutes
        
        # ‚≠ê TRACKING PR√âSENCE UTILISATEUR (pour Mode UI vs BACKEND)
        self.is_on_chat_page: bool = False  # Est-il actuellement sur la PAGE de chat?
        self.current_active_thread: Optional[str] = None  # Sur QUEL thread pr√©cis?
        
        # M√©triques
        self.created_at = datetime.now(timezone.utc)
        self.last_activity: Dict[str, datetime] = {}
        self.response_times: Dict[str, list] = {}

        # ‚≠ê LISTENERS ONBOARDING (RTDB follow-up)
        self.onboarding_listeners: Dict[str, Dict[str, Any]] = {}
        self.onboarding_processed_ids: Dict[str, Set[str]] = {}
        
        # ‚≠ê MODE INTERM√âDIATION (FOLLOW_MESSAGE)
        # G√®re la communication directe m√©tier-utilisateur sans agent LLM
        self.intermediation_mode: Dict[str, bool] = {}  # {thread_key: True/False}

        # ‚≠ê Boucle asyncio d√©di√©e pour les callbacks RTDB (isolation session)
        self._callback_loop: Optional[asyncio.AbstractEventLoop] = None
        self._callback_thread: Optional[threading.Thread] = None
        self._callback_loop_lock = threading.Lock()
        
        logger.info(f"[SESSION_INIT] üì¶ LLMSession cr√©√©e: {session_key}")
    
    def ensure_callback_loop(self) -> asyncio.AbstractEventLoop:
        """Garantit qu'une boucle asyncio d√©di√©e √† la session est disponible."""

        with self._callback_loop_lock:
            if (
                self._callback_loop
                and self._callback_thread
                and self._callback_thread.is_alive()
                and not self._callback_loop.is_closed()
            ):
                return self._callback_loop

            loop = asyncio.new_event_loop()

            def _run_loop() -> None:
                asyncio.set_event_loop(loop)
                loop.run_forever()

            thread = threading.Thread(
                target=_run_loop,
                name=f"LLMSessionLoop-{self.session_key}",
                daemon=True
            )
            thread.start()

            self._callback_loop = loop
            self._callback_thread = thread

            logger.info(
                f"[SESSION_LOOP] üîÑ Boucle callbacks initialis√©e pour session={self.session_key}"
            )

            return loop

    def schedule_coroutine(
        self,
        coro: Awaitable[Any],
        timeout: Optional[float] = 1.0
    ):
        """Planifie l'ex√©cution d'une coroutine sur la boucle d√©di√©e."""

        loop = self.ensure_callback_loop()
        future = asyncio.run_coroutine_threadsafe(coro, loop)

        if timeout is not None:
            future.result(timeout=timeout)

        return future

    def stop_callback_loop(self) -> None:
        """Arr√™te proprement la boucle d√©di√©e (utilis√©e lors du nettoyage de session)."""

        loop: Optional[asyncio.AbstractEventLoop]
        thread: Optional[threading.Thread]

        with self._callback_loop_lock:
            loop = self._callback_loop
            thread = self._callback_thread
            self._callback_loop = None
            self._callback_thread = None

        if not loop:
            return

        try:
            if loop.is_running():
                loop.call_soon_threadsafe(loop.stop)

            if thread and thread.is_alive():
                thread.join(timeout=1.0)

            loop.close()

            logger.info(
                f"[SESSION_LOOP] üì¥ Boucle callbacks arr√™t√©e pour session={self.session_key}"
            )
        except Exception:
            logger.exception(
                f"[SESSION_LOOP] ‚ùå Erreur lors de l'arr√™t de la boucle callbacks session={self.session_key}"
            )

    async def initialize_session_data(self, client_uuid: str):
        """
        Charge les donn√©es permanentes de la session (une seule fois).
        NE cr√©e PAS de brain ici - les brains sont cr√©√©s par chat dans load_chat_history().
        
        ‚≠ê NOUVELLE ARCHITECTURE :
        - Donn√©es permanentes charg√©es UNE fois (user_context, jobs_data, jobs_metrics)
        - Brains cr√©√©s dynamiquement par thread/chat (1 brain = 1 chat)
        - Isolation compl√®te entre chats
        
        Donn√©es charg√©es :
        1. user_context : M√©tadonn√©es company (mandate_path, client_uuid, dms_system, etc.)
        2. jobs_data : Jobs complets (factures, documents, transactions)
        3. jobs_metrics : Compteurs pour system prompt
        """
        try:
            logger.info(f"[SESSION_DATA] üîÑ Chargement donn√©es permanentes pour session {self.session_key}")
            
            # ‚ïê‚ïê‚ïê √âTAPE 1 : D√©tecter mode connexion ‚ïê‚ïê‚ïê
            mode = await self._detect_connection_mode()
            logger.info(f"[SESSION_DATA] üîç Mode d√©tect√©: {mode}")
            
            # ‚ïê‚ïê‚ïê √âTAPE 2 : Charger contexte utilisateur ‚ïê‚ïê‚ïê
            from ..firebase_providers import FirebaseManagement
            
            firebase_service = FirebaseManagement()
            
            # ‚ö†Ô∏è V√©rifier que client_uuid n'est pas vide
            if not client_uuid or client_uuid.strip() == '':
                raise ValueError(
                    f"client_uuid vide ou invalide pour user_id={self.context.user_id}, collection_name={self.context.collection_name}"
                )
            
            # Utiliser le client_uuid pass√© en param√®tre
            logger.info(f"[SESSION_DATA] ‚úÖ client_uuid fourni: {client_uuid}")
            
            # R√©cup√©rer le profil complet depuis Firebase
            full_profile = await asyncio.to_thread(
                firebase_service.reconstruct_full_client_profile,
                self.context.user_id,
                client_uuid,
                self.context.collection_name
            )
            
            if not full_profile:
                raise ValueError(f"Profil client vide pour user={self.context.user_id}")

            workflow_params_raw = full_profile.get("workflow_params") or {}
            workflow_params = copy.deepcopy(workflow_params_raw)
            
            # Extraire les IDs pour construire mandate_path complet
            client_id = full_profile.get('_client_id')
            mandate_id = full_profile.get('_mandate_id')
            
            if not client_id or not mandate_id:
                raise ValueError(f"client_id ou mandate_id manquant dans full_profile")
            
            # ‚≠ê Construire le mandate_path complet (chemin Firebase r√©el)
            mandate_path = f'clients/{self.context.user_id}/bo_clients/{client_id}/mandates/{mandate_id}'

            # Charger la table des fonctions (function_table) pour les r√®gles Router
            function_table_source_path = f"{mandate_path}/setup/function_table"
            function_table_info: Dict[str, Any] = {
                "raw": None,
                "ask_approval": {},
                "available": False,
                "source_path": function_table_source_path,
                "status_message": (
                    "R√®gles d'approbation par d√©partement non configur√©es. "
                    "Configurez-les dans le panneau de configuration de la soci√©t√©."
                ),
            }

            try:
                def _load_function_table() -> Tuple[Optional[Dict[str, Any]], Dict[str, bool]]:
                    doc_ref = firebase_service.firestore_client.document(function_table_source_path)
                    doc = doc_ref.get()
                    if not doc.exists:
                        return None, {}
                    data = doc.to_dict() or {}
                    approvals: Dict[str, bool] = {}
                    for service_name, payload in data.items():
                        if isinstance(payload, dict):
                            approvals[service_name] = bool(payload.get("ask_approval", False))
                    return data, approvals

                raw_data, approvals = await asyncio.to_thread(_load_function_table)
                if raw_data:
                    function_table_info["raw"] = raw_data
                    function_table_info["ask_approval"] = approvals
                    function_table_info["available"] = True
                    function_table_info["status_message"] = (
                        "R√®gles d'approbation par d√©partement charg√©es depuis Firebase."
                    )
            except Exception as function_table_error:
                logger.warning(
                    "[SESSION_DATA] ‚ö†Ô∏è Impossible de charger function_table pour %s : %s",
                    mandate_path,
                    function_table_error,
                )

            workflow_params["function_table"] = function_table_info
            
            # ‚≠ê Construire user_context avec les BONS noms de champs
            self.user_context = {
                # Identifiants
                "client_uuid": client_uuid,
                "client_id": client_id,
                "mandate_id": mandate_id,
                "mandate_path": mandate_path,  # Chemin complet Firebase
                
                # Noms (avec pr√©fixes corrects depuis reconstruct_full_client_profile)
                "company_name": full_profile.get("mandate_legal_name") or full_profile.get("mandate_contact_space_name") or self.context.collection_name,
                "contact_space_id": full_profile.get("mandate_contact_space_id"),
                "contact_space_name": full_profile.get("mandate_contact_space_name"),
                "legal_name": full_profile.get("mandate_legal_name"),
                "country":full_profile.get("mandate_country",),
                "timezone":full_profile.get("mandate_timezone","no timezone found"),
                "user_language": full_profile.get("mandate_user_language", "fr"),
                
                # DMS (Document Management System)
                "dms_system": full_profile.get("erp_dms_system", "google_drive"),
                "drive_space_parent_id": full_profile.get("mandate_drive_space_parent_id"),
                "input_drive_doc_id": full_profile.get("mandate_input_drive_doc_id"),
                "output_drive_doc_id": full_profile.get("mandate_output_drive_doc_id"),
                
                # ERP - Types
                "mandate_bank_erp": full_profile.get("mandate_bank_erp"),
                "mandate_ap_erp": full_profile.get("mandate_ap_erp"),
                "mandate_ar_erp": full_profile.get("mandate_ar_erp"),
                "mandate_gl_accounting_erp": full_profile.get("mandate_gl_accounting_erp"),
                
                # ERP - Connexion Odoo
                "erp_odoo_url": full_profile.get("erp_odoo_url"),
                "erp_odoo_username": full_profile.get("erp_odoo_username"),
                "erp_odoo_db": full_profile.get("erp_odoo_db"),
                "erp_odoo_company_name": full_profile.get("erp_odoo_company_name"),
                "erp_erp_type": full_profile.get("erp_erp_type"),
                "erp_secret_manager": full_profile.get("erp_secret_manager"),
                
                # Communication
                "communication_mode": full_profile.get("mandate_communication_chat_type", "pinnokio"),
                "log_communication_mode": full_profile.get("mandate_communication_log_type", "pinnokio"),
                
                # Devise
                "base_currency": full_profile.get("mandate_base_currency"),
                
                # ‚≠ê WORKFLOW PARAMS (param√®tres d'approbation)
                "workflow_params": workflow_params
            }
            
            # üîç DEBUG : V√©rifier que workflow_params est bien inclus
            workflow_params = self.user_context.get("workflow_params", {})
            logger.info(
                f"[SESSION_DATA] üîç DEBUG workflow_params inclus dans session.user_context: "
                f"{workflow_params is not None and workflow_params != {}}"
            )
            if workflow_params:
                logger.info(
                    f"[SESSION_DATA] üîç DEBUG workflow_params cl√©s: {list(workflow_params.keys())}"
                )
                if "Apbookeeper_param" in workflow_params:
                    logger.info(
                        f"[SESSION_DATA] üîç DEBUG Apbookeeper_param: "
                        f"approval_required={workflow_params['Apbookeeper_param'].get('apbookeeper_approval_required')}, "
                        f"approval_contact_creation={workflow_params['Apbookeeper_param'].get('apbookeeper_approval_contact_creation')}"
                    )
                ft_info = workflow_params.get("function_table", {})
                logger.info(
                    "[SESSION_DATA] üîç DEBUG function_table disponible=%s, services=%s",
                    ft_info.get("available", False),
                    list((ft_info.get("ask_approval") or {}).keys()),
                )
            
            logger.info(
                f"[SESSION_DATA] ‚úÖ Contexte utilisateur charg√© - "
                f"company={self.user_context.get('company_name')}, "
                f"mandate_path={self.user_context.get('mandate_path')}"
            )
            
            # ‚ïê‚ïê‚ïê √âTAPE 3 : Charger jobs et m√©triques ‚ïê‚ïê‚ïê
            self.jobs_data, self.jobs_metrics = await self._load_jobs_with_metrics(mode)
            
            logger.info(
                f"[SESSION_DATA] ‚úÖ Jobs charg√©s - "
                f"APBookkeeper: {self.jobs_metrics.get('APBOOKEEPER', {}).get('to_do', 0)} to_do, "
                f"Router: {self.jobs_metrics.get('ROUTER', {}).get('to_process', 0)} to_process, "
                f"Bank: {self.jobs_metrics.get('BANK', {}).get('to_reconcile', 0)} to_reconcile"
            )
            
            logger.info(f"[SESSION_DATA] üéâ Donn√©es session initialis√©es (SANS brain - cr√©√©s par chat)")
            
        except Exception as e:
            logger.error(f"[SESSION_DATA] ‚ùå Erreur chargement donn√©es: {e}", exc_info=True)
            raise
    
    async def _detect_connection_mode(self) -> str:
        """
        D√©tecte si l'utilisateur est en mode UI (connect√©) ou BACKEND (d√©connect√©).
        
        Logique :
        - V√©rifier le heartbeat dans UnifiedRegistry
        - Si heartbeat r√©cent (< 30s) ‚Üí Mode UI
        - Sinon ‚Üí Mode BACKEND
        
        Returns:
            "UI" ou "BACKEND"
        """
        try:
            from ..registry.unified_registry import UnifiedRegistryService
            
            registry = UnifiedRegistryService()
            
            # V√©rifier si l'utilisateur a un heartbeat r√©cent
            is_connected = registry.is_user_connected(
                self.context.user_id
            )
            
            return "UI" if is_connected else "BACKEND"
            
        except Exception as e:
            logger.warning(f"[SESSION] Erreur d√©tection mode connexion: {e}")
            # Par d√©faut, mode BACKEND (plus s√ªr)
            return "BACKEND"
    
    async def _load_jobs_with_metrics(self, mode: str) -> Tuple[Dict, Dict]:
        """
        Charge les jobs depuis Firebase/Drive/ERP et calcule les m√©triques.
        
        Args:
            mode: "UI" (avec cache Redis) ou "BACKEND" (direct)
        
        Returns:
            Tuple[Dict, Dict]: (jobs_data, jobs_metrics)
        """
        try:
            from ..pinnokio_agentic_workflow.tools.job_loader import JobLoader
            
            loader = JobLoader(
                user_id=self.context.user_id,
                company_id=self.context.collection_name,
                client_uuid=self.user_context.get("client_uuid")
            )
            
            jobs_data, jobs_metrics = await loader.load_all_jobs(
                mode=mode,
                user_context=self.user_context
            )
            
            # üîç LOGS DE DIAGNOSTIC - D√©tails des jobs charg√©s
            logger.info(f"[SESSION] üîç DIAGNOSTIC jobs_data - Cl√©s: {list(jobs_data.keys())}")
            logger.info(f"[SESSION] üîç DIAGNOSTIC ROUTER - Type: {type(jobs_data.get('ROUTER'))}, "
                       f"Cl√©s: {list(jobs_data.get('ROUTER', {}).keys()) if isinstance(jobs_data.get('ROUTER'), dict) else 'N/A'}")
            
            if isinstance(jobs_data.get('ROUTER'), dict):
                router_data = jobs_data['ROUTER']
                unprocessed = router_data.get('to_process', [])
                in_process = router_data.get('in_process', [])
                processed = router_data.get('processed', [])
                logger.info(f"[SESSION] üîç DIAGNOSTIC ROUTER d√©tails - "
                           f"to_process: {len(unprocessed) if isinstance(unprocessed, list) else 'Not a list'}, "
                           f"in_process: {len(in_process) if isinstance(in_process, list) else 'Not a list'}, "
                           f"processed: {len(processed) if isinstance(processed, list) else 'Not a list'}")
                
                # Afficher le premier document si pr√©sent
                if isinstance(unprocessed, list) and len(unprocessed) > 0:
                    first_doc = unprocessed[0]
                    logger.info(f"[SESSION] üîç DIAGNOSTIC ROUTER premier doc - "
                               f"Cl√©s: {list(first_doc.keys()) if isinstance(first_doc, dict) else 'Not a dict'}")
                else:
                    logger.warning(f"[SESSION] ‚ö†Ô∏è DIAGNOSTIC ROUTER - Aucun document unprocessed !")
            
            logger.info(f"[SESSION] üîç DIAGNOSTIC jobs_metrics - "
                       f"ROUTER.to_process: {jobs_metrics.get('ROUTER', {}).get('to_process', 'N/A')}")
            
            return jobs_data, jobs_metrics
            
        except Exception as e:
            logger.error(f"[SESSION] Erreur chargement jobs: {e}", exc_info=True)
            # Retourner des structures vides avec message d'avertissement
            empty_metrics = {
                "APBOOKEEPER": {"to_do": 0, "in_process": 0, "done": 0},
                "ROUTER": {"to_process": 0, "in_process": 0, "done": 0},
                "BANK": {"to_reconcile": 0, "pending": 0, "in_process": 0},
                "warnings": [f"‚ö†Ô∏è Erreur lors du chargement des jobs: {str(e)}"]
            }
            return {}, empty_metrics
    
    def update_context(self, **kwargs):
        """
        Met √† jour le contexte dynamiquement.
        
        ‚ö†Ô∏è PARTIALLY DEPRECATED: La partie agent est obsol√®te.
        """
        for key, value in kwargs.items():
            if hasattr(self.context, key):
                setattr(self.context, key, value)
        
        # ‚ö†Ô∏è DEPRECATED: self.agent n'existe plus dans la nouvelle architecture
        # Les brains par thread g√®rent maintenant leur propre contexte
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # TRACKING PR√âSENCE UTILISATEUR (Mode UI vs BACKEND)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def enter_chat(self, thread_key: str):
        """
        Marque que l'utilisateur vient d'envoyer un message sur ce thread.
        Appel√© automatiquement par send_message().
        
        Args:
            thread_key: Thread sur lequel l'utilisateur est actif
        """
        self.is_on_chat_page = True
        self.current_active_thread = thread_key
        self.last_activity[thread_key] = datetime.now(timezone.utc)
        
        logger.info(
            f"[SESSION_TRACKING] üë§ User ENTR√â sur chat - "
            f"session={self.session_key}, thread={thread_key}"
        )
    
    def switch_thread(self, new_thread_key: str):
        """
        Marque que l'utilisateur change de thread (toujours sur la page chat).
        Appel√© par load_chat_history() quand user change de conversation.
        
        Args:
            new_thread_key: Nouveau thread actif
        """
        old_thread = self.current_active_thread
        self.current_active_thread = new_thread_key
        self.last_activity[new_thread_key] = datetime.now(timezone.utc)
        
        logger.info(
            f"[SESSION_TRACKING] üîÑ User SWITCH thread - "
            f"session={self.session_key}, {old_thread} ‚Üí {new_thread_key}"
        )
    
    def leave_chat(self):
        """
        Marque que l'utilisateur quitte la page chat.
        Appel√© par signal RPC depuis Reflex (unmount, navigation).
        
        Note: On conserve current_active_thread pour historique.
        """
        old_thread = self.current_active_thread
        self.is_on_chat_page = False
        # ‚ö†Ô∏è NE PAS effacer current_active_thread (utile pour logs/debug)
        
        logger.info(
            f"[SESSION_TRACKING] üëã User QUITT√â chat - "
            f"session={self.session_key}, √©tait sur thread={old_thread}"
        )
    
    def is_user_on_specific_thread(self, thread_key: str) -> bool:
        """
        V√©rifie si l'utilisateur est ACTUELLEMENT actif sur ce thread pr√©cis.
        
        Logique:
        - is_on_chat_page = False ‚Üí False (pas sur la page)
        - is_on_chat_page = True + current_active_thread = thread_key ‚Üí True
        - is_on_chat_page = True + current_active_thread ‚â† thread_key ‚Üí False
        
        Args:
            thread_key: Thread √† v√©rifier
            
        Returns:
            True si user est sur la page chat ET sur ce thread pr√©cis
        """
        is_on = self.is_on_chat_page and self.current_active_thread == thread_key
        
        logger.debug(
            f"[SESSION_TRACKING] Check user on thread={thread_key}: {is_on} "
            f"(is_on_chat_page={self.is_on_chat_page}, "
            f"current_active_thread={self.current_active_thread})"
        )
        
        return is_on
    
    
    
    def _extract_response_text(self, response) -> str:
        """Extrait le texte de la r√©ponse de BaseAIAgent."""
        response_text = ""
        if isinstance(response, dict):
            if 'text_output' in response:
                text_output = response.get('text_output', {})
                if isinstance(text_output, dict):
                    content = text_output.get('content', {})
                    if isinstance(content, dict):
                        response_text = content.get('answer_text', '')
                    else:
                        response_text = str(content)
                else:
                    response_text = str(text_output)
            else:
                response_text = str(response)
        else:
            response_text = str(response)
        
        return response_text
    
    
    def get_last_response_duration_ms(self, thread_key: str) -> int:
        """Retourne la dur√©e de la derni√®re r√©ponse en ms."""
        if thread_key in self.response_times and self.response_times[thread_key]:
            return int(self.response_times[thread_key][-1])
        return 0


class LLMManager:
    """Gestionnaire LLM utilisant Firebase Realtime Database."""
    ONBOARDING_LIKE_MODES = {"onboarding_chat", "apbookeeper_chat", "router_chat", "banker_chat"}
    ACTIVE_CHAT_MODES = {"apbookeeper_chat", "router_chat", "banker_chat"}
    
    def __init__(self):
        self.sessions: Dict[str, LLMSession] = {}
        self._lock = threading.Lock()
        self.rtdb_formatter = RTDBMessageFormatter()
        self.streaming_controller = StreamingController()
    
    def _is_onboarding_like(self, chat_mode: Optional[str]) -> bool:
        return (chat_mode or "") in self.ONBOARDING_LIKE_MODES

    def _resolve_messages_container(self, chat_mode: Optional[str]) -> str:
        if (chat_mode or "") in self.ACTIVE_CHAT_MODES:
            return "active_chats"
        return "chats"

    def _get_messages_base_path(self, collection_name: str, thread_key: str, chat_mode: Optional[str]) -> str:
        container = self._resolve_messages_container(chat_mode)
        return f"{collection_name}/{container}/{thread_key}/messages"
    
    def _get_rtdb_ref(self, path: str):
        """Obtient une r√©f√©rence Firebase RTDB."""
        from ..listeners_manager import _get_rtdb_ref
        return _get_rtdb_ref(path)
    
    async def _load_history_from_rtdb(self, collection_name: str, thread_key: str, chat_mode: Optional[str] = None) -> list:
        """
        Charge l'historique d'un chat depuis Firebase RTDB (mode BACKEND uniquement).
        En mode UI, l'historique est d√©j√† fourni via WebSocket.
        
        Args:
            collection_name: Nom de la collection (soci√©t√©)
            thread_key: Cl√© du thread de chat
            mode: Mode de groupement ('job_chats' ou 'chats')
            
        Returns:
            Liste des messages [{"role": "user/assistant", "content": "..."}]
        """
        try:
            messages_mode = self._resolve_messages_container(chat_mode)
            logger.info(
                f"[LOAD_RTDB] üì• Chargement historique depuis RTDB (BACKEND): {collection_name}/{messages_mode}/{thread_key}"
            )
            
            # Utiliser la m√©thode existante get_channel_messages de FirebaseRealtimeChat
            from ..firebase_providers import FirebaseRealtimeChat
            
            firebase_mgmt = FirebaseRealtimeChat()
            messages = firebase_mgmt.get_channel_messages(
                space_code=collection_name,
                thread_key=thread_key,
                limit=1000,  # Charger tous les messages r√©cents
                mode=messages_mode
            )
            
            if not messages:
                logger.info(f"[LOAD_RTDB] ‚ÑπÔ∏è Aucun historique trouv√© (nouveau chat)")
                return []
            
            # Transformer au format attendu par BaseAIAgent
            history = []
            for msg in messages:
                role = msg.get("role")
                content = msg.get("content", "")
                message_type = msg.get("message_type")
                
                # Compat h√©rit√©e : ignorer les anciens messages LOG_FOLLOW_UP persist√©s c√¥t√© agent utilisateur
                if message_type == "LOG_FOLLOW_UP":
                    logger.debug(f"[LOAD_RTDB] ‚è≠Ô∏è Message LOG_FOLLOW_UP filtr√©: {msg.get('message_id', 'unknown')}")
                    continue
                
                # ‚≠ê FILTRER les messages non-MESSAGE (CARD, WORKFLOW, CMMD, FOLLOW_MESSAGE, etc.)
                # Ces messages ne doivent PAS √™tre inject√©s dans l'historique LLM
                # - FOLLOW_MESSAGE : G√©r√© en mode interm√©diation, pas dans l'historique agent
                # - Autres types : Envoy√©s uniquement via WebSocket (g√©r√© dans _handle_onboarding_log_event)
                if message_type and message_type not in ["MESSAGE", None]:
                    logger.debug(
                        f"[LOAD_RTDB] ‚è≠Ô∏è Message non-MESSAGE filtr√©: "
                        f"type={message_type} message_id={msg.get('id', msg.get('message_id', 'unknown'))}"
                    )
                    continue
                
                # Filtrer les messages vides ou invalides
                if role in ["user", "assistant"] and content:
                    history.append({
                        "role": role,
                        "content": content
                    })
            
            logger.info(f"[LOAD_RTDB] ‚úÖ Historique charg√©: {len(history)} messages")
            return history
            
        except Exception as e:
            logger.error(f"[LOAD_RTDB] ‚ùå Erreur chargement historique: {e}", exc_info=True)
            return []
    
    async def _ensure_session_initialized(
        self,
        user_id: str,
        collection_name: str,
        chat_mode: str = "general_chat"
        ) -> LLMSession:
        """
        Garantit qu'une session existe avec toutes les donn√©es permanentes charg√©es.
        
        ‚≠ê CRITIQUE pour isolation: Charge user_context, jobs_data, jobs_metrics
        
        Utilis√© par:
        - Mode UI (send_message)
        - Mode BACKEND (callback LPT, scheduler)
        
        Returns:
            LLMSession avec donn√©es permanentes charg√©es
        
        Raises:
            Exception si l'initialisation √©choue
        """
        session_key = f"{user_id}:{collection_name}"
        
        # V√©rifier si session existe avec donn√©es charg√©es
        session = None
        with self._lock:
            if session_key in self.sessions:
                session = self.sessions[session_key]
                
                # Si donn√©es permanentes charg√©es ‚Üí V√©rifier si chat_mode doit √™tre mis √† jour
                if session.user_context is not None:
                    # ‚≠ê NOUVEAU : Mettre √† jour le chat_mode si diff√©rent
                    if session.context.chat_mode != chat_mode:
                        logger.info(
                            f"[ENSURE_SESSION] üîÑ Mise √† jour chat_mode: "
                            f"{session.context.chat_mode} ‚Üí {chat_mode}"
                        )
                        session.update_context(chat_mode=chat_mode)
                    else:
                        logger.info(
                            f"[ENSURE_SESSION] ‚úÖ Session OK avec donn√©es permanentes: {session_key}"
                        )
                        return session
                else:
                    # Session existe mais donn√©es manquantes
                    logger.warning(
                        f"[ENSURE_SESSION] Session existe mais user_context=None, "
                        f"rechargement des donn√©es permanentes..."
                    )
                    session = None
        
        # Si session existe avec user_context et chat_mode diff√©rent ‚Üí Mettre √† jour les brains
        if session is not None and session.user_context is not None:
            try:
                # ‚≠ê Mettre √† jour tous les brains actifs avec le nouveau chat_mode
                for thread_key, brain in session.active_brains.items():
                    brain.initialize_system_prompt(
                        chat_mode=chat_mode,
                        jobs_metrics=session.jobs_metrics
                    )
                    # Charger les donn√©es selon le mode
                    if chat_mode == "onboarding_chat":
                        await brain.load_onboarding_data()
                    elif chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                        # Pour ces modes, le job_id est le thread_key
                        job_id = thread_key
                        await brain.load_job_data(job_id)
                    logger.info(
                        f"[ENSURE_SESSION] ‚úÖ Brain thread={thread_key} "
                        f"mis √† jour avec chat_mode={chat_mode}"
                    )
            except Exception as e:
                logger.warning(
                    f"[ENSURE_SESSION] ‚ö†Ô∏è Erreur mise √† jour brains: {e}"
                )
            
            logger.info(
                f"[ENSURE_SESSION] ‚úÖ Session OK avec donn√©es permanentes: {session_key}"
            )
            return session
        
        # Session n'existe pas OU donn√©es manquantes ‚Üí Initialiser
        logger.info(
            f"[ENSURE_SESSION] Initialisation session (nouvelle ou donn√©es manquantes): {session_key}"
        )
        
        result = await self.initialize_session(
            user_id=user_id,
            collection_name=collection_name,
            chat_mode=chat_mode
        )
        
        if not result.get("success"):
            raise Exception(f"√âchec initialisation session: {result.get('error')}")
        
        # R√©cup√©rer la session nouvellement cr√©√©e/rafra√Æchie
        with self._lock:
            if session_key not in self.sessions:
                raise Exception("Session non trouv√©e apr√®s initialisation")
            
            session = self.sessions[session_key]
            
            # V√©rification finale
            if session.user_context is None:
                raise Exception("Session initialis√©e mais user_context toujours None")
            
            logger.info(
                f"[ENSURE_SESSION] ‚úÖ Session initialis√©e avec donn√©es permanentes: {session_key}"
            )
            
            return session
    
    async def initialize_session(
        self,
        user_id: str,
        collection_name: str,
        client_uuid: str,
        dms_system: str = "google_drive",
        dms_mode: str = "prod",
        chat_mode: str = "general_chat"
        ) -> dict:
        """Initialise une session LLM pour un utilisateur/soci√©t√©."""
        try:
            logger.info(f"=== D√âBUT initialize_session ===")
            logger.info(f"Param√®tres: user_id={user_id}, collection_name={collection_name}, client_uuid={client_uuid}")
            logger.info(f"Chat mode: {chat_mode}")
            
            with self._lock:
                base_session_key = f"{user_id}:{collection_name}"
                
                logger.info(f"Initialisation session LLM: {base_session_key}")
                
                # V√©rifier si session existe d√©j√†
                if base_session_key in self.sessions:
                    session = self.sessions[base_session_key]
                    
                    logger.info(f"Session existante trouv√©e: {base_session_key}")
                    
                    # ‚≠ê NOUVEAU : V√©rifier si client_uuid OU collection_name a chang√©
                    # (Normalement collection_name ne change pas car session_key = user_id:collection_name,
                    #  mais on v√©rifie quand m√™me pour robustesse)
                    current_client_uuid = (session.user_context or {}).get("client_uuid") if session.user_context else None
                    current_collection_name = session.context.collection_name if session.context else None
                    
                    # üîç DIAGNOSTIC
                    logger.info(
                        f"[SESSION] üîç DIAGNOSTIC user_context - "
                        f"user_context existe: {session.user_context is not None}, "
                        f"current_client_uuid: {current_client_uuid}, "
                        f"nouveau client_uuid: {client_uuid}, "
                        f"current_collection_name: {current_collection_name}, "
                        f"nouveau collection_name: {collection_name}"
                    )
                    
                    # D√©cider si on doit recharger user_context
                    should_reload = False
                    reload_reason = None
                    
                    # ‚ö†Ô∏è V√©rifier que client_uuid n'est pas vide avant de recharger
                    if not client_uuid or client_uuid.strip() == '':
                        logger.warning(
                            f"[SESSION] ‚ö†Ô∏è client_uuid vide re√ßu, conservation du client_uuid existant: {current_client_uuid}"
                        )
                        # Utiliser le client_uuid existant si disponible
                        if current_client_uuid:
                            client_uuid = current_client_uuid
                        else:
                            raise ValueError(
                                f"Impossible d'initialiser la session: client_uuid vide et aucun client_uuid existant"
                            )
                    
                    if current_client_uuid and current_client_uuid != client_uuid:
                        should_reload = True
                        reload_reason = f"client_uuid a chang√©: {current_client_uuid} ‚Üí {client_uuid}"
                    elif current_collection_name and current_collection_name != collection_name:
                        should_reload = True
                        reload_reason = f"collection_name a chang√©: {current_collection_name} ‚Üí {collection_name}"
                    elif not current_client_uuid:
                        should_reload = True
                        reload_reason = "user_context manquant"
                    
                    if should_reload:
                        logger.info(
                            f"[SESSION] üîÑ {reload_reason} pour session_key={base_session_key}"
                        )
                        logger.info(f"[SESSION] üîÑ Rechargement user_context...")
                        
                        # Recharger user_context avec le nouveau client_uuid et collection_name
                        await session.initialize_session_data(client_uuid)
                        logger.info(f"[SESSION] ‚úÖ user_context recharg√© avec nouveau contexte")
                    
                    # ‚≠ê UTILISER le dms_system depuis user_context (priorit√© sur le param√®tre)
                    actual_dms_system = session.user_context.get("dms_system", "google_drive") if session.user_context else dms_system
                    
                    # Mettre √† jour le contexte si n√©cessaire
                    if (session.context.dms_system != actual_dms_system or 
                        session.context.chat_mode != chat_mode):
                        session.update_context(
                            dms_system=actual_dms_system,  # ‚≠ê Utiliser la valeur du user_context
                            dms_mode=dms_mode,
                            chat_mode=chat_mode
                        )
                        logger.info(f"[SESSION] üîÑ DMS mis √† jour depuis user_context: {actual_dms_system}")
                    
                    # ‚úÖ RAFRA√éCHIR les jobs et m√©triques (m√™me si session existe)
                    # ‚≠ê Maintenant avec le BON user_context (recharg√© ci-dessus si n√©cessaire)
                    try:
                        logger.info(f"[SESSION] üîÑ Rafra√Æchissement des jobs et m√©triques...")
                        
                        # D√©tecter le mode (UI/BACKEND)
                        mode = await session._detect_connection_mode()
                        logger.info(f"[SESSION] Mode d√©tect√©: {mode}")
                        
                        # Recharger les jobs depuis Redis (UI) ou sources (BACKEND)
                        jobs_data, jobs_metrics = await session._load_jobs_with_metrics(mode)
                        
                        # Mettre √† jour les donn√©es de la session
                        session.jobs_data = jobs_data
                        session.jobs_metrics = jobs_metrics
                        
                        logger.info(f"[SESSION] ‚úÖ Jobs rafra√Æchis - APBookkeeper: {jobs_metrics.get('APBOOKEEPER', {}).get('to_do', 0)}, "
                                   f"Router: {jobs_metrics.get('ROUTER', {}).get('to_process', 0)}, "
                                   f"Bank: {jobs_metrics.get('BANK', {}).get('to_reconcile', 0)}")
                        
                        # ‚≠ê Mettre √† jour tous les brains actifs avec les nouvelles m√©triques
                        for thread_key, brain in session.active_brains.items():
                            brain.jobs_data = jobs_data
                            brain.jobs_metrics = jobs_metrics
                            # Charger les donn√©es selon le mode
                            if chat_mode == "onboarding_chat":
                                await brain.load_onboarding_data()
                            elif chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                                # Pour ces modes, le job_id est le thread_key
                                job_id = thread_key
                                await brain.load_job_data(job_id)
                            brain.initialize_system_prompt(chat_mode=chat_mode, jobs_metrics=jobs_metrics)
                            logger.info(f"[SESSION] ‚úÖ Brain thread={thread_key} mis √† jour avec m√©triques fra√Æches")
                        
                    except Exception as e:
                        logger.warning(f"[SESSION] ‚ö†Ô∏è Erreur rafra√Æchissement jobs: {e}")
                        # Ne pas bloquer la session si le rafra√Æchissement √©choue
                    
                    logger.info(f"Session r√©utilis√©e avec donn√©es rafra√Æchies: {base_session_key}")
                    return {
                        "success": True,
                        "session_id": base_session_key,
                        "status": "refreshed",
                        "message": "Session LLM r√©utilis√©e avec donn√©es rafra√Æchies"
                    }
                
                # ‚ö†Ô∏è V√©rifier que client_uuid n'est pas vide avant de cr√©er une nouvelle session
                if not client_uuid or client_uuid.strip() == '':
                    raise ValueError(
                        f"Impossible de cr√©er une nouvelle session: client_uuid vide requis pour user_id={user_id}, collection_name={collection_name}"
                    )
                
                # Cr√©er nouvelle session
                context = LLMContext(
                    user_id=user_id,
                    collection_name=collection_name,
                    dms_system=dms_system,
                    dms_mode=dms_mode,
                    chat_mode=chat_mode
                )
                
                session = LLMSession(
                    session_key=base_session_key,
                    context=context
                )
                
                # Initialiser les donn√©es permanentes
                logger.info(f"Initialisation donn√©es session...")
                await session.initialize_session_data(client_uuid)
                logger.info(f"Donn√©es session initialis√©es avec succ√®s")
                
                # ‚≠ê METTRE √Ä JOUR le dms_system depuis le user_context charg√©
                if session.user_context and session.user_context.get("dms_system"):
                    actual_dms_system = session.user_context.get("dms_system", "google_drive")
                    if session.context.dms_system != actual_dms_system:
                        session.update_context(dms_system=actual_dms_system)
                        logger.info(f"[SESSION] üîÑ DMS mis √† jour depuis user_context lors de la cr√©ation: {actual_dms_system}")
                
                # Stocker en cache
                logger.info(f"Stockage de la session en cache...")
                self.sessions[base_session_key] = session
                logger.info(f"Session stock√©e en cache")
                
                logger.info(f"Nouvelle session cr√©√©e: {base_session_key}")
                logger.info(f"=== FIN initialize_session ===")
                return {
                    "success": True,
                    "session_id": base_session_key,
                    "status": "created",
                    "message": "Session LLM initialis√©e avec succ√®s"
                }
                
        except Exception as e:
            logger.error(f"Erreur initialisation session LLM: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec de l'initialisation LLM"
            }
    
    async def invalidate_user_context(self, user_id: str, collection_name: str) -> dict:
        """
        Invalide le contexte utilisateur en m√©moire et dans Redis pour forcer un rechargement.
        """
        session_key = f"{user_id}:{collection_name}"
        logger.info(f"[INVALIDATE_CONTEXT] Requ√™te re√ßue pour {session_key}")

        with self._lock:
            session = self.sessions.get(session_key)

        brains_snapshot: List[Tuple[str, Any]] = []
        if session:
            with session._lock:
                session.user_context = None
                session.jobs_data = None
                session.jobs_metrics = None
                session.thread_contexts.clear()
                brains_snapshot = list(session.active_brains.items())

            logger.info(
                "[INVALIDATE_CONTEXT] Session trouv√©e, contexte remis √† z√©ro pour %s",
                session_key,
            )
        else:
            logger.info(
                "[INVALIDATE_CONTEXT] Session introuvable pour %s (aucune donn√©e √† invalider)",
                session_key,
            )

        brains_invalidated = 0
        for thread_key, brain in brains_snapshot:
            if not brain:
                continue
            try:
                brain.user_context = None
                brain.jobs_data = None
                brain.jobs_metrics = None
                brains_invalidated += 1
                logger.info(
                    "[INVALIDATE_CONTEXT] Brain thread=%s marqu√© pour rechargement",
                    thread_key,
                )
            except Exception as brain_error:
                logger.warning(
                    "[INVALIDATE_CONTEXT] Erreur remise √† z√©ro brain thread=%s: %s",
                    thread_key,
                    brain_error,
                )

        redis_deleted: Optional[bool] = None
        try:
            from ..redis_client import get_redis

            redis_client = get_redis()
            context_key = f"context:{user_id}:{collection_name}"
            deleted = redis_client.delete(context_key)
            redis_deleted = bool(deleted)
            if redis_deleted:
                logger.info(
                    "[INVALIDATE_CONTEXT] Cl√© Redis supprim√©e: %s",
                    context_key,
                )
            else:
                logger.info(
                    "[INVALIDATE_CONTEXT] Cl√© Redis absente (aucune suppression): %s",
                    context_key,
                )
        except Exception as redis_error:
            logger.warning(
                "[INVALIDATE_CONTEXT] Erreur suppression Redis pour %s: %s",
                session_key,
                redis_error,
            )

        status = "session_reset" if session else "session_absent"
        return {
            "success": True,
            "status": status,
            "session_key": session_key,
            "brains_invalidated": brains_invalidated,
            "redis_deleted": redis_deleted,
        }
    
    async def start_onboarding_chat(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        chat_mode: str = "onboarding_chat",
        initial_message: Optional[str] = None,
        system_prompt: Optional[str] = None,
        job_status: Optional[str] = None
        ) -> dict:
        """
        Lance le job LPT d'onboarding pour un thread.

        ‚ö†Ô∏è IMPORTANT : Le thread RTDB existe D√âJ√Ä (cr√©√© c√¥t√© frontend).

        ‚≠ê R√¥le :
        - Cr√©e/initialise le brain si n√©cessaire
        - Charge les donn√©es onboarding
        - Lance TOUJOURS le job LPT (sauf si d√©j√† lanc√©)
        - Envoie le message de notification √† l'utilisateur

        ‚≠ê Diff√©rence avec enter_chat() :
        - start_onboarding_chat() : LANCE le job LPT (appel√© via bouton "Lancer onboarding")
        - enter_chat() : Initialise juste le brain/context (appel√© quand on s√©lectionne le chat)
        - enter_chat() NE lance PAS le LPT (juste conversation avec l'agent)

        Sc√©narios :
        1. Nouveau chat ‚Üí start_onboarding_chat() ‚Üí cr√©e brain ‚Üí lance LPT ‚Üí message
        2. Chat existant (s√©lection) ‚Üí enter_chat() ‚Üí initialise brain ‚Üí PAS de LPT
        3. Chat existant (bouton lancement) ‚Üí start_onboarding_chat() ‚Üí v√©rifie si d√©j√† lanc√© ‚Üí lance LPT si pas lanc√© ‚Üí message
        """

        try:
            logger.info(
                f"[ONBOARDING_START] üöÄ user={user_id} collection={collection_name} thread={thread_key}"
            )

            # 1. Initialiser la session en mode onboarding et marquer la pr√©sence
            session = await self._ensure_session_initialized(
                user_id=user_id,
                collection_name=collection_name,
                chat_mode="onboarding_chat"
            )

            session.enter_chat(thread_key)

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : CHARGER/CR√âER LE BRAIN POUR CE THREAD
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            history = await self._load_history_from_rtdb(collection_name, thread_key, chat_mode)
            load_result = await self.load_chat_history(
                user_id=user_id,
                collection_name=collection_name,
                thread_key=thread_key,
                history=history
            )

            if not load_result.get("success"):
                return {
                    "success": False,
                    "error": "brain_initialization_failed",
                    "message": load_result.get("message", "√âchec cr√©ation brain"),
                    "details": load_result
                }

            brain = session.active_brains.get(thread_key)
            if not brain:
                raise RuntimeError("Brain introuvable apr√®s initialisation")

            await brain.load_onboarding_data()
            onboarding_data = brain.onboarding_data or {}

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : V√âRIFIER SI LE JOB A D√âJ√Ä √âT√â LANC√â (protection doublons)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # Utiliser l'historique d√©j√† charg√© (pas de double chargement)
            job_already_launched = len(history) > 0

            # Pr√©charger l'historique des logs (utilis√© apr√®s lancement du job)
            log_entries = await self._load_onboarding_log_history(
                brain=brain,
                collection_name=collection_name,
                session=session,
                thread_key=thread_key
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : LANCER AUTOMATIQUEMENT LE JOB LPT
            # (Identique √† enter_chat - m√™me format, m√™me logique)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            lpt_status = None
            job_id = (brain.onboarding_data or {}).get("job_id") if brain.onboarding_data else None
            launch_result = None

            if not job_already_launched:
                logger.info(f"[ONBOARDING_START] üöÄ Lancement automatique du job onboarding pour thread={thread_key}")
                
                from ..pinnokio_agentic_workflow.tools.lpt_client import LPTClient
                lpt_client = LPTClient()
                launch_result = await lpt_client.launch_onboarding_job(
                    user_id=user_id,
                    company_id=collection_name,
                    thread_key=thread_key,
                    session=session,
                    brain=brain
                )

                lpt_status = launch_result.get("status") if isinstance(launch_result, dict) else None
                job_id = (brain.onboarding_data or {}).get("job_id") if brain.onboarding_data else None

                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                # √âTAPE 4 : ENVOYER LE PREMIER MESSAGE ASSISTANT
                # (Identique √† enter_chat - m√™me m√©thode, m√™me format)
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                if lpt_status in ("queued", "started"):
                    await self._send_onboarding_start_message(
                        user_id=user_id,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        job_id=job_id or "onboarding"
                    )
                    logger.info(f"[ONBOARDING_START] ‚úÖ Message de d√©marrage envoy√© pour job={job_id}")
            else:
                logger.info(
                    f"[ONBOARDING_START] ‚è≠Ô∏è Job d√©j√† lanc√© pour thread={thread_key}, "
                    f"pas de relance (protection doublons)"
                )
                # R√©cup√©rer le job_id depuis les donn√©es onboarding m√™me si job d√©j√† lanc√©
                job_id = (brain.onboarding_data or {}).get("job_id") if brain.onboarding_data else None
                
                # ‚≠ê ENVOYER QUAND M√äME UN MESSAGE pour informer l'utilisateur que le job est actif
                await self._send_onboarding_start_message(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    job_id=job_id or "onboarding"
                )
                logger.info(f"[ONBOARDING_START] ‚úÖ Message informatif envoy√© pour job existant={job_id}")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 5 : D√âMARRER L'√âCOUTE RTDB
            # (Identique √† enter_chat - m√™me canaux, m√™me logique)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            await self._ensure_onboarding_listener(
                session=session,
                brain=brain,
                collection_name=collection_name,
                thread_key=thread_key,
                initial_entries=log_entries
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 5.5 : V√âRIFIER MODE INTERM√âDIATION AU CHARGEMENT
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            await self._check_intermediation_on_load(
                session=session,
                collection_name=collection_name,
                thread_key=thread_key,
                job_status=job_status
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 6 : CONFIGURATION TRACABILIT√â (optionnel, pour compatibilit√©)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if isinstance(launch_result, dict) and launch_result.get("status") == "queued":
                if session.thread_states is not None:
                    session.thread_states[thread_key] = "onboarding_running"
                
                brain.active_task_data = {
                    "task_id": launch_result.get("task_id") or launch_result.get("job_id"),
                    "execution_id": launch_result.get("execution_id"),
                    "mandate_path": (session.user_context or {}).get("mandate_path") if session.user_context else None,
                    "thread_key": thread_key,
                    "task_type": "ONBOARDING"
                }

            # G√©rer les diff√©rents cas de succ√®s
            if job_already_launched:
                # Job d√©j√† lanc√© (d√©tect√© par protection doublons)
                success = True
                message = "Onboarding d√©j√† initialis√© (job pr√©c√©demment lanc√©)"
            elif lpt_status in ("queued", "started"):
                # Job lanc√© avec succ√®s
                success = True
                message = "Onboarding d√©marr√© avec succ√®s"
            else:
                # √âchec du lancement
                success = False
                message = "Onboarding initialis√© avec avertissement"

            response = {
                "success": success,
                "message": message,
                "thread_key": thread_key,
                "job_id": job_id,
                "lpt_status": lpt_status,
                "job_already_launched": job_already_launched,
                "lpt": launch_result
            }

            if job_already_launched:
                response["info"] = "Le job √©tait d√©j√† lanc√©, pas de relance effectu√©e"
            elif not success:
                response["warning"] = "Le job onboarding n'a pas pu √™tre lanc√©"
                if isinstance(launch_result, dict) and launch_result.get("error"):
                    response["error"] = launch_result.get("error")

            logger.info(
                f"[ONBOARDING_START] ‚úÖ Termin√© - success={success} status={lpt_status} thread={thread_key}"
            )

            return response

        except Exception as e:
            logger.error(f"[ONBOARDING_START] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec du d√©marrage de l'onboarding"
            }

    async def stop_onboarding_chat(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        chat_mode: str = "onboarding_chat",
        job_ids: Optional[str] = None,
        mandates_path: Optional[str] = None
        ) -> dict:
        """
        Arr√™te imm√©diatement le job d'onboarding (action synchrone, pas LPT).
        
        ‚ö†Ô∏è IMPORTANT : Le thread RTDB existe D√âJ√Ä (cr√©√© c√¥t√© frontend).
        
        ‚≠ê R√¥le :
        - Initialise le brain/context (m√™me logique que enter_chat)
        - Envoie directement une requ√™te HTTP d'arr√™t au point de terminaison
        - Attend le retour 200/202
        - √âcrit le r√©sultat dans RTDB pour que l'agent informe l'utilisateur
        
        Args:
            user_id: ID Firebase de l'utilisateur
            collection_name: ID de la soci√©t√©
            thread_key: Thread sur lequel le job tourne
            chat_mode: Mode de chat (default: "onboarding_chat")
            job_ids: ID du job √† arr√™ter (dans payload)
            mandates_path: Chemin du mandat (dans payload)
        """
        try:
            logger.info(
                f"[ONBOARDING_STOP] üõë user={user_id} collection={collection_name} "
                f"thread={thread_key} job_ids={job_ids}"
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : INITIALISER SESSION ET BRAIN (identique √† enter_chat)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            session = await self._ensure_session_initialized(
                user_id=user_id,
                collection_name=collection_name,
                chat_mode="onboarding_chat"
            )

            session.enter_chat(thread_key)

            # Charger/Cr√©er le brain pour ce thread
            history = await self._load_history_from_rtdb(collection_name, thread_key, session.context.chat_mode)
            load_result = await self.load_chat_history(
                user_id=user_id,
                collection_name=collection_name,
                thread_key=thread_key,
                history=history
            )

            if not load_result.get("success"):
                return {
                    "success": False,
                    "error": "brain_initialization_failed",
                    "message": load_result.get("message", "√âchec cr√©ation brain"),
                    "details": load_result
                }

            brain = session.active_brains.get(thread_key)
            if not brain:
                raise RuntimeError("Brain introuvable apr√®s initialisation")

            await brain.load_onboarding_data()
            
            # R√©cup√©rer mandate_path depuis le contexte si non fourni
            if not mandates_path:
                # Essayer depuis session.user_context d'abord
                mandates_path = (session.user_context or {}).get("mandate_path") if session.user_context else None
                
                # Fallback sur brain.user_context si pas trouv√©
                if not mandates_path:
                    context = brain.get_user_context()
                    mandates_path = context.get("mandate_path") if context else None
                
                # Fallback sur session.context.mandate_path
                if not mandates_path:
                    mandates_path = session.context.mandate_path if session.context else None
                
                if not mandates_path:
                    return {
                        "success": False,
                        "error": "mandates_path_required",
                        "message": "mandates_path est requis pour arr√™ter le job"
                    }

            # R√©cup√©rer job_id depuis les donn√©es onboarding si non fourni
            if not job_ids:
                job_ids = (brain.onboarding_data or {}).get("job_id") if brain.onboarding_data else None
                if not job_ids:
                    return {
                        "success": False,
                        "error": "job_id_required",
                        "message": "job_ids est requis pour arr√™ter le job"
                    }

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : CONSTRUIRE LE PAYLOAD D'ARR√äT
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            payload = {
                "job_ids": job_ids,
                "mandates_path": mandates_path
            }

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : ENVOYER REQU√äTE HTTP DIRECTE (action imm√©diate, pas LPT)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # D√©terminer l'URL selon l'environnement
            import os
            environment = os.getenv('PINNOKIO_ENVIRONMENT', 'LOCAL').upper()
            
            if environment == 'LOCAL':
                base_url = 'http://127.0.0.1:8080'
            else:  # PROD
                base_url = os.getenv(
                    'PINNOKIO_AWS_URL', 
                    'http://klk-load-balancer-http-https-435479360.us-east-1.elb.amazonaws.com'
                )
            
            # ‚≠ê Format attendu: /stop-onboarding/<job_id> avec job_id dans le chemin
            stop_url = f"{base_url}/stop-onboarding/{job_ids}"
            
            logger.info(f"[ONBOARDING_STOP] üì§ Envoi HTTP POST vers: {stop_url}")
            logger.info(f"[ONBOARDING_STOP] üì¶ Payload: {payload}")
            
            import aiohttp
            stop_result = None
            http_status = None
            
            try:
                async with aiohttp.ClientSession() as session_http:
                    async with session_http.post(
                        stop_url, 
                        json=payload, 
                        timeout=aiohttp.ClientTimeout(total=30)
                    ) as response:
                        http_status = response.status
                        
                        if http_status in (200, 202):
                            try:
                                stop_result = await response.json()
                            except Exception:
                                stop_result = {"status": "stopped", "message": await response.text()}
                            
                            logger.info(
                                f"[ONBOARDING_STOP] ‚úÖ R√©ponse HTTP {http_status} - "
                                f"job_ids={job_ids} thread={thread_key}"
                            )
                        else:
                            error_text = await response.text()
                            logger.error(
                                f"[ONBOARDING_STOP] ‚ùå Erreur HTTP {http_status}: {error_text}"
                            )
                            stop_result = {
                                "status": "error",
                                "error": f"HTTP {http_status}: {error_text}"
                            }

            except aiohttp.ClientError as ce:
                logger.error(f"[ONBOARDING_STOP] ‚ùå Erreur de connexion HTTP: {ce}", exc_info=True)
                stop_result = {
                    "status": "error",
                    "error": f"Erreur de connexion: {str(ce)}",
                    "error_type": "connection_error"
                }
            except asyncio.TimeoutError:
                logger.error(f"[ONBOARDING_STOP] ‚è±Ô∏è Timeout apr√®s 30s vers {stop_url}")
                stop_result = {
                    "status": "error",
                    "error": "Timeout de connexion (30s)",
                    "error_type": "timeout"
                }

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 4 : √âCRIRE LE R√âSULTAT DANS RTDB POUR QUE L'AGENT INFORME L'UTILISATEUR
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            import uuid
            from datetime import datetime, timezone
            import json as _json
            
            assistant_message_id = str(uuid.uuid4())
            assistant_timestamp = datetime.now(timezone.utc).isoformat()
            
            # Construire le message selon le r√©sultat
            if http_status in (200, 202) and stop_result and stop_result.get("status") != "error":
                message_content = (
                    f"‚úÖ **Arr√™t du job d'onboarding**\n\n"
                    f"Le job **{job_ids}** a √©t√© arr√™t√© avec succ√®s.\n\n"
                    f"Le processus d'onboarding a √©t√© interrompu. Vous pouvez continuer √† me poser "
                    f"des questions si vous avez besoin d'aide."
                )
                if isinstance(stop_result, dict) and stop_result.get("message"):
                    message_content += f"\n\n**D√©tails** : {stop_result.get('message')}"
            else:
                error_msg = (
                    stop_result.get("error") if isinstance(stop_result, dict) 
                    else "Erreur inconnue lors de l'arr√™t"
                )
                message_content = (
                    f"‚ùå **Erreur lors de l'arr√™t du job**\n\n"
                    f"Impossible d'arr√™ter le job **{job_ids}**.\n\n"
                    f"**Erreur** : {error_msg}\n\n"
                    f"Veuillez r√©essayer ou contacter le support."
                )
            
            # √âcrire le message dans RTDB
            messages_base_path = self._get_messages_base_path(
                collection_name, thread_key, session.context.chat_mode
            )
            assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
            assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
            
            message_data = self.rtdb_formatter.format_ai_message(
                content=message_content,
                user_id=user_id,
                message_id=assistant_message_id,
                timestamp=assistant_timestamp,
                metadata={
                    "status": "completed",
                    "automation": "onboarding_stop",
                    "job_ids": job_ids,
                    "http_status": http_status,
                    "stop_result": stop_result
                }
            )
            
            assistant_msg_ref.set(message_data)
            
            logger.info(
                f"[ONBOARDING_STOP] ‚úÖ Message r√©sultat envoy√© - "
                f"thread={thread_key}, job_ids={job_ids}, http_status={http_status}"
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 5 : RETOURNER LA R√âPONSE
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            success = http_status in (200, 202) and stop_result and stop_result.get("status") != "error"
            
            response = {
                "success": success,
                "message": "Job arr√™t√© avec succ√®s" if success else "Erreur lors de l'arr√™t du job",
                "thread_key": thread_key,
                "job_ids": job_ids,
                "http_status": http_status,
                "stop_result": stop_result,
                "assistant_message_id": assistant_message_id
            }

            if not success:
                if isinstance(stop_result, dict) and stop_result.get("error"):
                    response["error"] = stop_result.get("error")

            logger.info(
                f"[ONBOARDING_STOP] ‚úÖ Termin√© - success={success} http_status={http_status} "
                f"thread={thread_key}"
            )

            return response

        except Exception as e:
            logger.error(f"[ONBOARDING_STOP] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec de l'arr√™t de l'onboarding"
            }
    
    async def send_message(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        message: str,
        chat_mode: str = "general_chat",
        system_prompt: str = None,
        selected_tool: str = None
        ) -> dict:
        """
        Point d'entr√©e MODE UI : Envoie un message et stream la r√©ponse via WebSocket.
        
        ‚≠ê FLUX UNIFI√â : Utilise _process_unified_workflow() avec enable_streaming=True
        """
        try:
            logger.info(
                f"[SEND_MESSAGE] üöÄ MODE UI - user={user_id} collection={collection_name} "
                f"thread={thread_key} message={message[:100]}..."
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : GARANTIR INITIALISATION SESSION (avec donn√©es permanentes)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            session = await self._ensure_session_initialized(
                user_id=user_id,
                collection_name=collection_name,
                chat_mode=chat_mode
            )
            
            logger.info(f"[SEND_MESSAGE] ‚úÖ Session garantie avec donn√©es permanentes")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1.5 : V√âRIFIER MODE INTERM√âDIATION
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # Si le thread est en mode interm√©diation, rediriger vers le handler sp√©cial
            if session.intermediation_mode.get(thread_key, False):
                logger.info(
                    f"[SEND_MESSAGE] üîÑ Mode interm√©diation actif - "
                    f"redirection vers handler sp√©cial pour thread={thread_key}"
                )
                return await self._handle_intermediation_response(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message,
                    session=session
                )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : V√âRIFIER QUE LE BRAIN EXISTE
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # Note: Le brain doit avoir √©t√© cr√©√© par LLM.enter_chat() avant l'envoi du message
            if thread_key not in session.active_brains:
                logger.error(
                    f"[SEND_MESSAGE] ‚ùå Brain non trouv√© pour thread={thread_key}. "
                    f"Le frontend doit appeler LLM.enter_chat() AVANT d'envoyer un message."
                )
                return {
                    "success": False,
                    "error": "Brain not initialized",
                    "message": f"Le chat doit √™tre initialis√© via enter_chat() avant d'envoyer des messages",
                    "thread_key": thread_key
                }
            
            logger.info(f"[SEND_MESSAGE] ‚úÖ Brain trouv√© et pr√™t")
            
            brain = session.active_brains[thread_key]

            # Charger les donn√©es selon le mode
            if session.context.chat_mode == "onboarding_chat":
                await brain.load_onboarding_data()
            elif session.context.chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                # Pour ces modes, le job_id est le thread_key
                # Si le document n'existe pas encore, c'est normal (job pas encore lanc√©)
                job_id = thread_key
                await brain.load_job_data(job_id)

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : PR√âPARER MESSAGE ASSISTANT RTDB
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # ‚ö†Ô∏è Note: Le message utilisateur est d√©j√† sauvegard√© par le frontend dans active_chats
            # On ne sauvegarde que le message assistant pour √©viter les doublons
            assistant_message_id = str(uuid.uuid4())
            assistant_timestamp = datetime.now(timezone.utc).isoformat()
            messages_base_path = self._get_messages_base_path(
                collection_name, thread_key, session.context.chat_mode
            )
            
            # Message assistant initial (vide, pour streaming)
            assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
            assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
            
            # ‚≠ê Utiliser le formatter pour garantir compatibilit√© UI
            initial_message_data = self.rtdb_formatter.format_ai_message(
                content="",
                user_id=user_id,
                message_id=assistant_message_id,
                timestamp=assistant_timestamp,
                metadata={
                    "status": "streaming",
                    "streaming_progress": 0.0
                }
            )
            
            assistant_msg_ref.set(initial_message_data)
            
            logger.info(f"[SEND_MESSAGE] Messages RTDB cr√©√©s")
            
            if self._is_onboarding_like(session.context.chat_mode) and message.strip().upper().endswith("TERMINATE"):
                await self._synthesize_and_send_terminate_response(
                    session=session,
                    brain=brain,
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    user_message=message
                )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 4 : LANCER WORKFLOW UNIFI√â EN ARRI√àRE-PLAN
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            task = asyncio.create_task(
                self._process_unified_workflow(
                    session=session,
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message,
                    assistant_message_id=assistant_message_id,
                    assistant_timestamp=assistant_timestamp,
                    enable_streaming=True,  # ‚Üê MODE UI : Streaming WebSocket activ√©
                    chat_mode=session.context.chat_mode,
                    system_prompt=system_prompt
                )
            )
            
            # Enregistrer stream pour contr√¥le d'arr√™t
            await self.streaming_controller.register_stream(
                session_key=f"{user_id}:{collection_name}",
                thread_key=thread_key,
                task=task
            )
            
            logger.info(f"[SEND_MESSAGE] ‚úÖ Workflow unifi√© lanc√© en arri√®re-plan (MODE UI)")
            
            return {
                "success": True,
                "user_message_id": None,  # ‚ö†Ô∏è Le frontend g√©n√®re son propre ID pour le message utilisateur
                "assistant_message_id": assistant_message_id,
                "ws_channel": f"chat:{user_id}:{collection_name}:{thread_key}",
                "message": "Message envoy√©, r√©ponse en cours de streaming via WebSocket"
            }
            
        except Exception as e:
            logger.error(f"Erreur envoi message LLM: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    async def update_context(
        self,
        user_id: str,
        collection_name: str,
        system_prompt: str = None
        ) -> dict:
        """
        Met √† jour le contexte de soci√©t√© pour le LLM.
        Appelle update_system_prompt de BaseAIAgent.
        
        Args:
            user_id: ID de l'utilisateur
            collection_name: ID de la soci√©t√©
            system_prompt: Prompt syst√®me personnalis√© (optionnel)
        """
        try:
            base_session_key = f"{user_id}:{collection_name}"
            
            logger.info(f"Mise √† jour contexte pour session: {base_session_key}")
            
            # R√©cup√©rer la session existante (lock MINIMAL)
            with self._lock:
                if base_session_key not in self.sessions:
                    return {
                        "success": False,
                        "error": "Session non trouv√©e",
                        "message": "Session LLM non initialis√©e"
                    }
                session = self.sessions[base_session_key]
            
            # Mettre √† jour le prompt syst√®me via BaseAIAgent
            if session.agent:
                # Utiliser le system_prompt fourni ou cr√©er un prompt par d√©faut
                if system_prompt:
                    new_system_prompt = system_prompt
                    logger.info(f"System prompt fourni: {system_prompt[:100]}...")
                else:
                    # Cr√©er un nouveau prompt syst√®me bas√© sur le contexte
                    new_system_prompt = f"""
                    Contexte mis √† jour pour l'utilisateur {user_id} dans la soci√©t√© {collection_name}.
                    Vous √™tes maintenant configur√© pour cette soci√©t√© sp√©cifique.
                    """
                    logger.info(f"System prompt par d√©faut cr√©√© pour {collection_name}")
                
                # Appeler update_system_prompt de BaseAIAgent
                session.agent.update_system_prompt(new_system_prompt)
                
                logger.info(f"Contexte mis √† jour pour session: {base_session_key}")
                
                return {
                    "success": True,
                    "message": "Contexte mis √† jour avec succ√®s",
                    "session_id": base_session_key
                }
            else:
                return {
                    "success": False,
                    "error": "Agent non initialis√©",
                    "message": "Agent LLM non disponible"
                }
                
        except Exception as e:
            logger.error(f"Erreur update_context: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec de la mise √† jour du contexte"
            }

    def _build_onboarding_intro_message(
        self,
        onboarding_data: Dict[str, Any],
        user_context: Optional[Dict[str, Any]],
        lpt_status: Optional[str],
        lpt_error: Optional[str] = None
        ) -> str:
        """Construit le message d'introduction envoy√© √† l'utilisateur."""

        company_name = (
            (onboarding_data.get("base_info") or {}).get("company_name")
            or onboarding_data.get("company_name")
            or (user_context or {}).get("company_name")
            or "votre entreprise"
        )

        if lpt_status == "queued":
            return (
                f"Bonjour ! Je suis Pinnokio, votre agent onboarding d√©di√© √† {company_name}. "
                "Je viens de lancer automatiquement l'analyse de vos donn√©es comptables. "
                "Je vous expliquerai chaque √©tape et vous alerterai d√®s qu'une action sera n√©cessaire. "
                "Pour commencer, pourriez-vous vous pr√©senter bri√®vement et partager vos attentes principales pour cette int√©gration ?"
            )

        error_part = (
            f" Je n'ai toutefois pas pu d√©marrer automatiquement le processus (d√©tail : {lpt_error})."
            if lpt_error else " Je n'ai toutefois pas pu d√©marrer automatiquement le processus."
        )

        return (
            f"Bonjour ! Je suis Pinnokio, votre agent onboarding d√©di√© √† {company_name}."
            + error_part +
            " Je reste √† vos c√¥t√©s pour relancer la proc√©dure et vous guider pas √† pas. "
            "Pr√©sentez-vous bri√®vement et dites-moi ce dont vous avez besoin en priorit√© pour que nous puissions avancer ensemble."
        )
    
    async def load_chat_history(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        history: list
        ) -> dict:
        """
        ‚≠ê NOUVELLE ARCHITECTURE: Charge l'historique = Cr√©er/Ouvrir brain pour ce chat
        
        Cette m√©thode est appel√©e quand l'utilisateur change de chat.
        Elle cr√©e un brain sp√©cifique pour ce thread s'il n'existe pas, ou le r√©utilise.
        
        Workflow:
        1. V√©rifier si brain existe d√©j√† pour ce thread
        2. Si oui: Recharger l'historique (peut avoir chang√©)
        3. Si non: Cr√©er nouveau brain avec agents + charger historique
        
        Args:
            user_id: ID Firebase de l'utilisateur
            collection_name: ID de la soci√©t√© (space_code)
            thread_key: Cl√© du thread de chat (ex: "new_chat_1019eff4")
            history: Historique du chat au format [{"role": "user", "content": "..."}, ...]
            
        Returns:
            dict: {"success": bool, "status": "created"|"updated", "loaded_messages": int}
        """
        try:
            base_session_key = f"{user_id}:{collection_name}"
            
            logger.info(f"[LOAD_CHAT] üìö Chargement chat pour session={base_session_key}, thread={thread_key}")
            logger.info(f"[LOAD_CHAT] Historique fourni: {len(history)} messages")
            
            # R√©cup√©rer la session existante
            with self._lock:
                if base_session_key not in self.sessions:
                    return {
                        "success": False,
                        "error": "Session non trouv√©e",
                        "message": "Session LLM non initialis√©e. Appelez initialize_session d'abord.",
                        "loaded_messages": 0
                    }
                session = self.sessions[base_session_key]
            
            # ‚≠ê TRACKER: Si user est d√©j√† sur la page chat, c'est un changement de thread
            if session.is_on_chat_page:
                session.switch_thread(thread_key)
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # CAS 1: Brain existe d√©j√† pour ce thread
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if thread_key in session.active_brains:
                brain = session.active_brains[thread_key]
                logger.info(f"[LOAD_CHAT] ‚ôªÔ∏è Brain existant trouv√© pour thread={thread_key}, rechargement historique...")
                
                # Recharger l'historique (peut avoir √©t√© mis √† jour)
                brain.pinnokio_agent.load_chat_history(history=history)
                
                if self._is_onboarding_like(session.context.chat_mode):
                    # Charger les donn√©es selon le mode
                    if session.context.chat_mode == "onboarding_chat":
                        await brain.load_onboarding_data()
                    elif session.context.chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                        # Pour ces modes, le job_id est le thread_key
                        job_id = thread_key
                        await brain.load_job_data(job_id)
                    log_entries = await self._load_onboarding_log_history(
                        brain=brain,
                        collection_name=collection_name,
                        session=session,
                        thread_key=thread_key
                    )
                    await self._ensure_onboarding_listener(
                        session=session,
                        brain=brain,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        initial_entries=log_entries
                    )

                    # ‚ïê‚ïê‚ïê V√âRIFIER MODE INTERM√âDIATION AU CHARGEMENT ‚ïê‚ïê‚ïê
                    # ‚ö†Ô∏è REMOVED: Cette v√©rification est d√©j√† effectu√©e dans enter_chat() et start_onboarding_chat()
                    # pour √©viter les appels en double qui causent l'envoi dupliqu√© des messages d'interm√©diation.
                    # Le mode interm√©diation est v√©rifi√© apr√®s la cr√©ation compl√®te du brain et du listener.

                session.last_activity[thread_key] = datetime.now(timezone.utc)
                
                logger.info(f"[LOAD_CHAT] ‚úÖ Brain mis √† jour: {len(history)} messages charg√©s")
                return {
                    "success": True,
                    "status": "updated",
                    "message": f"Brain existant mis √† jour: {len(history)} messages",
                    "loaded_messages": len(history),
                    "thread_key": thread_key
                }
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # CAS 2: Cr√©er nouveau brain pour ce thread
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            logger.info(f"[LOAD_CHAT] üÜï Cr√©ation nouveau brain pour thread={thread_key}")
            
            # Cr√©er lock pour ce thread
            if thread_key not in session._brain_locks:
                session._brain_locks[thread_key] = asyncio.Lock()
            
            async with session._brain_locks[thread_key]:
                # Double-check apr√®s le lock
                if thread_key in session.active_brains:
                    logger.info(f"[LOAD_CHAT] Brain cr√©√© par autre t√¢che, r√©utilisation")
                    return await self.load_chat_history(user_id, collection_name, thread_key, history)
                
                # ‚ïê‚ïê‚ïê Cr√©er le brain ‚ïê‚ïê‚ïê
                from ..pinnokio_agentic_workflow.orchestrator.pinnokio_brain import PinnokioBrain
                
                brain = PinnokioBrain(
                    collection_name=collection_name,
                    firebase_user_id=user_id,
                    dms_system=session.context.dms_system,
                    dms_mode=session.context.dms_mode
                )
                
                logger.info(f"[LOAD_CHAT] ü§ñ Cr√©ation agents du brain...")
                
                # ‚ïê‚ïê‚ïê Cr√©er les agents du brain ‚ïê‚ïê‚ïê
                await brain.initialize_agents()  # ‚Üê M√©thode √† cr√©er dans PinnokioBrain
                
                logger.info(f"[LOAD_CHAT] ‚úÖ Agents cr√©√©s (principal + outils)")
                
                # ‚ïê‚ïê‚ïê Injecter donn√©es permanentes ‚ïê‚ïê‚ïê
                brain.user_context = session.user_context  # R√©f√©rence partag√©e
                brain.jobs_data = session.jobs_data
                brain.jobs_metrics = session.jobs_metrics
                
                # üîç DEBUG : V√©rifier workflow_params dans session.user_context
                if session.user_context:
                    workflow_params = session.user_context.get("workflow_params", {})
                    logger.info(f"[LOAD_CHAT] üîç DEBUG session.user_context.workflow_params existe: {workflow_params is not None and workflow_params != {}}")
                    logger.info(f"[LOAD_CHAT] üîç DEBUG session.user_context.workflow_params cl√©s: {list(workflow_params.keys()) if workflow_params else 'VIDE'}")
                    if workflow_params and "Apbookeeper_param" in workflow_params:
                        logger.info(f"[LOAD_CHAT] üîç DEBUG Apbookeeper_param dans session: {workflow_params['Apbookeeper_param']}")
                else:
                    logger.warning(f"[LOAD_CHAT] ‚ö†Ô∏è session.user_context est None !")
                
                # üîç DEBUG : V√©rifier workflow_params dans brain.user_context apr√®s injection
                if brain.user_context:
                    brain_workflow_params = brain.user_context.get("workflow_params", {})
                    logger.info(f"[LOAD_CHAT] üîç DEBUG brain.user_context.workflow_params existe: {brain_workflow_params is not None and brain_workflow_params != {}}")
                    logger.info(f"[LOAD_CHAT] üîç DEBUG brain.user_context.workflow_params cl√©s: {list(brain_workflow_params.keys()) if brain_workflow_params else 'VIDE'}")
                else:
                    logger.warning(f"[LOAD_CHAT] ‚ö†Ô∏è brain.user_context est None apr√®s injection !")
                
                # Charger les donn√©es sp√©cifiques selon le mode
                if session.context.chat_mode == "onboarding_chat":
                    await brain.load_onboarding_data()
                elif session.context.chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                    # Pour ces modes, le job_id est le thread_key
                    job_id = thread_key
                    await brain.load_job_data(job_id)

                # üîç LOGS DE DIAGNOSTIC - V√©rifier donn√©es inject√©es au brain
                logger.info(f"[LOAD_CHAT] üìä Donn√©es permanentes inject√©es")
                logger.info(f"[LOAD_CHAT] üîç DIAGNOSTIC brain.jobs_data - Cl√©s: {list(brain.jobs_data.keys()) if brain.jobs_data else 'None'}")
                if brain.jobs_data and 'ROUTER' in brain.jobs_data:
                    router_count = len(brain.jobs_data['ROUTER'].get('unprocessed', []))
                    logger.info(f"[LOAD_CHAT] üîç DIAGNOSTIC brain ROUTER - {router_count} documents unprocessed inject√©s")
                else:
                    logger.warning(f"[LOAD_CHAT] ‚ö†Ô∏è DIAGNOSTIC brain - Pas de donn√©es ROUTER dans jobs_data !")
                
                logger.info(f"[LOAD_CHAT] üîç DIAGNOSTIC brain.jobs_metrics - "
                           f"ROUTER.to_process: {brain.jobs_metrics.get('ROUTER', {}).get('to_process', 'N/A') if brain.jobs_metrics else 'None'}")
                
                # ‚ïê‚ïê‚ïê Initialiser system prompt ‚ïê‚ïê‚ïê
                brain.initialize_system_prompt(
                    chat_mode=session.context.chat_mode,
                    jobs_metrics=session.jobs_metrics
                )
                
                logger.info(f"[LOAD_CHAT] üìù System prompt initialis√©")
                
                # ‚ïê‚ïê‚ïê Charger historique ‚ïê‚ïê‚ïê
                brain.pinnokio_agent.load_chat_history(history=history)

                if self._is_onboarding_like(session.context.chat_mode):
                    log_entries = await self._load_onboarding_log_history(
                        brain=brain,
                        collection_name=collection_name,
                        session=session,
                        thread_key=thread_key
                    )
                    await self._ensure_onboarding_listener(
                        session=session,
                        brain=brain,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        initial_entries=log_entries
                    )

                    # ‚ïê‚ïê‚ïê V√âRIFIER MODE INTERM√âDIATION AU CHARGEMENT ‚ïê‚ïê‚ïê
                    # ‚≠ê R√©cup√©rer le status depuis le brain qui vient d'√™tre charg√©
                    job_status = brain.job_data.get("status") if brain.job_data else None
                    await self._check_intermediation_on_load(
                        session=session,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        job_status=job_status
                    )

                logger.info(f"[LOAD_CHAT] üíæ Historique charg√©: {len(history)} messages")
                
                # ‚ïê‚ïê‚ïê Enregistrer le brain ‚ïê‚ïê‚ïê
                session.active_brains[thread_key] = brain
                session.last_activity[thread_key] = datetime.now(timezone.utc)
                
                logger.info(f"[LOAD_CHAT] üéâ Brain cr√©√© et pr√™t pour thread={thread_key}")
                
                return {
                    "success": True,
                    "status": "created",
                    "message": f"Nouveau brain cr√©√©: {len(history)} messages charg√©s",
                    "loaded_messages": len(history),
                    "thread_key": thread_key,
                    "active_brains_count": len(session.active_brains)
                }
                
        except Exception as e:
            logger.error(f"[LOAD_CHAT] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": f"√âchec du chargement: {str(e)}",
                "loaded_messages": 0
            }
    
    async def flush_chat_history(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str = None
        ) -> dict:
        """
        ‚≠ê NOUVELLE ARCHITECTURE: Flush = Fermer brain(s) et nettoyer
        
        Vide l'historique = Ferme le brain du thread et nettoie les ressources.
        ‚ö†Ô∏è IMPORTANT: Cette op√©ration est NON-BLOQUANTE et rapide.
        Les t√¢ches LPT en cours continuent en arri√®re-plan de mani√®re ind√©pendante.
        
        Args:
            user_id: ID Firebase de l'utilisateur
            collection_name: ID de la soci√©t√© (space_code)
            thread_key: Thread sp√©cifique √† fermer (optionnel)
                       - Si fourni: ferme uniquement ce thread
                       - Si None: ferme tous les threads de la session
            
        Returns:
            dict: {"success": bool, "message": str, "threads_cleared": int}
        """
        try:
            base_session_key = f"{user_id}:{collection_name}"
            
            logger.info(f"[FLUSH_CHAT] üóëÔ∏è Demande fermeture pour session={base_session_key}, thread={thread_key or 'TOUS'}")
            
            # R√©cup√©rer la session existante
            with self._lock:
                if base_session_key not in self.sessions:
                    return {
                        "success": False,
                        "error": "Session non trouv√©e",
                        "message": "Session LLM non initialis√©e."
                    }
                session = self.sessions[base_session_key]
            
            threads_cleared = 0
            
            if thread_key:
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                # FERMER UN SEUL THREAD
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                if thread_key in session.active_brains:
                    brain = session.active_brains[thread_key]
                    
                    logger.info(f"[FLUSH_CHAT] üîí Fermeture brain pour thread={thread_key}")
                    
                    # ‚ö†Ô∏è Note: Les t√¢ches LPT continuent en arri√®re-plan de mani√®re ind√©pendante
                    # On ne les attend pas car flush_chat_history doit √™tre rapide et non-bloquant
                    if brain.has_active_lpt_tasks(thread_key):
                        logger.info(f"[FLUSH_CHAT] ‚ö†Ô∏è T√¢ches LPT actives d√©tect√©es - elles continueront en arri√®re-plan (fermeture non-bloquante)")
                    
                    # Nettoyer le brain
                    try:
                        brain.pinnokio_agent.clear_chat_history()
                        logger.info(f"[FLUSH_CHAT] üßπ Historique brain vid√©")
                    except Exception as e:
                        logger.warning(f"[FLUSH_CHAT] Erreur nettoyage brain: {e}")
                    
                    # Supprimer le brain
                    del session.active_brains[thread_key]
                    if thread_key in session._brain_locks:
                        del session._brain_locks[thread_key]

                    self._stop_onboarding_listener(session, thread_key)
                    
                    # ‚ïê‚ïê‚ïê NETTOYER TOUS LES √âTATS DU THREAD ‚ïê‚ïê‚ïê
                    # Supprimer le mode d'interm√©diation
                    if thread_key in session.intermediation_mode:
                        del session.intermediation_mode[thread_key]
                    
                    # Supprimer les IDs trait√©s
                    if thread_key in session.onboarding_processed_ids:
                        del session.onboarding_processed_ids[thread_key]
                    
                    # Supprimer l'activit√©
                    if thread_key in session.last_activity:
                        del session.last_activity[thread_key]
                    
                    # Supprimer l'√©tat du thread
                    if thread_key in session.thread_states:
                        del session.thread_states[thread_key]
                    
                    # Supprimer le cache de contexte
                    if thread_key in session.thread_contexts:
                        del session.thread_contexts[thread_key]
                    
                    threads_cleared = 1
                    
                    logger.info(f"[FLUSH_CHAT] ‚úÖ Brain ferm√© et √©tats nettoy√©s pour thread={thread_key}")
                    
                    return {
                        "success": True,
                        "message": f"Brain ferm√© avec succ√®s pour thread {thread_key}",
                        "session_id": base_session_key,
                        "thread_key": thread_key,
                        "threads_cleared": threads_cleared,
                        "active_brains_remaining": len(session.active_brains)
                    }
                else:
                    logger.warning(f"[FLUSH_CHAT] ‚ö†Ô∏è Aucun brain actif trouv√© pour thread={thread_key}")
                    return {
                        "success": False,
                        "error": "Thread non trouv√©",
                        "message": f"Aucun brain actif pour thread {thread_key}",
                        "threads_cleared": 0
                    }
            else:
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                # FERMER TOUS LES THREADS
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                threads_count = len(session.active_brains)
                
                logger.info(f"[FLUSH_CHAT] üîí Fermeture de {threads_count} brains...")
                
                # Fermer tous les brains
                for t_key, brain in list(session.active_brains.items()):
                    try:
                        brain.pinnokio_agent.clear_chat_history()
                        logger.info(f"[FLUSH_CHAT] üßπ Brain thread={t_key} nettoy√©")
                    except Exception as e:
                        logger.warning(f"[FLUSH_CHAT] Erreur nettoyage brain {t_key}: {e}")
                
                # Tout vider
                session.active_brains.clear()
                session._brain_locks.clear()
                session.last_activity.clear()
                
                # ‚ïê‚ïê‚ïê NETTOYER TOUS LES √âTATS DE TOUS LES THREADS ‚ïê‚ïê‚ïê
                session.intermediation_mode.clear()
                session.onboarding_processed_ids.clear()
                session.thread_states.clear()
                session.thread_contexts.clear()

                self._stop_onboarding_listener(session)
                
                logger.info(f"[FLUSH_CHAT] ‚úÖ Tous les brains ferm√©s et √©tats nettoy√©s ({threads_count})")
                
                return {
                    "success": True,
                    "message": f"Tous les brains ferm√©s avec succ√®s",
                    "session_id": base_session_key,
                    "threads_cleared": threads_count
                }
                
        except Exception as e:
            logger.error(f"[FLUSH_CHAT] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": f"√âchec fermeture: {str(e)}",
                "threads_cleared": 0
            }
    
    async def stop_streaming(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str = None
        ) -> dict:
        """
        Arr√™te le streaming via WebSocket pour un thread sp√©cifique ou tous les threads.
        
        Args:
            user_id: ID de l'utilisateur
            collection_name: ID de la soci√©t√©
            thread_key: Thread sp√©cifique (optionnel, arr√™te tous si omis)
        """
        try:
            base_session_key = f"{user_id}:{collection_name}"
            
            logger.info(
                f"[STOP_STREAMING] üõë Demande re√ßue - "
                f"session={base_session_key}, thread={thread_key or 'ALL'}"
            )
            
            # Debug: Afficher les streams actifs avant l'arr√™t
            active_streams = await self.streaming_controller.get_active_streams(base_session_key)
            logger.info(
                f"[STOP_STREAMING] üìä Streams actifs pour cette session: "
                f"{list(active_streams.keys()) if active_streams else 'AUCUN'}"
            )
            
            if thread_key:
                # Arr√™ter un thread sp√©cifique
                logger.info(f"[STOP_STREAMING] üéØ Tentative d'arr√™t du thread: {thread_key}")
                success = await self.streaming_controller.stop_stream(base_session_key, thread_key)
                
                if success:
                    logger.info(
                        f"[STOP_STREAMING] ‚úÖ Stream arr√™t√© avec succ√®s - "
                        f"thread={thread_key}"
                    )
                    return {
                        "success": True,
                        "message": f"Stream arr√™t√© pour thread {thread_key}",
                        "thread_key": thread_key
                    }
                else:
                    logger.warning(
                        f"[STOP_STREAMING] ‚ö†Ô∏è Thread non trouv√© ou d√©j√† arr√™t√© - "
                        f"thread={thread_key}, active_streams={list(active_streams.keys())}"
                    )
                    return {
                        "success": False,
                        "error": "Thread non trouv√© ou d√©j√† arr√™t√©",
                        "message": f"Thread {thread_key} non trouv√© dans les streams actifs"
                    }
            else:
                # Arr√™ter tous les threads de la session
                logger.info(f"[STOP_STREAMING] üåê Arr√™t de TOUS les streams de la session")
                stopped_count = await self.streaming_controller.stop_all_streams(base_session_key)
                
                logger.info(
                    f"[STOP_STREAMING] ‚úÖ Tous les streams arr√™t√©s - "
                    f"count={stopped_count}"
                )
                return {
                    "success": True,
                    "message": f"Tous les streams arr√™t√©s ({stopped_count} threads)",
                    "stopped_count": stopped_count
                }
                
        except Exception as e:
            logger.error(f"[STOP_STREAMING] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec de l'arr√™t du streaming"
            }
    
    async def enter_chat(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        chat_mode: str = "general_chat",
        job_status: Optional[str] = None
        ) -> dict:
        """
        ‚≠ê NOUVEAU: Notifie que l'utilisateur ENTRE sur un thread de chat.
        Appel√© par Reflex via RPC quand user ouvre/entre sur un thread.

        Permet de capturer la pr√©sence AVANT l'envoi du premier message,
        ce qui active le mode UI pour le streaming et les notifications temps r√©el.

        Args:
            user_id: ID Firebase de l'utilisateur
            collection_name: ID de la soci√©t√©
            thread_key: Thread sur lequel l'utilisateur entre
            chat_mode: Mode de chat (default: "general_chat")
            job_status: Statut du job (optionnel) - "running", "in queue", "completed", etc.

        Returns:
            dict: {"success": bool, "message": str, "thread_key": str}
        """
        try:
            base_session_key = f"{user_id}:{collection_name}"
            
            logger.info(
                f"[ENTER_CHAT] üì• Signal re√ßu - "
                f"session={base_session_key}, thread_key={thread_key}"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : GARANTIR INITIALISATION SESSION
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            session = await self._ensure_session_initialized(
                user_id=user_id,
                collection_name=collection_name,
                chat_mode=chat_mode
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : MARQUER PR√âSENCE SUR LE THREAD
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # Si user est d√©j√† sur la page chat, c'est un changement de thread
            if session.is_on_chat_page and session.current_active_thread != thread_key:
                session.switch_thread(thread_key)
            else:
                # Premi√®re entr√©e sur la page chat
                session.enter_chat(thread_key)
            
            logger.info(
                f"[ENTER_CHAT] ‚úÖ User {user_id} marqu√© comme PR√âSENT sur chat - "
                f"thread_key={thread_key}, is_on_chat_page={session.is_on_chat_page}"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : CR√âER LE BRAIN POUR CE THREAD (pr√©-chargement)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if thread_key not in session.active_brains:
                logger.info(
                    f"[ENTER_CHAT] üß† Brain non trouv√© pour thread={thread_key}, "
                    f"cr√©ation et chargement historique..."
                )
                
                # Charger historique depuis RTDB
                history = await self._load_history_from_rtdb(collection_name, thread_key, session.context.chat_mode)
                
                # Cr√©er brain pour ce thread
                load_result = await self.load_chat_history(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    history=history
                )
                
                if not load_result.get("success"):
                    logger.error(f"[ENTER_CHAT] ‚ùå √âchec cr√©ation brain: {load_result}")
                    return {
                        "success": False,
                        "error": "Brain creation failed",
                        "message": f"Impossible de cr√©er le brain pour thread={thread_key}",
                        "details": load_result
                    }
                
                logger.info(f"[ENTER_CHAT] ‚úÖ Brain cr√©√© et historique charg√©")
            else:
                logger.info(f"[ENTER_CHAT] ‚úÖ Brain existant trouv√©")

            if self._is_onboarding_like(session.context.chat_mode):
                brain = session.active_brains.get(thread_key)
                if brain:
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    # ENTER_CHAT : Juste initialiser le brain et charger l'historique
                    # PAS de lancement LPT (r√©serv√© √† start_onboarding_chat)
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    # Charger les donn√©es selon le mode
                    if session.context.chat_mode == "onboarding_chat":
                        await brain.load_onboarding_data()
                    elif session.context.chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                        # Pour ces modes, le job_id est le thread_key
                        job_id = thread_key
                        await brain.load_job_data(job_id)
                    
                    # Charger l'historique des logs (pour injection dans contexte LLM)
                    log_entries = await self._load_onboarding_log_history(
                        brain=brain,
                        collection_name=collection_name,
                        session=session,
                        thread_key=thread_key
                    )
                    
                    # D√©marrer l'√©coute RTDB (pour suivre les logs m√©tier)
                    await self._ensure_onboarding_listener(
                        session=session,
                        brain=brain,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        initial_entries=log_entries
                    )
                    
                    # ‚≠ê NOUVEAU : V√©rifier mode interm√©diation au chargement
                    # Permet de r√©activer le mode si dernier message √©tait TOOL/CARD/FOLLOW_MESSAGE
                    # ‚≠ê R√©cup√©rer le status depuis le brain qui vient d'√™tre charg√©
                    job_status_from_brain = brain.job_data.get("status") if brain.job_data else None
                    await self._check_intermediation_on_load(
                        session=session,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        job_status=job_status_from_brain or job_status  # Utiliser brain d'abord, sinon param√®tre
                    )
                    
                    logger.info(
                        f"[ENTER_CHAT] ‚úÖ Brain initialis√© pour mode onboarding-like - "
                        f"thread={thread_key}, job_id={brain.onboarding_data.get('job_id') if brain.onboarding_data else None}"
                    )
            
            return {
                "success": True,
                "message": "User marked as entered chat, brain ready",
                "thread_key": thread_key,
                "is_on_chat_page": session.is_on_chat_page,
                "current_active_thread": session.current_active_thread,
                "session_key": base_session_key,
                "brain_ready": True
            }
            
        except Exception as e:
            logger.error(f"[ENTER_CHAT] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec du traitement enter_chat"
            }
    
    async def leave_chat(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str = None
        ) -> dict:
        """
        Notifie que l'utilisateur quitte la page chat.
        Appel√© par Reflex via RPC quand user ferme l'onglet ou change de module.
        
        ‚≠ê IMPORTANT: thread_key n'est pas utilis√© car on veut juste marquer
        que l'utilisateur n'est plus sur la page (ind√©pendamment du thread).
        
        Args:
            user_id: ID Firebase de l'utilisateur
            collection_name: ID de la soci√©t√©
            thread_key: Thread actuel (optionnel, non utilis√©)
            
        Returns:
            dict: {"success": bool, "message": str, "was_on_thread": str}
        """
        try:
            base_session_key = f"{user_id}:{collection_name}"
            
            logger.info(
                f"[LEAVE_CHAT] üì• Signal re√ßu - "
                f"session={base_session_key}, thread_key={thread_key}"
            )
            
            # V√©rifier si session existe
            with self._lock:
                if base_session_key not in self.sessions:
                    logger.warning(
                        f"[LEAVE_CHAT] ‚ö†Ô∏è Session non trouv√©e: {base_session_key}"
                    )
                    return {
                        "success": False,
                        "error": "Session not found",
                        "message": "Session LLM non trouv√©e (peut-√™tre d√©j√† ferm√©e)"
                    }
                
                session = self.sessions[base_session_key]
            
            # Sauvegarder l'√©tat avant modification (pour log)
            was_on_chat_page = session.is_on_chat_page
            was_on_thread = session.current_active_thread
            
            # Marquer user comme absent de la page chat
            session.leave_chat()
            
            logger.info(
                f"[LEAVE_CHAT] ‚úÖ User {user_id} marqu√© comme HORS chat - "
                f"was_on_chat_page={was_on_chat_page}, "
                f"was_on_thread={was_on_thread}"
            )
            
            return {
                "success": True,
                "message": "User marked as left chat",
                "was_on_chat_page": was_on_chat_page,
                "was_on_thread": was_on_thread,
                "session_key": base_session_key
            }
            
        except Exception as e:
            logger.error(f"[LEAVE_CHAT] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "√âchec du traitement leave_chat"
            }
    
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # PINNOKIO AGENTIC WORKFLOW
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # EX√âCUTION DES T√ÇCHES PLANIFI√âES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _execute_scheduled_task(
        self,
        user_id: str,
        company_id: str,
        task_data: dict,
        thread_key: str,
        execution_id: str
        ):
        """
        Ex√©cute une t√¢che planifi√©e.

        Workflow:
            1. Initialiser session/brain (comme send_message)
            2. Charger le mission_plan
            3. Construire system prompt sp√©cifique t√¢che
            4. Ex√©cuter le workflow avec l'agent
            5. L'agent cr√©era la checklist via CREATE_CHECKLIST
            6. L'agent mettra √† jour les √©tapes via UPDATE_STEP
            7. G√©rer les LPT (attente callback)
            8. Finaliser l'ex√©cution via TERMINATE_TASK
        """
        t0 = time.time()
        task_id = task_data["task_id"]
        mission = task_data["mission"]
        mandate_path = task_data["mandate_path"]

        logger.info(
            f"[TASK_EXEC] D√©but: task_id={task_id}, thread={thread_key}, "
            f"execution_id={execution_id}"
        )

        try:
            # 1. Initialiser la session
            session = await self._ensure_session_initialized(
                user_id=user_id,
                collection_name=company_id,
                chat_mode="task_execution"
            )

            # 2. R√©cup√©rer ou cr√©er le brain pour ce thread
            if thread_key not in session.active_brains:
                logger.info(
                    f"[TASK_EXEC] Cr√©ation brain pour thread de t√¢che: {thread_key}"
                )

                # Cr√©er le brain directement (pas de chat history pour t√¢ches automatiques)
                from ..pinnokio_agentic_workflow.orchestrator.pinnokio_brain import PinnokioBrain

                # Cr√©er lock pour ce thread
                if thread_key not in session._brain_locks:
                    session._brain_locks[thread_key] = asyncio.Lock()

                async with session._brain_locks[thread_key]:
                    # Double-check apr√®s le lock
                    if thread_key in session.active_brains:
                        logger.info(f"[TASK_EXEC] Brain cr√©√© par autre t√¢che, r√©utilisation")
                    else:
                        # Cr√©er le brain
                        brain = PinnokioBrain(
                            collection_name=company_id,
                            firebase_user_id=user_id,
                            dms_system=session.context.dms_system,
                            dms_mode=session.context.dms_mode
                        )

                        logger.info(f"[TASK_EXEC] ü§ñ Cr√©ation agents du brain...")

                        # Cr√©er les agents du brain
                        await brain.initialize_agents()

                        logger.info(f"[TASK_EXEC] ‚úÖ Agents cr√©√©s")

                        # Injecter donn√©es permanentes (depuis session)
                        brain.user_context = session.user_context
                        brain.jobs_data = session.jobs_data
                        brain.jobs_metrics = session.jobs_metrics

                        logger.info(f"[TASK_EXEC] üìä Donn√©es permanentes inject√©es")

                        # Initialiser system prompt
                        brain.initialize_system_prompt(
                            chat_mode="task_execution",
                            jobs_metrics=session.jobs_metrics
                        )

                        logger.info(f"[TASK_EXEC] üìù System prompt initialis√©")

                        # ‚ö†Ô∏è PAS de load_chat_history - Les t√¢ches automatiques n'ont pas d'historique

                        # Enregistrer le brain
                        session.active_brains[thread_key] = brain
                        session.last_activity[thread_key] = datetime.now(timezone.utc)

                        logger.info(f"[TASK_EXEC] üéâ Brain cr√©√© et pr√™t (sans historique)")

            brain = session.active_brains.get(thread_key)

            if not brain:
                raise Exception(f"Brain non trouv√© pour thread: {thread_key}")

            logger.info(f"[TASK_EXEC] Brain actif r√©cup√©r√© pour thread: {thread_key}")

            # 4. Stocker les infos de la t√¢che dans le brain
            brain.active_task_data = {
                "task_id": task_id,
                "execution_id": execution_id,
                "mission": mission,
                "mandate_path": mandate_path,
                "execution_plan": task_data.get("execution_plan"),
                "last_execution_report": task_data.get("last_execution_report")
            }

            # 5. Construire le system prompt sp√©cifique (extension du prompt principal)
            task_specific_addition = self._build_task_execution_addition(
                mission=mission,
                last_report=task_data.get("last_execution_report"),
                execution_plan=task_data.get("execution_plan")
            )

            # Combiner avec le system prompt principal
            base_prompt = brain.pinnokio_agent.system_prompt if brain.pinnokio_agent else ""
            task_specific_prompt = f"{base_prompt}\n\n{task_specific_addition}"

            # 5. Construire le message initial
            # Mapping textuel pour le message initial
            mode_mapping = {
                "ON_DEMAND": "Action manuelle de l'utilisateur",
                "SCHEDULED": "Ex√©cution r√©currente planifi√©e",
                "ONE_TIME": "Ex√©cution unique programm√©e",
                "NOW": "Ex√©cution imm√©diate"
            }
            mode_text = mode_mapping.get(task_data.get("execution_plan"), task_data.get("execution_plan", "Mode automatique"))

            initial_message = f"""üéØ **Ex√©cution Automatique de T√¢che**

                **Titre** : {mission['title']}
                **Description** : {mission['description']}
                **Mode d'ex√©cution** : {mode_text}

                **Plan d'Action** :
                {mission['plan']}

                **Instructions** :
                1. Cr√©er la workflow checklist avec CREATE_CHECKLIST
                2. Ex√©cuter le plan d'action √©tape par √©tape
                3. Mettre √† jour chaque √©tape avec UPDATE_STEP
                4. Finaliser avec TERMINATE_TASK

                Commence maintenant l'ex√©cution."""

            # 6. D√©terminer mode (UI/BACKEND)
            from ..registry.unified_registry import get_unified_registry
            registry = get_unified_registry()
            user_connected = registry.is_user_connected(user_id)

            mode = "UI" if user_connected else "BACKEND"

            logger.info(f"[TASK_EXEC] D√©marrage workflow - mode={mode}")

            # 7. Pr√©parer assistant_message_id
            assistant_message_id = f"task_{execution_id}"
            assistant_timestamp = datetime.now(timezone.utc).isoformat()

            # 8. Ex√©cuter le workflow
            await self._process_unified_workflow(
                session=session,
                user_id=user_id,
                collection_name=company_id,
                thread_key=thread_key,
                message=initial_message,
                assistant_message_id=assistant_message_id,
                assistant_timestamp=assistant_timestamp,
                enable_streaming=user_connected,
                chat_mode="task_execution",
                system_prompt=task_specific_prompt
            )

            dt_ms = int((time.time() - t0) * 1000)
            logger.info(f"[TASK_EXEC] Termin√©: task_id={task_id}, dt_ms={dt_ms}")

        except Exception as e:
            dt_ms = int((time.time() - t0) * 1000)
            logger.error(
                f"[TASK_EXEC] Erreur: task_id={task_id}, error={repr(e)}",
                exc_info=True
            )

            # Marquer l'ex√©cution comme √©chou√©e
            try:
                from ..firebase_providers import get_firebase_management
                fbm = get_firebase_management()

                # Cr√©er rapport d'√©chec
                error_report = {
                    "execution_id": execution_id,
                    "executed_at": datetime.now(timezone.utc).isoformat(),
                    "duration_seconds": int(time.time() - t0),
                    "status": "failed",
                    "summary": f"Erreur d'ex√©cution: {str(e)}",
                    "errors": [str(e)]
                }

                # Finaliser l'ex√©cution
                fbm.complete_task_execution(
                    mandate_path, task_id, execution_id, error_report
                )
            except:
                pass

    def _build_task_execution_addition(self, mission: dict, last_report: Optional[dict], execution_plan: str = None) -> str:
        """
        Construit l'ADDITION au system prompt principal pour l'ex√©cution d'une t√¢che.
        Cette section s'ajoute au prompt principal existant.

        Args:
            mission: Dictionnaire de la mission
            last_report: Rapport de la derni√®re ex√©cution (optionnel)
            execution_plan: Mode d'ex√©cution (ON_DEMAND, SCHEDULED, NOW, etc.)
        """

        # Mapping textuel des modes d'ex√©cution
        mode_mapping = {
            "ON_DEMAND": "Cette t√¢che est param√©tr√©e pour √™tre effectu√©e par une action manuelle de l'utilisateur",
            "SCHEDULED": "Cette t√¢che a une r√©currence planifi√©e et s'ex√©cute automatiquement selon le calendrier d√©fini",
            "ONE_TIME": "Cette t√¢che est programm√©e pour s'ex√©cuter une seule fois √† une date et heure pr√©cise",
            "NOW": "Cette t√¢che doit √™tre ex√©cut√©e imm√©diatement sans attendre de planification"
        }

        mode_description = mode_mapping.get(execution_plan, f"Mode d'ex√©cution: {execution_plan}")

        prompt = f"""
            ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            üéØ MODE EX√âCUTION AUTOMATIQUE DE T√ÇCHE
            ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            Vous ex√©cutez une t√¢che planifi√©e de mani√®re autonome (pas d'interaction utilisateur).

            **MISSION** : {mission['title']}
            **DESCRIPTION** : {mission['description']}

            **MODE D'EX√âCUTION** : {mode_description}

            **PLAN D'ACTION** :
            {mission['plan']}
            """

        # Ajouter le rapport de la derni√®re ex√©cution si disponible
        if last_report:
            prompt += f"""
                üìä **DERNI√àRE EX√âCUTION** ({last_report.get('executed_at')}) :
                - Statut : {last_report.get('status')}
                - R√©sum√© : {last_report.get('summary')}
                """
            if last_report.get('warnings'):
                prompt += "- ‚ö†Ô∏è Warnings : " + ", ".join(last_report['warnings']) + "\n"
            if last_report.get('errors'):
                prompt += "- ‚ùå Erreurs : " + ", ".join(last_report['errors']) + "\n"

        prompt += """
                üìã **WORKFLOW OBLIGATOIRE** :

                1. **CREATE_CHECKLIST** au d√©but (√©tapes bas√©es sur le plan)
                2. Pour chaque √©tape :
                - **UPDATE_STEP** status="in_progress" avant de commencer
                - Ex√©cuter l'outil ou l'action
                - **UPDATE_STEP** status="completed" (ou "error")
                3. **TERMINATE_TASK** √† la fin avec rapport d√©taill√©

                üîß **Outils disponibles** : CREATE_CHECKLIST, UPDATE_STEP + tous vos outils habituels
                ‚ö° **Autonomie** : Prenez des d√©cisions bas√©es sur le plan et les r√©sultats

                Commencez maintenant l'ex√©cution.
                ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                """

        return prompt

    async def _finalize_task_execution_if_needed(self, brain, terminate_kwargs: dict):
        """
        Finalise l'ex√©cution d'une t√¢che si on est en mode task_execution.

        Steps:
            1. V√©rifier si brain.active_task_data existe
            2. R√©cup√©rer l'ex√©cution depuis Firebase
            3. Construire le rapport final
            4. Appeler firebase.complete_task_execution()
        """
        try:
            # V√©rifier si on est en mode t√¢che
            if not hasattr(brain, 'active_task_data') or not brain.active_task_data:
                logger.debug("[FINALIZE_TASK] Pas en mode t√¢che, skip")
                return

            task_id = brain.active_task_data["task_id"]
            execution_id = brain.active_task_data["execution_id"]
            mandate_path = brain.active_task_data["mandate_path"]
            execution_plan = brain.active_task_data.get("execution_plan")

            # NOW ou t√¢ches non stock√©es : PAS stock√© (√©ph√©m√®re), ne pas finaliser dans Firebase
            stored_in_firebase = brain.active_task_data.get("stored_in_firebase", True)
            if execution_plan == "NOW" or not stored_in_firebase:
                logger.info(f"[FINALIZE_TASK] T√¢che {execution_plan} {task_id} - pas de finalisation Firebase (non stock√©e)")
                return

            logger.info(f"[FINALIZE_TASK] Finalisation t√¢che: {task_id}, execution: {execution_id}")

            # R√©cup√©rer l'ex√©cution
            from ..firebase_providers import get_firebase_management
            fbm = get_firebase_management()

            execution = fbm.get_task_execution(mandate_path, task_id, execution_id)

            if not execution:
                logger.error(f"[FINALIZE_TASK] Ex√©cution {execution_id} non trouv√©e")
                return

            # Calculer dur√©e
            from dateutil import parser
            started_at = parser.isoparse(execution["started_at"])
            duration_seconds = int((datetime.now(timezone.utc) - started_at).total_seconds())

            # Extraire checklist
            checklist = execution.get("workflow_checklist", {})
            steps = checklist.get("steps", [])

            steps_completed = sum(1 for s in steps if s.get("status") == "completed")
            steps_total = len(steps)

            errors = [s.get("message") for s in steps if s.get("status") == "error"]

            # D√©terminer status global
            if steps_completed == steps_total and not errors:
                status = "completed"
            elif errors:
                status = "failed"
            else:
                status = "partial"

            # Extraire infos LPT
            lpt_executions = []
            for lpt_id, lpt_data in execution.get("lpt_tasks", {}).items():
                lpt_executions.append({
                    "lpt_type": lpt_data.get("task_type"),
                    "status": lpt_data.get("status"),
                    "summary": lpt_data.get("result", {}).get("summary", "")
                })

            # Construire rapport final
            final_report = {
                "execution_id": execution_id,
                "executed_at": execution["started_at"],
                "duration_seconds": duration_seconds,
                "status": status,
                "steps_completed": steps_completed,
                "steps_total": steps_total,
                "summary": terminate_kwargs.get("conclusion", "Ex√©cution termin√©e"),
                "errors": errors,
                "warnings": [],  # √Ä extraire si n√©cessaire
                "lpt_executions": lpt_executions
            }

            # Finaliser (sauvegarde rapport + suppression execution)
            fbm.complete_task_execution(
                mandate_path, task_id, execution_id, final_report
            )

            logger.info(
                f"[FINALIZE_TASK] T√¢che finalis√©e: {task_id}, status={status}, "
                f"steps={steps_completed}/{steps_total}, duration={duration_seconds}s"
            )

        except Exception as e:
            logger.error(f"[FINALIZE_TASK] Erreur: {e}", exc_info=True)

    async def _ensure_onboarding_listener(
        self,
        session: LLMSession,
        brain,
        collection_name: str,
        thread_key: str,
        initial_entries: Optional[List[str]] = None
        ) -> None:
        """D√©marre l'√©coute RTDB follow-up pour les chats d'onboarding."""

        existing_listener = session.onboarding_listeners.get(thread_key)
        initial_processed_ids = session.onboarding_processed_ids.get(thread_key)
        if initial_processed_ids is None:
            initial_processed_ids = set()
            session.onboarding_processed_ids[thread_key] = initial_processed_ids

        if existing_listener:
            if initial_entries is not None:
                existing_listener["log_entries"] = list(initial_entries)
            existing_listener.setdefault("processed_message_ids", initial_processed_ids)
            return

        # R√©cup√©rer job_id selon le mode
        job_id = None
        if session.context.chat_mode == "onboarding_chat":
            onboarding_data = brain.onboarding_data or await brain.load_onboarding_data()
            job_id = (onboarding_data or {}).get("job_id")
        elif session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
            # Pour ces modes, charger job_data et utiliser thread_key comme job_id
            job_id = thread_key
            await brain.load_job_data(job_id)
        
        # ‚≠ê CORRECTION: Pour les modes onboarding-like (apbookeeper_chat, router_chat, banker_chat), 
        # le thread_key est le job_id (fallback si job_id non trouv√©)
        if not job_id and session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
            # Le thread_key qui commence par 'klk_' est directement le job_id
            if thread_key.startswith("klk_"):
                job_id = thread_key
                logger.info(
                    f"[ONBOARDING_LISTENER] üîß Utilisation thread_key comme job_id pour {session.context.chat_mode}: {job_id}"
                )
            else:
                # Fallback: utiliser le thread_key m√™me s'il ne commence pas par klk_
                job_id = thread_key
                logger.info(
                    f"[ONBOARDING_LISTENER] üîß Utilisation thread_key comme job_id (fallback) pour {session.context.chat_mode}: {job_id}"
                )

        if not job_id:
            logger.warning(
                f"[ONBOARDING_LISTENER] job_id manquant pour thread={thread_key}, √©coute non d√©marr√©e"
            )
            return

        follow_thread = f"follow_{job_id}"

        try:
            from ..firebase_providers import get_firebase_realtime

            rtdb = get_firebase_realtime()

            # S'assurer que la boucle d√©di√©e est pr√™te pour les callbacks
            session.ensure_callback_loop()

            async def _callback(message: Dict[str, Any]) -> None:
                logger.info(
                    f"[ONBOARDING_LISTENER] üì® Message re√ßu depuis application m√©tier - "
                    f"job_id={job_id} thread={thread_key} message_id={message.get('id', 'N/A')} "
                    f"content_preview={str(message.get('content', message.get('message', '')))[:100]}"
                )
                await self._handle_onboarding_log_event(
                    session=session,
                    brain=brain,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    follow_thread_key=follow_thread,  # ‚ö†Ô∏è Conserv√© pour compatibilit√© mais non utilis√©
                    message=message
                )

            # ‚≠ê MODIFI√â: √âcoute sur job_chats/{job_id} o√π l'application m√©tier publie ses logs
            # (pas sur chats/ qui est r√©serv√© aux conversations agent-utilisateur)
            listener_path = f"{collection_name}/job_chats/{job_id}/messages"
            logger.info(
                f"[ONBOARDING_LISTENER] üîç Configuration √©coute m√©tier - "
                f"space={collection_name} job_id={job_id} mode=job_chats path={listener_path}"
            )
            
            listener = await rtdb.listen_realtime_channel(
                space_code=collection_name,
                thread_key=job_id,
                callback=_callback,
                mode='job_chats',  # ‚≠ê job_chats pour les logs m√©tier
                scheduler=session.schedule_coroutine
            )

            session.onboarding_listeners[thread_key] = {
                "listener": listener,
                "job_id": job_id,
                "follow_thread": follow_thread,
                "log_entries": list(initial_entries) if initial_entries else [],
                "processed_message_ids": initial_processed_ids
            }

            logger.info(
                f"[ONBOARDING_LISTENER] ‚úÖ √âcoute d√©marr√©e pour job_id={job_id} thread={thread_key} "
                f"- √âcoute sur: {listener_path}"
            )

        except Exception as e:
            logger.error(
                f"[ONBOARDING_LISTENER] ‚ùå √âchec d√©marrage √©coute pour job_id={job_id}: {e}",
                exc_info=True
            )

    async def _load_onboarding_log_history(
        self,
        brain,
        collection_name: str,
        session: LLMSession,
        thread_key: str
        ) -> List[str]:
        """Charge les logs onboarding depuis le RTDB m√©tier et les injecte dans l'agent."""

        # R√©cup√©rer job_id selon le mode
        job_id = None
        if session.context.chat_mode == "onboarding_chat":
            job_id = (brain.onboarding_data or {}).get("job_id") if brain.onboarding_data else None
        elif session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
            # Pour ces modes, utiliser thread_key comme job_id
            job_id = thread_key
        
        # ‚≠ê CORRECTION: Pour les modes onboarding-like (apbookeeper_chat, router_chat, banker_chat),
        # le thread_key est le job_id (fallback si job_id non trouv√©)
        if not job_id and session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
            # Le thread_key qui commence par 'klk_' est directement le job_id
            if thread_key.startswith("klk_"):
                job_id = thread_key
                logger.info(
                    f"[ONBOARDING_LOG] üîß Utilisation thread_key comme job_id pour {session.context.chat_mode}: {job_id}"
                )
            else:
                # Fallback: utiliser le thread_key m√™me s'il ne commence pas par klk_
                job_id = thread_key
                logger.info(
                    f"[ONBOARDING_LOG] üîß Utilisation thread_key comme job_id (fallback) pour {session.context.chat_mode}: {job_id}"
                )
        
        if not job_id:
            logger.debug("[ONBOARDING_LOG] job_id manquant pour chargement historique")
            return []

        job_messages_path = f"{collection_name}/job_chats/{job_id}/messages"
        logger.info(
            f"[ONBOARDING_LOG] üìñ Chargement historique depuis job_chats - "
            f"thread={thread_key} job_id={job_id} path={job_messages_path}"
        )

        try:
            from ..firebase_providers import get_firebase_realtime

            rtdb = get_firebase_realtime()

            def _fetch_existing():
                ref = rtdb.db.child(job_messages_path)
                return ref.get()

            data = await asyncio.to_thread(_fetch_existing)

            if not data or not isinstance(data, dict):
                logger.info(
                    f"[ONBOARDING_LOG] ‚ÑπÔ∏è Aucun historique trouv√© c√¥t√© m√©tier - "
                    f"thread={thread_key} job_id={job_id}"
                )
                return []

            messages: List[Dict[str, Any]] = []
            for message_id, payload in data.items():
                if not isinstance(payload, dict):
                    continue
                payload_with_id = dict(payload)
                payload_with_id.setdefault("id", message_id)
                messages.append(payload_with_id)

            if not messages:
                logger.info(
                    f"[ONBOARDING_LOG] ‚ÑπÔ∏è Aucun message exploitable c√¥t√© m√©tier - "
                    f"thread={thread_key} job_id={job_id}"
                )
                return []

            def _sort_key(msg: Dict[str, Any]) -> float:
                ts = msg.get("timestamp")
                if ts is None:
                    return 0.0
                try:
                    if isinstance(ts, str):
                        return datetime.fromisoformat(ts.replace('Z', '+00:00')).timestamp()
                    return float(ts)
                except (ValueError, TypeError):
                    return 0.0

            messages.sort(key=_sort_key)

            log_entries: List[str] = []
            processed_ids: Set[str] = set()
            last_timestamp = datetime.now(timezone.utc)

            for msg in messages:
                msg_type = msg.get('message_type') or msg.get('type') or 'MESSAGE'
                if msg_type != 'MESSAGE':
                    continue

                log_text, timestamp_obj = self._format_onboarding_log_entry(msg)
                log_entries.append(log_text)
                last_timestamp = timestamp_obj

                message_id = msg.get("id") or msg.get("message_id")
                if message_id:
                    processed_ids.add(message_id)

            if not log_entries:
                logger.info(
                    f"[ONBOARDING_LOG] ‚ÑπÔ∏è Aucun log MESSAGE trouv√© c√¥t√© m√©tier - "
                    f"thread={thread_key} job_id={job_id}"
                )
                return []

            combined_text = "\n".join(log_entries)
            logger.info(
                f"[ONBOARDING_LOG] ‚úÖ Historique m√©tier charg√© - "
                f"thread={thread_key} job_id={job_id} entries_count={len(log_entries)}"
            )

            if brain and getattr(brain, 'pinnokio_agent', None):
                brain.pinnokio_agent.append_system_log(
                    message_id=job_id,
                    timestamp=last_timestamp.isoformat(),
                    payload=combined_text
                )
                logger.info(
                    f"[ONBOARDING_LOG] ‚úÖ Logs inject√©s dans brain agent - "
                    f"thread={thread_key} job_id={job_id}"
                )

            session.onboarding_processed_ids[thread_key] = processed_ids

            listener_info = session.onboarding_listeners.get(thread_key)
            if listener_info is not None:
                listener_info["log_entries"] = list(log_entries)
                listener_info["processed_message_ids"] = processed_ids
                session.onboarding_listeners[thread_key] = listener_info

            return log_entries

        except Exception as e:
            logger.error(f"[ONBOARDING_LOG] ‚ùå Erreur chargement historique: {e}", exc_info=True)
            return []

    async def _start_intermediation_mode(
        self,
        session: LLMSession,
        user_id: str,
        collection_name: str,
        thread_key: str,
        message: Dict[str, Any],
        job_id: Optional[str] = None
    ) -> None:
        """
        D√©marre le mode interm√©diation pour un thread donn√©.

        Actions:
        1. Active le flag intermediation_mode dans la session
        2. Envoie un message syst√®me au frontend (visible, mais NON sauv√© en RTDB)
        3. Envoie un signal RPC au frontend pour notifier le d√©marrage

        Args:
            session: Session LLM active
            user_id: ID Firebase utilisateur
            collection_name: ID soci√©t√©
            thread_key: Cl√© du thread
            message: Message RTDB qui a d√©clench√© l'interm√©diation
            job_id: ID du job (optionnel)
        """
        try:
            from ..ws_hub import hub

            # ‚ïê‚ïê‚ïê 0. V√âRIFIER SI D√âJ√Ä ACTIF (√©viter double activation) ‚ïê‚ïê‚ïê
            already_active = session.intermediation_mode.get(thread_key, False)
            if already_active:
                logger.info(
                    f"[INTERMEDIATION] ‚è≠Ô∏è Mode D√âJ√Ä actif - thread={thread_key} - "
                    f"Ignorer r√©activation (√©viter doublons)"
                )
                return False  # Retourner False pour indiquer que le mode n'a pas √©t√© activ√©

            # ‚ïê‚ïê‚ïê 1. ACTIVER LE FLAG INTERM√âDIATION ‚ïê‚ïê‚ïê
            session.intermediation_mode[thread_key] = True

            # ‚ïê‚ïê‚ïê 2. EXTRAIRE LES OUTILS DISPONIBLES ‚ïê‚ïê‚ïê
            # Les outils peuvent √™tre fournis dans 2 formats:
            # - Format Anthropic (CARD/FOLLOW_MESSAGE): [{"name": "TOOL_X", "description": "...", "input_schema": {...}}, ...]
            # - Format simple (TOOL): {"content": {"tool_list": ["TOOL_1", "TOOL_2"]}}
            tools_config_anthropic = message.get("tools_config") or message.get("tools") or []

            # ‚≠ê EXTRAIRE UNIQUEMENT LES NOMS DES OUTILS (comme send_tools_list le fait)
            # Le frontend chargera les d√©tails depuis config_tools.json
            tool_names = []
            
            # V√©rifier si c'est un message TOOL avec format simple
            # Le tool_list peut √™tre dans "content" ou √† la racine du message
            tool_list_simple = None
            
            # Chercher d'abord √† la racine (format le plus courant)
            if "tool_list" in message:
                tool_list_simple = message.get("tool_list")
                logger.debug(f"[INTERMEDIATION] tool_list trouv√© √† la racine du message")
            # Sinon chercher dans content
            else:
                message_content = message.get("content", {})
                # ‚≠ê PARSER LE JSON SI CONTENT EST UNE STRING (format TOOL depuis send_tools_list)
                if isinstance(message_content, str):
                    try:
                        import json
                        message_content = json.loads(message_content)
                        logger.debug(f"[INTERMEDIATION] content JSON pars√© avec succ√®s")
                    except (json.JSONDecodeError, TypeError) as e:
                        logger.warning(f"[INTERMEDIATION] ‚ö†Ô∏è Erreur parsing JSON content: {e}")
                        message_content = {}
                
                if isinstance(message_content, dict):
                    tool_list_simple = message_content.get("tool_list")
                    if tool_list_simple:
                        logger.debug(f"[INTERMEDIATION] tool_list trouv√© dans content")
            
            if tool_list_simple:
                # Format simple : liste de strings ["TOOL_1", "TOOL_2"]
                tool_names = tool_list_simple if isinstance(tool_list_simple, list) else []
                logger.info(
                    f"[INTERMEDIATION] üîß Outils extraits du format simple (TOOL) - "
                    f"count={len(tool_names)} tools={tool_names}"
                )
            
            # Sinon, utiliser le format Anthropic (CARD/FOLLOW_MESSAGE)
            if not tool_names and tools_config_anthropic:
                if isinstance(tools_config_anthropic, list):
                    # Format Anthropic (liste de dicts avec "name")
                    tool_names = [tool.get("name") for tool in tools_config_anthropic if isinstance(tool, dict) and "name" in tool]
                    logger.info(
                        f"[INTERMEDIATION] üîß Outils extraits du format Anthropic (CARD/FOLLOW_MESSAGE) - "
                        f"count={len(tool_names)} tools={tool_names}"
                    )

            # Construire la liste des outils format√©e pour l'affichage dans le message syst√®me
            tools_list_text = ""
            if tool_names:
                tools_list_text = "\n\n**Available tools:**\n"
                # Si format Anthropic, utiliser les descriptions fournies
                if tools_config_anthropic:
                    for tool_anthropic in tools_config_anthropic:
                        if isinstance(tool_anthropic, dict):
                            tool_name = tool_anthropic.get("name", "Unknown")
                            tool_desc = tool_anthropic.get("description", "")
                            tools_list_text += f"- **{tool_name}**: {tool_desc}\n"
                else:
                    # Si format simple, juste lister les noms
                    for tool_name in tool_names:
                        tools_list_text += f"- **{tool_name}**\n"

            # ‚ïê‚ïê‚ïê 3. ENVOYER MESSAGE SYST√àME AU FRONTEND (VISIBLE, NON SAUV√â RTDB) ‚ïê‚ïê‚ïê
            system_message_content = f"""üîÑ **Intermediation Mode Activated**

You are now in direct communication with the business application. Messages will be processed by the business system and not by the main agent.
{tools_list_text}
You can use the keywords **TERMINATE**, **PENDING**, or **NEXT** to close this mode, or click on a card if available."""

            # Envoyer via WebSocket comme message syst√®me (pas de sauvegarde RTDB)
            system_message_payload = {
                "type": "SYSTEM_MESSAGE_INTERMEDIATION",
                "thread_key": thread_key,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "message_id": str(uuid.uuid4()),
                "content": system_message_content,
                "system_type": "intermediation_start",
                "title": "Intermediation Mode",
                "from_intermediation": True,
                "tool_names": tool_names  # ‚≠ê Juste les noms, pas le format Anthropic complet
            }

            ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
            
            # ‚ïê‚ïê‚ïê 4. ENVOYER SIGNAL RPC AU FRONTEND ‚ïê‚ïê‚ïê
            # Signal pour que le frontend active l'√©tat intermediation_active
            # ‚≠ê On envoie juste les noms des outils (tool_names) comme le fait send_tools_list()
            # Le frontend chargera les d√©tails depuis config_tools.json
            rpc_signal = {
                "type": "RPC_INTERMEDIATION_STATE",
                "channel": ws_channel,
                "payload": {
                    "action": "start",
                    "thread_key": thread_key,
                    "job_id": job_id,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "tool_names": tool_names  # ‚≠ê Liste de strings ["TOOL_1", "TOOL_2"]
                }
            }

            # ‚ïê‚ïê‚ïê 5. ENVOYER MESSAGES VIA WEBSOCKET ‚ïê‚ïê‚ïê
            # ‚≠ê NOUVEAU : Envoyer directement comme les CARDs (pas de v√©rification listener)
            # Le hub.broadcast g√®re automatiquement les WebSockets connect√©s.
            # Si le WebSocket n'est pas connect√©, le message est simplement ignor√© (comportement identique aux CARDs).
            
            try:
                # Envoyer le message syst√®me
                await hub.broadcast(user_id, {
                    "type": "SYSTEM_MESSAGE_INTERMEDIATION",
                    "channel": ws_channel,
                    "payload": system_message_payload
                })
                
                # Envoyer le signal RPC
                await hub.broadcast(user_id, rpc_signal)
                
                logger.info(
                    f"[INTERMEDIATION] üì° Messages syst√®me envoy√©s via WebSocket - "
                    f"thread={thread_key} (comportement identique aux CARDs)"
                )
            except Exception as e:
                logger.warning(
                    f"[INTERMEDIATION] ‚ö†Ô∏è Erreur envoi WebSocket (ignor√©e) - "
                    f"thread={thread_key} error={e}"
                )

            logger.info(
                f"[INTERMEDIATION] üîÑ Mode activ√© avec message syst√®me - "
                f"thread={thread_key} job_id={job_id} tools_count={len(tool_names)}"
            )
            
            return True  # Retourner True pour indiquer que le mode a √©t√© activ√©

        except Exception as e:
            logger.error(
                f"[INTERMEDIATION] ‚ùå Erreur d√©marrage mode interm√©diation: {e}",
                exc_info=True
            )
            return False  # Retourner False en cas d'erreur

    async def _stop_intermediation_mode(
        self,
        session: LLMSession,
        user_id: str,
        collection_name: str,
        thread_key: str,
        job_id: Optional[str] = None,
        reason: str = "user_action"
    ) -> None:
        """
        Arr√™te le mode interm√©diation pour un thread donn√©.

        Actions:
        1. D√©sactive le flag intermediation_mode dans la session
        2. Envoie un message syst√®me au frontend (visible, mais NON sauv√© en RTDB)
        3. Envoie un signal RPC au frontend pour notifier l'arr√™t

        Args:
            session: Session LLM active
            user_id: ID Firebase utilisateur
            collection_name: ID soci√©t√©
            thread_key: Cl√© du thread
            job_id: ID du job (optionnel)
            reason: Raison de la cl√¥ture ("user_action", "timeout", "card_click", "termination_word")
        """
        try:
            from ..ws_hub import hub

            # ‚ïê‚ïê‚ïê 1. D√âSACTIVER LE FLAG INTERM√âDIATION ‚ïê‚ïê‚ïê
            if thread_key in session.intermediation_mode:
                session.intermediation_mode[thread_key] = False

            # ‚ïê‚ïê‚ïê 2. ENVOYER MESSAGE SYST√àME AU FRONTEND (VISIBLE, NON SAUV√â RTDB) ‚ïê‚ïê‚ïê
            reason_text = {
                "user_action": "by user action",
                "timeout": "due to timeout",
                "card_click": "by card selection",
                "termination_word": "by termination keyword"
            }.get(reason, reason)

            system_message_content = f"""‚úÖ **Intermediation Mode Terminated**

The intermediation session has been closed {reason_text}. You can now continue to chat normally with the agent."""

            # Envoyer via WebSocket comme message syst√®me (pas de sauvegarde RTDB)
            system_message_payload = {
                "type": "SYSTEM_MESSAGE_INTERMEDIATION",
                "thread_key": thread_key,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "message_id": str(uuid.uuid4()),
                "content": system_message_content,
                "system_type": "intermediation_end",
                "title": "End of Intermediation",
                "from_intermediation": False
            }

            ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
            await hub.broadcast(user_id, {
                "type": "SYSTEM_MESSAGE_INTERMEDIATION",
                "channel": ws_channel,
                "payload": system_message_payload
            })

            # ‚ïê‚ïê‚ïê 3. ENVOYER SIGNAL RPC AU FRONTEND ‚ïê‚ïê‚ïê
            rpc_signal = {
                "type": "RPC_INTERMEDIATION_STATE",
                "channel": ws_channel,
                "payload": {
                    "action": "stop",
                    "thread_key": thread_key,
                    "job_id": job_id,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "reason": reason
                }
            }

            await hub.broadcast(user_id, rpc_signal)

            logger.info(
                f"[INTERMEDIATION] üîö Mode d√©sactiv√© avec message syst√®me - "
                f"thread={thread_key} job_id={job_id} reason={reason}"
            )

        except Exception as e:
            logger.error(
                f"[INTERMEDIATION] ‚ùå Erreur arr√™t mode interm√©diation: {e}",
                exc_info=True
            )

    async def _send_websocket_message(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        message_type: str,
        payload_data: Dict[str, Any],
        additional_fields: Optional[Dict[str, Any]] = None
        ) -> None:
        """
        M√©thode centralis√©e pour envoyer des messages via WebSocket.
        
        Utilise le m√™me format que request_approval_with_card (general_chat) pour garantir
        la coh√©rence entre tous les modes de chat.
        
        Args:
            user_id: ID Firebase utilisateur
            collection_name: ID soci√©t√© (space_code)
            thread_key: Cl√© du thread de chat
            message_type: Type du message WebSocket ("CARD", "WORKFLOW", "CMMD", etc.)
            payload_data: Donn√©es du payload WebSocket
            additional_fields: Champs additionnels √† ajouter au payload (optionnel)
        """
        try:
            from ..ws_hub import hub
            
            # Construire le payload avec structure identique √† general_chat
            ws_message = {
                "type": message_type,
                "thread_key": thread_key,
                **payload_data
            }
            
            # Ajouter champs additionnels si fournis
            if additional_fields:
                ws_message.update(additional_fields)
            
            # Channel WebSocket (format standardis√©)
            ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
            
            # Broadcast via hub (format identique √† request_approval_with_card)
            await hub.broadcast(user_id, {
                "type": message_type,  # ‚úÖ Type explicite (CARD, WORKFLOW, CMMD, etc.)
                "channel": ws_channel,
                "payload": ws_message
            })
            
            logger.info(
                f"[WSS_CENTRAL] üì° Message WebSocket envoy√© - "
                f"type={message_type} thread={thread_key} channel={ws_channel}"
            )
            
        except Exception as e:
            logger.error(
                f"[WSS_CENTRAL] ‚ùå Erreur envoi WebSocket: {e}",
                exc_info=True
            )

    async def _send_non_message_via_websocket(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        message: Dict[str, Any]
        ) -> None:
        """
        Envoie les messages non-MESSAGE (CARD, WORKFLOW, CMMD, etc.) via WebSocket.
        
        Ces messages ne doivent PAS √™tre inject√©s dans l'historique LLM mais envoy√©s
        directement au frontend via WebSocket. Utilise la m√©thode centralis√©e
        _send_websocket_message pour garantir la coh√©rence du format.
        
        Args:
            user_id: ID Firebase utilisateur
            collection_name: ID soci√©t√© (space_code)
            thread_key: Cl√© du thread de chat
            message: Message RTDB complet avec tous ses arguments
        """
        try:
            # Extraire le type de message depuis le message RTDB
            message_type = message.get('message_type') or message.get('type')
            
            if not message_type:
                logger.warning(
                    f"[ONBOARDING_WSS] ‚ö†Ô∏è Type de message manquant, utilisation de 'MESSAGE' par d√©faut "
                    f"thread={thread_key}"
                )
                message_type = 'MESSAGE'
            
            # Construire le payload avec les champs essentiels
            payload_data = {
                "timestamp": message.get("timestamp") or datetime.now(timezone.utc).isoformat(),
                "message_id": message.get("id") or message.get("message_id"),
            }
            
            # Pr√©server le contenu du message
            if "content" in message:
                payload_data["content"] = message["content"]
            
            # Pr√©server les autres champs du message (event, message, cardParams, etc.)
            # mais exclure les champs d√©j√† trait√©s
            excluded_fields = {"id", "message_id", "timestamp", "message_type", "type"}
            additional_fields = {
                k: v for k, v in message.items() 
                if k not in excluded_fields
            }
            
            # Utiliser la m√©thode centralis√©e avec le format g√©n√©ral_chat
            await self._send_websocket_message(
                user_id=user_id,
                collection_name=collection_name,
                thread_key=thread_key,
                message_type=message_type,  # ‚úÖ Utilise le vrai type (CARD, WORKFLOW, CMMD)
                payload_data=payload_data,
                additional_fields=additional_fields if additional_fields else None
            )
            
            logger.info(
                f"[ONBOARDING_WSS] ‚úÖ Message non-MESSAGE rout√© via WebSocket centralis√© - "
                f"type={message_type} thread={thread_key}"
            )
            
        except Exception as e:
            logger.error(
                f"[ONBOARDING_WSS] ‚ùå Erreur envoi WebSocket: {e}",
                exc_info=True
            )

    def _format_onboarding_log_entry(self, message: Dict[str, Any]) -> Tuple[str, datetime]:
        """Formate un message m√©tier en entr√©e de log horodat√©."""

        raw_content = message.get("content")

        if isinstance(raw_content, str):
            try:
                content_dict = json.loads(raw_content)
                if isinstance(content_dict, dict):
                    if "message" in content_dict and isinstance(content_dict["message"], dict):
                        if "argumentText" in content_dict["message"]:
                            text_content = content_dict["message"]["argumentText"]
                        else:
                            text_content = json.dumps(content_dict["message"], ensure_ascii=False)
                    else:
                        text_content = raw_content
                else:
                    text_content = raw_content
            except (json.JSONDecodeError, TypeError):
                text_content = raw_content
        elif isinstance(raw_content, dict):
            message_payload = raw_content.get("message") if isinstance(raw_content.get("message"), dict) else None
            if message_payload and "argumentText" in message_payload:
                text_content = message_payload["argumentText"]
            else:
                text_content = json.dumps(raw_content, ensure_ascii=False)
        else:
            text_content = (
                message.get("message")
                or message.get("description")
                or json.dumps(message, ensure_ascii=False)
            )

        timestamp_obj = datetime.now(timezone.utc)
        message_timestamp = message.get("timestamp")
        if message_timestamp:
            try:
                if isinstance(message_timestamp, str):
                    timestamp_obj = datetime.fromisoformat(message_timestamp.replace('Z', '+00:00'))
                else:
                    timestamp_obj = datetime.fromtimestamp(message_timestamp, tz=timezone.utc)
            except (ValueError, TypeError):
                timestamp_obj = datetime.now(timezone.utc)

        timestamp_formatted = timestamp_obj.strftime("%Y-%m-%d %H:%M:%S")
        log_text = f"{timestamp_formatted} | {text_content}"

        return log_text, timestamp_obj

    async def _handle_onboarding_log_event(
        self,
        session: LLMSession,
        brain,
        collection_name: str,
        thread_key: str,
        follow_thread_key: str,  # ‚ö†Ô∏è Conserv√© pour compatibilit√© mais non utilis√©
        message: Dict[str, Any]
        ) -> None:
        """
        Traite chaque log onboarding re√ßu depuis RTDB.
        
        ‚≠ê MODIFI√â: Filtre par message_type :
        - MESSAGE ‚Üí Injection directe dans l'historique agent avec format horodat√©
        - Autres types (CARD, WORKFLOW, CMMD) ‚Üí Envoi via WebSocket uniquement
        """

        try:
            listener_info = session.onboarding_listeners.get(thread_key)
            if not listener_info:
                logger.debug(
                    f"[ONBOARDING_LOG] Listener non trouv√© pour thread={thread_key}, message ignor√©"
                )
                return

            job_id = listener_info.get("job_id")
            user_id = session.context.user_id
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : Extraction du type de message
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            message_type = message.get('message_type') or message.get('type')
            
            # Si pas de type explicite, supposer MESSAGE par d√©faut (compatibilit√©)
            if not message_type:
                message_type = 'MESSAGE'
                logger.debug(
                    f"[ONBOARDING_LOG] ‚ö†Ô∏è Type manquant, suppos√© MESSAGE pour thread={thread_key}"
                )
            
            logger.info(
                f"[ONBOARDING_LOG] üì® Message re√ßu - "
                f"type={message_type} thread={thread_key} job_id={job_id} "
                f"message_id={message.get('id', 'N/A')}"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : Routage selon le type
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            if message_type == 'MESSAGE':
                # ‚ïê‚ïê‚ïê V√âRIFICATION MODE INTERM√âDIATION ‚ïê‚ïê‚ïê
                # Si mode interm√©diation actif, rediriger vers WebSocket au lieu d'injecter
                if session.intermediation_mode.get(thread_key, False):
                    # En mode interm√©diation, les MESSAGE sont envoy√©s via WebSocket avec llm_message_direct
                    from ..ws_hub import hub
                    
                    message_id = message.get("id") or message.get("message_id")
                    timestamp = message.get("timestamp") or datetime.now(timezone.utc).isoformat()
                    
                    # Extraire le contenu du message
                    content = message.get("content", "")
                    # Si le contenu est un JSON string, le parser
                    if isinstance(content, str):
                        try:
                            import json
                            content_dict = json.loads(content)
                            if isinstance(content_dict, dict) and "message" in content_dict:
                                if isinstance(content_dict["message"], dict) and "argumentText" in content_dict["message"]:
                                    content = content_dict["message"]["argumentText"]
                        except (json.JSONDecodeError, KeyError, TypeError):
                            pass  # Garder le contenu tel quel si pas de JSON valide
                    
                    ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
                    
                    await hub.broadcast(user_id, {
                        "type": "llm_message_direct",
                        "channel": ws_channel,
                        "payload": {
                            "message_id": message_id or str(uuid.uuid4()),
                            "thread_key": thread_key,
                            "space_code": collection_name,
                            "content": content,
                            "timestamp": timestamp,
                            "intermediation": True,
                            "from_agent": True  # Indique que c'est une r√©ponse de l'agent
                        }
                    })
                    
                    logger.info(
                        f"[INTERMEDIATION] üì° MESSAGE redirig√© vers WebSocket (mode interm√©diation) - "
                        f"type=llm_message_direct thread={thread_key} message_id={message_id}"
                    )
                    return
                
                # ‚ïê‚ïê‚ïê MODE NORMAL : Injection dans l'historique agent ‚ïê‚ïê‚ïê
                log_entries = listener_info.setdefault("log_entries", [])
                existing_processed = session.onboarding_processed_ids.get(thread_key)
                if existing_processed is None:
                    existing_processed = set()
                    session.onboarding_processed_ids[thread_key] = existing_processed
                processed_ids = listener_info.setdefault("processed_message_ids", existing_processed)

                message_id = message.get("id") or message.get("message_id")
                if message_id and message_id in processed_ids:
                    logger.debug(
                        f"[ONBOARDING_LOG] üîÅ Message d√©j√† trait√© ignor√© - "
                        f"thread={thread_key} job_id={job_id} message_id={message_id}"
                    )
                    return

                log_text, timestamp_obj = self._format_onboarding_log_entry(message)

                if message_id:
                    processed_ids.add(message_id)

                log_entries.append(log_text)
                listener_info["log_entries"] = log_entries
                session.onboarding_processed_ids[thread_key] = processed_ids

                combined_text = "\n".join(log_entries)

                if brain and getattr(brain, "pinnokio_agent", None):
                    brain.pinnokio_agent.append_system_log(
                        message_id=job_id or thread_key,
                        timestamp=timestamp_obj.isoformat(),
                        payload=combined_text
                    )

                session.onboarding_listeners[thread_key] = listener_info

                logger.info(
                    f"[ONBOARDING_LOG] ‚úÖ MESSAGE inject√© dans l'historique agent - "
                    f"thread={thread_key} job_id={job_id} entries_count={len(log_entries)}"
                )
            
            elif message_type == 'FOLLOW_MESSAGE':
                # ‚ïê‚ïê‚ïê MODE INTERM√âDIATION ACTIV√â ‚ïê‚ïê‚ïê
                # L'application m√©tier requiert une interaction directe avec l'utilisateur

                # Envoyer le message via WebSocket (sans streaming)
                await self._send_non_message_via_websocket(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message
                )

                # ‚≠ê D√âMARRER MODE INTERM√âDIATION (pour tous les modes)
                await self._start_intermediation_mode(
                    session=session,
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message,
                    job_id=job_id
                )

                logger.info(
                    f"[INTERMEDIATION] üîÑ Mode activ√© via FOLLOW_MESSAGE - "
                    f"thread={thread_key} job_id={job_id} message_id={message.get('id', 'N/A')}"
                )
                return

            elif message_type == 'CLOSE_INTERMEDIATION':
                # ‚ïê‚ïê‚ïê MODE INTERM√âDIATION D√âSACTIV√â ‚ïê‚ïê‚ïê
                # L'application m√©tier signale explicitement la fin de l'interm√©diation
                # Peut √™tre d√©clench√© par: timeout, action utilisateur, carte cliqu√©e, mot de terminaison

                # D√©tecter la raison de la fermeture depuis le message
                # Le message peut contenir un champ 'reason' ou 'timeout' pour indiquer l'origine
                close_reason = message.get('reason') or message.get('close_reason')
                is_timeout = message.get('timeout', False) or close_reason == 'timeout'
                
                # D√©terminer la raison appropri√©e
                if is_timeout or close_reason == 'timeout':
                    reason = "timeout"
                elif close_reason == 'card_click':
                    reason = "card_click"
                elif close_reason == 'termination_word':
                    reason = "termination_word"
                else:
                    reason = "user_action"  # Par d√©faut

                # Envoyer via WebSocket pour notifier le frontend
                await self._send_non_message_via_websocket(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message
                )

                # ‚≠ê ARR√äTER MODE INTERM√âDIATION avec la raison appropri√©e
                await self._stop_intermediation_mode(
                    session=session,
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    job_id=job_id,
                    reason=reason
                )

                logger.info(
                    f"[INTERMEDIATION] üîö Mode d√©sactiv√© via CLOSE_INTERMEDIATION - "
                    f"thread={thread_key} job_id={job_id} message_id={message.get('id', 'N/A')} reason={reason}"
                )
                return

            elif message_type in {"CARD", "WAITING_MESSAGE"}:
                # ‚ïê‚ïê‚ïê ENVOI VIA WEBSOCKET + NOTIFICATION AGENT ‚ïê‚ïê‚ïê
                await self._send_non_message_via_websocket(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message
                )

                await self._notify_agent_of_waiting_context(
                    session=session,
                    brain=brain,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    job_id=job_id,
                    message_type=message_type,
                    message=message
                )

                # ‚≠ê NOUVELLE LOGIQUE: D√©marrer mode interm√©diation pour CARD
                # UNIQUEMENT pour apbookeeper_chat, router_chat, banker_chat
                if session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
                    await self._start_intermediation_mode(
                        session=session,
                        user_id=user_id,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        message=message,
                        job_id=job_id
                    )
                    logger.info(
                        f"[INTERMEDIATION] üîÑ Mode activ√© via CARD pour {session.context.chat_mode} - "
                        f"thread={thread_key} job_id={job_id}"
                    )

                logger.info(
                    f"[ONBOARDING_LOG] ‚úÖ Message {message_type} rout√© via WebSocket "
                    f"et contexte partag√© avec l'agent"
                )

            elif message_type == "TOOL":
                # ‚ïê‚ïê‚ïê ENVOI OUTILS + ACTIVATION MODE INTERM√âDIATION ‚ïê‚ïê‚ïê
                # Le message TOOL contient la liste des outils disponibles
                # et d√©clenche le mode interm√©diation pour les modes concern√©s
                
                # Envoyer via WebSocket (pour compatibilit√© avec ancien syst√®me)
                await self._send_non_message_via_websocket(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message
                )
                
                # ‚≠ê NOUVEAU : Activer mode interm√©diation pour les modes concern√©s
                if session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
                    await self._start_intermediation_mode(
                        session=session,
                        user_id=user_id,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        message=message,
                        job_id=job_id
                    )
                    logger.info(
                        f"[INTERMEDIATION] üîÑ Mode activ√© via TOOL - "
                        f"thread={thread_key} job_id={job_id} message_id={message.get('id', 'N/A')}"
                    )
                else:
                    logger.info(
                        f"[ONBOARDING_LOG] ‚úÖ Message TOOL rout√© via WebSocket "
                        f"(mode {session.context.chat_mode} ne supporte pas l'interm√©diation)"
                    )

            elif message_type == "CARD_CLICKED_PINNOKIO":
                # ‚ïê‚ïê‚ïê CARTE CLIQU√âE - FERMETURE MODE INTERM√âDIATION ‚ïê‚ïê‚ïê
                # Quand l'utilisateur clique sur une carte, cela ferme le mode interm√©diation
                # Le message CARD_CLICKED_PINNOKIO est √©crit dans RTDB par le frontend
                # et doit √™tre trait√© pour fermer le mode interm√©diation
                
                # Envoyer via WebSocket pour notifier le frontend
                await self._send_non_message_via_websocket(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message
                )
                
                # ‚≠ê FERMER MODE INTERM√âDIATION si actif
                if session.intermediation_mode.get(thread_key, False):
                    await self._stop_intermediation_mode(
                        session=session,
                        user_id=user_id,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        job_id=job_id,
                        reason="card_click"
                    )
                    logger.info(
                        f"[INTERMEDIATION] üîö Mode d√©sactiv√© via CARD_CLICKED_PINNOKIO - "
                        f"thread={thread_key} job_id={job_id} message_id={message.get('id', 'N/A')}"
                    )
                else:
                    logger.debug(
                        f"[INTERMEDIATION] ‚ÑπÔ∏è CARD_CLICKED_PINNOKIO re√ßu mais mode interm√©diation d√©j√† inactif - "
                        f"thread={thread_key}"
                    )
                return

            else:
                # ‚ïê‚ïê‚ïê ENVOI VIA WEBSOCKET UNIQUEMENT ‚ïê‚ïê‚ïê
                # Types: WORKFLOW, CMMD, etc.
                await self._send_non_message_via_websocket(
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message
                )
                logger.info(
                    f"[ONBOARDING_LOG] ‚úÖ Message {message_type} rout√© via WebSocket "
                    f"(pas d'injection dans historique LLM)"
                )

        except Exception as e:
            logger.error(f"[ONBOARDING_LOG] ‚ùå Erreur traitement log: {e}", exc_info=True)

    async def _handle_intermediation_response(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        message: str,
        session: LLMSession
    ) -> dict:
        """
        Traite les r√©ponses utilisateur pendant le mode interm√©diation.
        Envoie la r√©ponse au RTDB de l'application m√©tier ET via WebSocket au frontend.
        
        Args:
            user_id: ID de l'utilisateur Firebase
            collection_name: ID de la soci√©t√© (space_code)
            thread_key: Cl√© du thread de chat
            message: Message de l'utilisateur
            session: Session LLM active
            
        Returns:
            dict: R√©sultat de l'op√©ration
        """
        from ..ws_hub import hub
        
        try:
            listener_info = session.onboarding_listeners.get(thread_key)
            if not listener_info:
                logger.error(
                    f"[INTERMEDIATION] ‚ùå Listener introuvable pour thread={thread_key}"
                )
                return {
                    "success": False,
                    "error": "Listener not found"
                }
            
            job_id = listener_info.get("job_id")
            
            # V√©rifier si le message contient un mot de terminaison
            termination_words = ["TERMINATE", "PENDING", "NEXT"]
            message_upper = message.upper()
            has_termination = any(word in message_upper for word in termination_words)
            
            # Envoyer la r√©ponse au RTDB de l'application m√©tier
            messages_path = f"{collection_name}/job_chats/{job_id}/messages"
            message_id = str(uuid.uuid4())
            timestamp = datetime.now(timezone.utc).isoformat()
            message_ref = self._get_rtdb_ref(f"{messages_path}/{message_id}")
            
            payload = {
                "id": message_id,
                "message_type": "MESSAGE_PINNOKIO",
                "content": message,
                "sender_id": user_id,
                "timestamp": timestamp,
                "read": False,
                "local_processed": False
            }
            
            message_ref.set(payload)
            
            logger.info(
                f"[INTERMEDIATION] ‚úÖ R√©ponse utilisateur envoy√©e vers RTDB m√©tier - "
                f"thread={thread_key} job_id={job_id} has_termination={has_termination}"
            )
            
            # ‚ö†Ô∏è NOTE : On n'envoie PAS le message utilisateur via WebSocket
            # Le frontend a d√©j√† sauvegard√© le message utilisateur dans active_chats
            # Envoyer llm_message_direct ici cr√©erait une duplication o√π le message utilisateur
            # appara√Ætrait comme message de l'agent dans active_chats
            # Seules les r√©ponses de l'agent m√©tier (MESSAGE avec from_agent=True) sont envoy√©es

            # Si mot de terminaison d√©tect√©, √©crire CLOSE_INTERMEDIATION et d√©sactiver le mode
            if has_termination:
                # √âcrire le message CLOSE_INTERMEDIATION dans RTDB
                close_message_id = str(uuid.uuid4())
                close_timestamp = datetime.now(timezone.utc).isoformat()
                close_message_ref = self._get_rtdb_ref(f"{messages_path}/{close_message_id}")

                close_payload = {
                    "id": close_message_id,
                    "message_type": "CLOSE_INTERMEDIATION",
                    "content": "Intermediation closed by user",
                    "timestamp": close_timestamp,
                    "read": False,
                    "eventTime": close_timestamp
                }

                close_message_ref.set(close_payload)

                # ‚≠ê ARR√äTER MODE INTERM√âDIATION avec message syst√®me
                await self._stop_intermediation_mode(
                    session=session,
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    job_id=job_id,
                    reason="termination_word"
                )

                logger.info(
                    f"[INTERMEDIATION] üîö Mode d√©sactiv√© - CLOSE_INTERMEDIATION √©crit dans RTDB - "
                    f"thread={thread_key} mot_terminaison_d√©tect√©=True"
                )
            
            return {
                "success": True,
                "message_id": message_id,
                "intermediation_active": not has_termination,
                "job_id": job_id
            }
            
        except Exception as e:
            logger.error(f"[INTERMEDIATION] ‚ùå Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }

    async def _check_intermediation_on_load(
        self,
        session: LLMSession,
        collection_name: str,
        thread_key: str,
        job_status: Optional[str] = None
    ) -> None:
        """
        V√©rifie si le chat doit √™tre en mode interm√©diation au chargement.

        ‚≠ê LOGIQUE CORRECTE :
        1. Cherche dans TOUT l'historique s'il existe un CARD/TOOL/FOLLOW_MESSAGE
        2. V√©rifie s'il y a un CLOSE_INTERMEDIATION apr√®s ce message
        3. Si OUI ‚Üí mode normal (interm√©diation termin√©e)
        4. Si NON ‚Üí activer mode interm√©diation (peu importe les messages entre)
        
        Le dernier message n'a pas d'importance : ce qui compte c'est l'existence
        d'un CARD/TOOL/FOLLOW_MESSAGE sans CLOSE_INTERMEDIATION apr√®s.
        
        ‚≠ê RENVOI DE CARTE :
        Si une CARD existe dans l'historique et n'a pas √©t√© cliqu√©e (CARD_CLICKED_PINNOKIO),
        elle est renvoy√©e au frontend pour permettre √† l'utilisateur d'interagir avec
        les boutons d'action (m√™me s'il y a eu des √©changes apr√®s).
        
        ‚≠ê CONDITIONS D'ACTIVATION :
        - CARD/TOOL/FOLLOW_MESSAGE trouv√© dans l'historique
        - Pas de CLOSE_INTERMEDIATION apr√®s
        - Job actif (job_status in ['running', 'in queue'])

        Args:
            session: Session LLM active
            collection_name: ID de la soci√©t√©
            thread_key: Cl√© du thread de chat
            job_status: Statut du job (optionnel) - "running", "in queue", "completed", etc.
        """
        try:
            logger.info(
                f"[INTERMEDIATION_LOAD] üîç V√©rification mode interm√©diation au chargement - "
                f"thread={thread_key} job_status={job_status}"
            )
            
            # ‚≠ê NOUVEAU : R√©cup√©rer job_id depuis listener ou utiliser thread_key comme fallback
            listener_info = session.onboarding_listeners.get(thread_key)
            job_id = None
            
            if listener_info:
                job_id = listener_info.get("job_id")
                logger.info(
                    f"[INTERMEDIATION_LOAD] Listener trouv√© - thread={thread_key} job_id={job_id}"
                )
            
            # ‚≠ê FALLBACK : Pour les modes onboarding-like, thread_key = job_id
            if not job_id and session.context.chat_mode in ("apbookeeper_chat", "router_chat", "banker_chat"):
                job_id = thread_key
                logger.info(
                    f"[INTERMEDIATION_LOAD] ‚ö†Ô∏è job_id non trouv√© dans listener, utilisation thread_key comme fallback - "
                    f"thread={thread_key} job_id={job_id}"
                )
            
            if not job_id:
                logger.info(
                    f"[INTERMEDIATION_LOAD] ‚è≠Ô∏è job_id introuvable pour thread={thread_key}, "
                    f"v√©rification ignor√©e (mode={session.context.chat_mode})"
                )
                return
            
            # Charger les derniers messages de l'application m√©tier
            from ..firebase_providers import FirebaseRealtimeChat
            firebase_mgmt = FirebaseRealtimeChat()
            
            messages = firebase_mgmt.get_channel_messages(
                space_code=collection_name,
                thread_key=job_id,
                limit=50,
                mode="job_chats"
            )
            
            if not messages:
                logger.info(
                    f"[INTERMEDIATION_LOAD] ‚è≠Ô∏è Aucun message m√©tier pour thread={thread_key} job_id={job_id}, "
                    f"mode normal"
                )
                return
            
            # Trier par timestamp (du plus r√©cent au plus ancien)
            def _sort_key(msg):
                ts = msg.get('timestamp', '')
                if isinstance(ts, str):
                    try:
                        return datetime.fromisoformat(ts.replace('Z', '+00:00')).timestamp()
                    except:
                        return 0
                return ts if isinstance(ts, (int, float)) else 0
            
            messages.sort(key=_sort_key, reverse=True)
            
            # ‚≠ê LOGIQUE CORRIG√âE AVEC V√âRIFICATION CHRONOLOGIQUE:
            # 1. Trouver la CARD/TOOL/FOLLOW_MESSAGE la plus r√©cente
            # 2. V√©rifier s'il y a un CLOSE_INTERMEDIATION APR√àS cette CARD (plus r√©cent chronologiquement)
            # 3. Si CLOSE_INTERMEDIATION est APR√àS la CARD ‚Üí mode ferm√©
            # 4. Si CLOSE_INTERMEDIATION est AVANT la CARD ‚Üí mode doit √™tre activ√© (nouvelle interm√©diation)
            
            has_card_clicked = False
            card_or_tool_message = None  # Dernier CARD/TOOL/FOLLOW_MESSAGE trouv√©
            card_or_tool_index = None
            last_card_for_display = None  # Derni√®re CARD √† afficher (si pas cliqu√©e)
            last_card_index = None
            close_message_index = None  # Index du CLOSE_INTERMEDIATION le plus r√©cent
            
            # 1. Parcourir TOUS les messages pour trouver :
            #    - Dernier CARD/TOOL/FOLLOW_MESSAGE (le plus r√©cent)
            #    - Derni√®re CARD (pour affichage)
            #    - CLOSE_INTERMEDIATION le plus r√©cent (pour comparaison chronologique)
            for idx, msg in enumerate(messages):
                msg_type = msg.get('message_type')
                
                # Sauvegarder le CLOSE_INTERMEDIATION le plus r√©cent (premier trouv√© = plus r√©cent)
                if msg_type == 'CLOSE_INTERMEDIATION' and close_message_index is None:
                    close_message_index = idx
                    logger.info(
                        f"[INTERMEDIATION_LOAD] ‚úÖ CLOSE_INTERMEDIATION trouv√© √† l'index {idx} - "
                        f"thread={thread_key} message_id={msg.get('id', 'N/A')}"
                    )
                
                # Sauvegarder le premier (plus r√©cent) CARD/TOOL/FOLLOW_MESSAGE trouv√©
                if msg_type in ('CARD', 'TOOL', 'FOLLOW_MESSAGE') and card_or_tool_message is None:
                    card_or_tool_message = msg
                    card_or_tool_index = idx
                    logger.info(
                        f"[INTERMEDIATION_LOAD] üîß Dernier {msg_type} trouv√© √† l'index {idx} - "
                        f"thread={thread_key} message_id={msg.get('id', 'N/A')}"
                    )
                
                # Sauvegarder la premi√®re (plus r√©cente) CARD trouv√©e pour affichage
                if msg_type == 'CARD' and last_card_for_display is None:
                    last_card_for_display = msg
                    last_card_index = idx
                    logger.info(
                        f"[INTERMEDIATION_LOAD] üÉè Derni√®re CARD trouv√©e √† l'index {idx} - "
                        f"thread={thread_key} card_id={msg.get('id', 'N/A')}"
                    )
            
            # 2. V√©rifier l'ordre chronologique : CLOSE_INTERMEDIATION est-il APR√àS la CARD ?
            # Les messages sont tri√©s du plus r√©cent (idx 0) au plus ancien
            # Si close_message_index < card_or_tool_index ‚Üí CLOSE est plus r√©cent que CARD ‚Üí mode ferm√©
            # Si close_message_index > card_or_tool_index ou None ‚Üí CLOSE est plus ancien ou absent ‚Üí mode doit √™tre activ√©
            has_close_after_card = False
            if card_or_tool_index is not None and close_message_index is not None:
                if close_message_index < card_or_tool_index:
                    # CLOSE_INTERMEDIATION est plus r√©cent que la CARD ‚Üí mode ferm√©
                    has_close_after_card = True
                    logger.info(
                        f"[INTERMEDIATION_LOAD] üîö CLOSE_INTERMEDIATION est APR√àS la CARD "
                        f"(close_idx={close_message_index} < card_idx={card_or_tool_index}) - "
                        f"thread={thread_key} ‚Üí Mode ferm√©"
                    )
                else:
                    # CLOSE_INTERMEDIATION est plus ancien que la CARD ‚Üí nouvelle interm√©diation
                    logger.info(
                        f"[INTERMEDIATION_LOAD] ‚úÖ CLOSE_INTERMEDIATION est AVANT la CARD "
                        f"(close_idx={close_message_index} >= card_idx={card_or_tool_index}) - "
                        f"thread={thread_key} ‚Üí Nouvelle interm√©diation d√©tect√©e"
                    )
            elif close_message_index is not None and card_or_tool_index is None:
                # CLOSE_INTERMEDIATION existe mais pas de CARD ‚Üí mode ferm√©
                has_close_after_card = True
                logger.info(
                    f"[INTERMEDIATION_LOAD] üîö CLOSE_INTERMEDIATION trouv√© sans CARD/TOOL/FOLLOW_MESSAGE - "
                    f"thread={thread_key} ‚Üí Mode ferm√©"
                )
            
            # 3. Si une CARD a √©t√© trouv√©e, v√©rifier si elle a √©t√© cliqu√©e
            if last_card_for_display and last_card_index is not None:
                for msg in messages[:last_card_index]:  # Messages plus r√©cents que la CARD
                    if msg.get('message_type') == 'CARD_CLICKED_PINNOKIO':
                        has_card_clicked = True
                        logger.info(
                            f"[INTERMEDIATION_LOAD] ‚úÖ CARD_CLICKED_PINNOKIO trouv√© apr√®s CARD - "
                            f"thread={thread_key} message_id={msg.get('id', 'N/A')}"
                        )
                        break
            
            # 4. D√©cider d'activer le mode interm√©diation
            if card_or_tool_message and not has_close_after_card:
                # Un CARD/TOOL/FOLLOW_MESSAGE existe ET pas de CLOSE_INTERMEDIATION apr√®s
                # ‚Üí Activer le mode interm√©diation

                # D√©terminer si le job est en cours de traitement
                job_in_process = True  # Par d√©faut, on suppose que le job est en cours

                if job_status:
                    # Si job_status est fourni, v√©rifier qu'il est bien "running" ou "in queue"
                    job_in_process = job_status in ('running', 'in queue')
                    logger.info(
                        f"[INTERMEDIATION_LOAD] üîç job_status={job_status} ‚Üí "
                        f"job_in_process={job_in_process}"
                    )

                # Ne r√©activer l'interm√©diation QUE si le job est en cours
                if job_in_process:
                    # R√©activer le mode interm√©diation avec message syst√®me
                    # Utiliser card_or_tool_message pour les outils
                    mode_activated = await self._start_intermediation_mode(
                        session=session,
                        user_id=session.context.user_id,
                        collection_name=collection_name,
                        thread_key=thread_key,
                        message=card_or_tool_message,
                        job_id=job_id
                    )
                    
                    if mode_activated:
                        logger.info(
                            f"[INTERMEDIATION_LOAD] ‚úÖ Mode r√©activ√© au chargement - "
                            f"thread={thread_key} job_id={job_id} "
                            f"(CARD/TOOL/FOLLOW_MESSAGE trouv√© sans CLOSE_INTERMEDIATION, job_status={job_status})"
                        )
                    else:
                        logger.info(
                            f"[INTERMEDIATION_LOAD] ‚è≠Ô∏è Mode D√âJ√Ä actif - thread={thread_key} - "
                            f"Ignorer r√©activation (√©viter doublons)"
                        )

                    # ‚≠ê Renvoyer la CARD si elle existe et n'a pas √©t√© cliqu√©e
                    if last_card_for_display and not has_card_clicked and mode_activated:
                        from ..ws_hub import hub
                        ws_channel = f"chat:{session.context.user_id}:{collection_name}:{thread_key}"

                        # Pr√©parer le message de la carte
                        card_message = {
                            "type": "CARD",
                            "channel": ws_channel,
                            "payload": last_card_for_display
                        }

                        # V√©rifier si le listener du chat est actif
                        from ..registry.registry_listeners import get_registry_listeners
                        registry = get_registry_listeners()
                        
                        listener_status = registry.check_listener_status(
                            user_id=session.context.user_id,
                            listener_type="chat",
                            space_code=collection_name,
                            thread_key=thread_key
                        )
                        
                        is_listener_active = listener_status.get("active", False)
                        
                        if is_listener_active:
                            # ‚úÖ WebSocket connect√© ‚Üí Envoyer imm√©diatement
                            await hub.broadcast(session.context.user_id, card_message)
                            
                            logger.info(
                                f"[INTERMEDIATION_LOAD] üÉè Carte renvoy√©e imm√©diatement (WebSocket actif) - "
                                f"thread={thread_key} card_id={last_card_for_display.get('id', 'N/A')}"
                            )
                        else:
                            # ‚è≥ WebSocket pas encore connect√© ‚Üí Bufferiser
                            from ..ws_message_buffer import get_message_buffer
                            buffer = get_message_buffer()
                            
                            buffer.store_pending_message(
                                user_id=session.context.user_id,
                                thread_key=thread_key,
                                message=card_message
                            )
                            
                            logger.info(
                                f"[INTERMEDIATION_LOAD] üÉè Carte bufferis√©e (WebSocket pas encore connect√©) - "
                                f"thread={thread_key} card_id={last_card_for_display.get('id', 'N/A')} "
                                f"listener_status={listener_status.get('status')}"
                            )
                else:
                    logger.info(
                        f"[INTERMEDIATION_LOAD] ‚è∏Ô∏è Mode interm√©diation NON r√©activ√© - "
                        f"thread={thread_key} job_id={job_id} "
                        f"(job termin√© ou non d√©marr√©, job_status={job_status})"
                    )
            else:
                # Pas de CARD/TOOL/FOLLOW_MESSAGE OU CLOSE_INTERMEDIATION d√©tect√© APR√àS la CARD
                if has_close_after_card:
                    logger.info(
                        f"[INTERMEDIATION_LOAD] ‚è≠Ô∏è Mode normal conserv√© - "
                        f"thread={thread_key} (CLOSE_INTERMEDIATION d√©tect√© APR√àS la CARD/TOOL/FOLLOW_MESSAGE)"
                    )
                elif not card_or_tool_message:
                    logger.info(
                        f"[INTERMEDIATION_LOAD] ‚è≠Ô∏è Mode normal - "
                        f"thread={thread_key} (aucun CARD/TOOL/FOLLOW_MESSAGE trouv√©)"
                    )
                else:
                    logger.info(
                        f"[INTERMEDIATION_LOAD] ‚è≠Ô∏è Mode normal - "
                        f"thread={thread_key} (condition non remplie pour activation)"
                    )
        
        except Exception as e:
            logger.error(
                f"[INTERMEDIATION_LOAD] ‚ùå Erreur v√©rification chargement: {e}",
                exc_info=True
            )

    async def _notify_agent_of_waiting_context(
        self,
        session: LLMSession,
        brain,
        collection_name: str,
        thread_key: str,
        job_id: Optional[str],
        message_type: str,
        message: Dict[str, Any]
        ) -> None:
        """Informe l'agent principal qu'un √©v√©nement CARD/WAITING_MESSAGE attend une action."""

        try:
            listener_info = session.onboarding_listeners.get(thread_key)
            if listener_info is None:
                logger.debug(
                    "[WAITING_CONTEXT] Listener introuvable pour thread=%s, notification ignor√©e",
                    thread_key
                )
                return

            event_id = (
                message.get("id")
                or message.get("message_id")
                or str(uuid.uuid4())
            )
            received_at = datetime.now(timezone.utc).isoformat()
            normalized_payload = self._decode_waiting_event_payload(message)

            summary_preview = json.dumps(normalized_payload, ensure_ascii=False)[:400]
            context_text = (
                f"Type: {message_type}\n"
                f"Job: {job_id or 'inconnu'}\n"
                f"√âv√©nement: {event_id}\n"
                f"D√©tails (preview): {summary_preview}"
            )

            waiting_context = {
                "event_id": event_id,
                "message_type": message_type,
                "job_id": job_id,
                "received_at": received_at,
                "payload": normalized_payload,
                "summary": context_text
            }

            listener_info.setdefault("waiting_events", []).append(waiting_context)
            listener_info["pending_waiting_event"] = waiting_context
            session.onboarding_listeners[thread_key] = listener_info

            if brain and getattr(brain, "pinnokio_agent", None):
                instruction = (
                    "üü† **Nouvelle attente application m√©tier**\n"
                    f"{context_text}\n\n"
                    "L'application m√©tier est en pause et attend soit un clic sur la carte, soit une r√©ponse "
                    "terminant par `TERMINATE`. Guide l'utilisateur, rappelle-lui d'ajouter `TERMINATE` √† la fin "
                    "de sa r√©ponse et pr√©pare-toi √† synth√©tiser l'√©change si n√©cessaire."
                )

                brain.pinnokio_agent.append_system_log(
                    message_id=f"waiting_ctx_{event_id}",
                    timestamp=received_at,
                    payload=instruction
                )

                logger.info(
                    "[WAITING_CONTEXT] Notification agent envoy√©e - thread=%s event=%s",
                    thread_key,
                    event_id
                )

        except Exception as exc:
            logger.error(
                "[WAITING_CONTEXT] ‚ùå Erreur notification agent: %s",
                exc,
                exc_info=True
            )

    def _decode_waiting_event_payload(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Normalise le contenu d'un √©v√©nement CARD/WAITING_MESSAGE pour logs et outils."""

        content = message.get("content")

        if isinstance(content, dict):
            return content

        if isinstance(content, str):
            try:
                decoded = json.loads(content)
                if isinstance(decoded, dict):
                    return decoded
                return {"value": decoded}
            except json.JSONDecodeError:
                return {"raw": content}

        # Fallback: inclure message brut
        return {
            "raw": content,
            "message": message
        }

    async def _synthesize_and_send_terminate_response(
        self,
        session: LLMSession,
        brain,
        user_id: str,
        collection_name: str,
        thread_key: str,
        user_message: str
        ) -> Optional[str]:
        """Synth√©tise la r√©ponse TERMINATE et l'envoie au canal m√©tier job_chats."""

        try:
            if brain is None or getattr(brain, "pinnokio_agent", None) is None:
                logger.warning(
                    "[WAITING_TERMINATE] Brain ou agent indisponible pour thread=%s",
                    thread_key
                )
                return None

            listener_info = session.onboarding_listeners.get(thread_key) or {}
            job_id = (
                listener_info.get("job_id")
                or (brain.onboarding_data or {}).get("job_id")
            )

            if not job_id:
                logger.warning(
                    "[WAITING_TERMINATE] job_id introuvable pour thread=%s",
                    thread_key
                )
                return None

            pending_event = listener_info.get("pending_waiting_event")
            if not pending_event:
                waiting_events = listener_info.get("waiting_events", [])
                pending_event = waiting_events[-1] if waiting_events else None

            event_summary = pending_event.get("summary") if pending_event else ""
            waiting_payload = pending_event.get("payload") if pending_event else {}

            user_message_clean = user_message.strip()
            if user_message_clean.upper().endswith("TERMINATE"):
                user_message_clean = user_message_clean[:-9].rstrip()

            instructions = (
                "L'application m√©tier attend une r√©ponse structur√©e terminant par le mot-cl√© `TERMINATE`.\n"
                "Analyse la conversation r√©cente, synth√©tise la r√©ponse de l'utilisateur et remplis l'outil "
                "`SUBMIT_WAITING_RESPONSE` avec: \n"
                "- `response_to_application`: message final √† envoyer au syst√®me m√©tier (doit se terminer par `TERMINATE`).\n"
                "- `user_summary`: r√©sum√© concis (3-4 phrases) de ce que l'utilisateur a fourni.\n"
                "- `context_notes` (optionnel): informations utiles suppl√©mentaires.\n"
                "N'ajoute aucun texte hors de l'appel outil."
            )

            if event_summary:
                instructions += f"\n\nContexte m√©tier: {event_summary}"

            if waiting_payload:
                payload_preview = json.dumps(waiting_payload, ensure_ascii=False)[:400]
                instructions += f"\n\nPayload brut: {payload_preview}"

            if user_message_clean:
                instructions += f"\n\nDernier message utilisateur sans mot-cl√©: {user_message_clean}"

            summary_tool = [{
                "name": "SUBMIT_WAITING_RESPONSE",
                "description": (
                    "Soumets la r√©ponse finale pour l'application m√©tier. `response_to_application` doit se "
                    "terminer par `TERMINATE`."
                ),
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "response_to_application": {
                            "type": "string",
                            "description": "Message envoy√© c√¥t√© m√©tier, doit se terminer par TERMINATE"
                        },
                        "user_summary": {
                            "type": "string",
                            "description": "Synth√®se des √©changes avec l'utilisateur"
                        },
                        "context_notes": {
                            "type": "string",
                            "description": "Informations compl√©mentaires pour le suivi",
                            "nullable": True
                        }
                    },
                    "required": ["response_to_application", "user_summary"]
                }
            }]

            def _noop_callback(**kwargs):
                return {"status": "captured", **kwargs}

            tool_mapping = {"SUBMIT_WAITING_RESPONSE": _noop_callback}

            response = await asyncio.to_thread(
                brain.pinnokio_agent.process_tool_use,
                instructions,
                summary_tool,
                tool_mapping,
                brain.default_size,
                {"type": "tool", "name": "SUBMIT_WAITING_RESPONSE"},
                False,
                brain.default_provider,
                False,
                1024,
                False
            )

            tool_payload, _, used_tool_name, _ = brain.pinnokio_agent.new_extract_tool_use_data(response)

            if not tool_payload or used_tool_name != "SUBMIT_WAITING_RESPONSE":
                logger.warning(
                    "[WAITING_TERMINATE] Outil non d√©clench√© correctement pour thread=%s",
                    thread_key
                )
                return None

            response_text = (tool_payload.get("response_to_application") or "").strip()
            user_summary = (tool_payload.get("user_summary") or "").strip()
            context_notes = (tool_payload.get("context_notes") or "").strip()

            if not response_text:
                logger.warning(
                    "[WAITING_TERMINATE] Champ response_to_application vide pour thread=%s",
                    thread_key
                )
                return None

            if not response_text.endswith("TERMINATE"):
                response_text = f"{response_text.rstrip()} TERMINATE"

            message_id = tool_payload.get("message_id") or str(uuid.uuid4())
            timestamp = datetime.now(timezone.utc).isoformat()

            payload = {
                "id": message_id,
                "message_type": "MESSAGE_PINNOKIO",
                "content": response_text,
                "sender_id": user_id,
                "timestamp": timestamp,
                "read": False,
                "local_processed": False,
                "metadata": {
                    "user_summary": user_summary,
                    "context_notes": context_notes,
                    "waiting_event_id": pending_event.get("event_id") if pending_event else None,
                    "waiting_event_type": pending_event.get("message_type") if pending_event else None
                }
            }

            # Nettoyer metadata des valeurs vides
            payload["metadata"] = {
                k: v for k, v in payload["metadata"].items() if v
            }

            rtdb_path = f"{collection_name}/job_chats/{job_id}/messages/{message_id}"
            self._get_rtdb_ref(rtdb_path).set(payload)

            listener_info["pending_waiting_event"] = None
            listener_info["last_terminate_sent"] = {
                "timestamp": timestamp,
                "message_id": message_id,
                "payload": payload
            }
            session.onboarding_listeners[thread_key] = listener_info

            confirmation_log = (
                "üü¢ **R√©ponse envoy√©e √† l'application m√©tier**\n"
                f"Job: {job_id}\n"
                f"Message ID: {message_id}\n"
                f"R√©sum√© utilisateur: {user_summary or '‚Äî'}"
            )

            brain.pinnokio_agent.append_system_log(
                message_id=f"waiting_ctx_ack_{message_id}",
                timestamp=timestamp,
                payload=confirmation_log
            )

            logger.info(
                "[WAITING_TERMINATE] ‚úÖ R√©ponse envoy√©e au job %s avec message_id=%s",
                job_id,
                message_id
            )

            return response_text

        except Exception as exc:
            logger.error(
                "[WAITING_TERMINATE] ‚ùå Erreur lors de la synth√®se/√©mission TERMINATE: %s",
                exc,
                exc_info=True
            )
            return None

    async def _send_onboarding_start_message(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        job_id: str
        ) -> None:
        """
        Envoie automatiquement le premier message assistant pour informer l'utilisateur du d√©marrage du job.
        
        ‚≠ê GESTION UI/BACKEND : Suit le m√™me pattern que _resume_workflow_after_lpt
        - Mode UI (user connect√© sur thread) : Streaming WebSocket + _process_unified_workflow
        - Mode BACKEND (user d√©connect√©) : √âcriture RTDB directe
        """
        try:
            import uuid
            from datetime import datetime, timezone
            from ..ws_hub import hub
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : R√âCUP√âRER LA SESSION EXISTANTE
            # (D√©j√† initialis√©e par start_onboarding_chat)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            session_key = f"{user_id}:{collection_name}"
            session = None
            with self._lock:
                session = self.sessions.get(session_key)
            
            if not session:
                logger.warning(
                    f"[ONBOARDING_START_MSG] ‚ö†Ô∏è Session non trouv√©e pour {session_key}, "
                    f"fallback mode BACKEND"
                )
                # Fallback : Mode BACKEND (√©criture RTDB directe)
                session = None
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : D√âTERMINER MODE UI/BACKEND
            # (M√™me logique que LPT callback)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            user_on_active_chat = False
            if session:
                user_on_active_chat = session.is_user_on_specific_thread(thread_key)
            
            mode = "UI" if user_on_active_chat else "BACKEND"
            
            logger.info(
                f"[ONBOARDING_START_MSG] Mode d√©tect√©: {mode} - "
                f"user_on_active_chat={user_on_active_chat} thread={thread_key} job_id={job_id}"
            )
            
            # Construire le message informatif pour l'utilisateur
            message_content = (
                f"üéØ **D√©marrage du processus d'onboarding**\n\n"
                f"Le job **{job_id}** a √©t√© lanc√© avec succ√®s pour initier votre phase d'onboarding.\n\n"
                f"Je suis l√† pour vous accompagner tout au long de ce processus. N'h√©sitez pas √† me poser "
                f"des questions ou √† me demander de l'aide √† tout moment. Je suivrai l'avancement du job "
                f"et vous tiendrai inform√© des √©tapes importantes."
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : PR√âPARER MESSAGE RTDB
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            assistant_message_id = str(uuid.uuid4())
            assistant_timestamp = datetime.now(timezone.utc).isoformat()
            chat_mode = session.context.chat_mode if session else None
            assistant_msg_base = self._get_messages_base_path(
                collection_name, thread_key, chat_mode
            )
            assistant_msg_path = f"{assistant_msg_base}/{assistant_message_id}"
            assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 4 : MODE UI - STREAMING WEBSOCKET
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if user_on_active_chat and session:
                # ‚≠ê CRITIQUE : Broadcaster AVANT de cr√©er le message RTDB
                # (M√™me pattern que _resume_workflow_after_lpt ligne 4448-4469)
                ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
                
                placeholder_event = {
                    "type": "assistant_message_placeholder",
                    "channel": ws_channel,
                    "payload": {
                        "message_id": assistant_message_id,
                        "thread_key": thread_key,
                        "space_code": collection_name,
                        "timestamp": assistant_timestamp,
                        "triggered_by": "onboarding_start",
                        "mode": mode,
                        "job_id": job_id
                    }
                }
                
                await hub.broadcast(user_id, placeholder_event)
                logger.info(f"[ONBOARDING_START_MSG] ‚ö° Signal placeholder envoy√© au frontend (message_id={assistant_message_id})")
                
                # Cr√©er message RTDB avec status "streaming" pour activer le streaming UI
                initial_message_data = self.rtdb_formatter.format_ai_message(
                    content="",
                    user_id=user_id,
                    message_id=assistant_message_id,
                    timestamp=assistant_timestamp,
                    metadata={
                        "status": "streaming",
                        "streaming_progress": 0.0,
                        "automation": "onboarding_start",
                        "job_id": job_id,
                        "mode": mode
                    }
                )
                
                assistant_msg_ref.set(initial_message_data)
                logger.info(f"[ONBOARDING_START_MSG] Message RTDB initial cr√©√© (status=streaming)")
                
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                # √âTAPE 5 : LANCER WORKFLOW UNIFI√â AVEC STREAMING
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                result = await self._process_unified_workflow(
                    session=session,
                    user_id=user_id,
                    collection_name=collection_name,
                    thread_key=thread_key,
                    message=message_content,
                    assistant_message_id=assistant_message_id,
                    assistant_timestamp=assistant_timestamp,
                    enable_streaming=True,  # ‚Üê Streaming activ√© pour Mode UI
                    chat_mode="onboarding_chat",
                    system_prompt=None
                )
                
                if result.get("success"):
                    logger.info(
                        f"[ONBOARDING_START_MSG] ‚úÖ Message streaming termin√© avec succ√®s - "
                        f"mode={mode} content_length={len(result.get('content', ''))}"
                    )
                else:
                    logger.error(
                        f"[ONBOARDING_START_MSG] ‚ùå √âchec workflow streaming - "
                        f"mode={mode} error={result.get('error')}"
                    )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 6 : MODE BACKEND - √âCRITURE RTDB DIRECTE
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            else:
                # Mode BACKEND : √âcriture RTDB directe (comportement original)
                message_data = self.rtdb_formatter.format_ai_message(
                    content=message_content,
                    user_id=user_id,
                    message_id=assistant_message_id,
                    timestamp=assistant_timestamp,
                    metadata={
                        "status": "completed",
                        "automation": "onboarding_start",
                        "job_id": job_id,
                        "mode": mode
                    }
                )
                
                assistant_msg_ref.set(message_data)
                
                logger.info(
                    f"[ONBOARDING_START_MSG] ‚úÖ Message automatique envoy√© (BACKEND) - "
                    f"thread={thread_key}, job_id={job_id}, message_id={assistant_message_id}"
                )
            
        except Exception as e:
            logger.error(
                f"[ONBOARDING_START_MSG] ‚ùå Erreur envoi message automatique: {e}",
                exc_info=True
            )

    def _stop_onboarding_listener(self, session: LLMSession, thread_key: Optional[str] = None) -> None:
        """Arr√™te les √©couteurs onboarding pour un thread ou pour tous."""

        if thread_key:
            listeners = {thread_key: session.onboarding_listeners.get(thread_key)}
        else:
            listeners = session.onboarding_listeners.copy()

        for key, info in listeners.items():
            if not info:
                continue
            listener = info.get("listener")
            try:
                if listener:
                    listener.close()
                    logger.info(f"[ONBOARDING_LISTENER] üîö Listener arr√™t√© pour thread={key}")
            except Exception as e:
                logger.warning(f"[ONBOARDING_LISTENER] ‚ö†Ô∏è Erreur arr√™t listener thread={key}: {e}")
            finally:
                session.onboarding_listeners.pop(key, None)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # COEUR M√âTIER UNIFI√â - UI ET BACKEND
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    async def _process_unified_workflow(
        self,
        session: LLMSession,
        user_id: str,
        collection_name: str,
        thread_key: str,
        message: str,
        assistant_message_id: str,
        assistant_timestamp: str,
        enable_streaming: bool = True,
        chat_mode: str = "general_chat",
        system_prompt: str = None
        ):
        """
        Coeur m√©tier unifi√© pour traitement de messages en mode UI et BACKEND.
        
        ‚≠ê UNIFICATION : Cette m√©thode est utilis√©e par :
        - Mode UI : send_message() avec enable_streaming=True
        - Mode BACKEND : _resume_workflow_after_lpt() avec enable_streaming=False (ou True si user connect√©)
        - Mode SCHEDULER (futur) : avec enable_streaming=False
        
        Args:
            session: Session LLM (DOIT avoir user_context, jobs_data charg√©s)
            user_id: ID utilisateur Firebase
            collection_name: Nom soci√©t√©/collection
            thread_key: Cl√© du thread de conversation
            message: Message utilisateur ou continuation
            assistant_message_id: ID du message assistant (d√©j√† cr√©√© dans RTDB)
            assistant_timestamp: Timestamp du message assistant
            enable_streaming: Si True, broadcast chunks WebSocket (Mode UI)
                             Si False, accumule en silence (Mode BACKEND)
            chat_mode: Mode de chat actif (d√©termine prompt/outil)
            system_prompt: Prompt syst√®me optionnel
        
        Returns:
            dict: {"success": bool, "content": str, ...}
        """
        from ..ws_hub import hub
        from ..pinnokio_agentic_workflow.orchestrator.pinnokio_brain import PinnokioBrain
        
        ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
        messages_base_path = self._get_messages_base_path(collection_name, thread_key, chat_mode)
        accumulated_content = ""
        mode = "UI" if enable_streaming else "BACKEND"
        
        try:
            logger.info(
                f"[UNIFIED_WORKFLOW] üöÄ D√©marrage - mode={mode} chat_mode={chat_mode} thread={thread_key} "
                f"streaming={'ON' if enable_streaming else 'OFF'}"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : R√âCUP√âRER BRAIN POUR CE THREAD
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if thread_key not in session.active_brains:
                error_msg = (
                    f"Brain non trouv√© pour thread={thread_key}. "
                    f"load_chat_history() doit √™tre appel√© avant."
                )
                logger.error(f"[UNIFIED_WORKFLOW] ‚ùå {error_msg}")
                raise ValueError(error_msg)
            
            brain = session.active_brains[thread_key]
            logger.info(f"[UNIFIED_WORKFLOW] ‚úÖ Brain r√©cup√©r√© pour thread={thread_key}")

            if self._is_onboarding_like(chat_mode):
                # Charger les donn√©es selon le mode
                if chat_mode == "onboarding_chat":
                    await brain.load_onboarding_data()
                elif chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                    # Pour ces modes, le job_id est le thread_key
                    job_id = thread_key
                    await brain.load_job_data(job_id)
            
            # ‚≠ê D√âFINIR LE THREAD ACTIF (pour workflows d'approbation)
            brain.set_active_thread(thread_key)
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : CR√âER OUTILS (SPT/LPT)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            tools, tool_mapping = brain.create_workflow_tools(
                thread_key,
                session,
                chat_mode=chat_mode,
            )
            logger.info(f"[UNIFIED_WORKFLOW] Outils cr√©√©s: {len(tools)} outils")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : NOTIFIER D√âBUT (SI STREAMING ACTIV√â)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if enable_streaming:
                await hub.broadcast(user_id, {
                    "type": "llm_stream_start",
                    "channel": ws_channel,
                    "payload": {
                        "message_id": assistant_message_id,
                        "thread_key": thread_key,
                        "space_code": collection_name,
                        "mode": mode
                    }
                })
                logger.info(f"[UNIFIED_WORKFLOW] WebSocket stream_start envoy√©")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 4 : BOUCLE AGENTIC AVEC BUDGET TOKENS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            max_turns = 20  # Garde-fou temporaire
            max_tokens_budget = 80000  # Budget principal: 80K tokens
            turn_count = 0
            current_input = message
            mission_completed = False
            
            logger.info(
                f"[UNIFIED_WORKFLOW] Budget tokens: {max_tokens_budget:,} "
                f"(tours max: {max_turns})"
            )
            
            while turn_count < max_turns and not mission_completed:
                turn_count += 1
                
                # ‚îÄ‚îÄ‚îÄ V√âRIFICATION BUDGET TOKENS ‚îÄ‚îÄ‚îÄ
                try:
                    tokens_before = brain.pinnokio_agent.get_total_context_tokens(
                        brain.default_provider
                    )
                    
                    logger.info(
                        f"[UNIFIED_WORKFLOW] Tour {turn_count}/{max_turns} - "
                        f"Tokens: {tokens_before:,}/{max_tokens_budget:,}"
                    )
                    
                    # Si budget d√©pass√©, g√©n√©rer r√©sum√© et r√©initialiser
                    if tokens_before >= max_tokens_budget:
                        logger.warning(
                            f"[TOKENS] Budget atteint ({tokens_before:,} tokens) - "
                            f"R√©initialisation contexte"
                        )
                        
                        summary = brain.generate_conversation_summary(
                            thread_key=thread_key,
                            total_tokens_used=tokens_before
                        )
                        
                        tokens_after_reset = brain.reset_context_with_summary(summary)
                        
                        logger.info(
                            f"[TOKENS] Contexte r√©initialis√© - "
                            f"Avant: {tokens_before:,} ‚Üí Apr√®s: {tokens_after_reset:,}"
                        )
                        
                        tokens_before = tokens_after_reset
                        
                except Exception as e:
                    logger.warning(f"[TOKENS] Erreur calcul tokens: {e}")
                
                # Variables pour d√©tecter TEXT_OUTPUT simple
                tools_used_this_turn = False
                text_generated_this_turn = False
                
                # ‚îÄ‚îÄ‚îÄ APPEL AGENT AVEC STREAMING ‚îÄ‚îÄ‚îÄ
                async for event in brain.pinnokio_agent.process_tool_use_streaming(
                    content=current_input,
                    tools=tools,
                    tool_mapping=tool_mapping,
                    provider=brain.default_provider,
                    size=brain.default_size,  # Utiliser la taille par d√©faut du brain (REASONING_MEDIUM pour Groq/Kimi K2)
                    max_tokens=2048
                    ):
                    event_type = event.get("type")
                    
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    # CAS 1 : TEXTE (streaming normal)
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    if event_type == "text_chunk":
                        text_generated_this_turn = True
                        chunk = event.get("chunk")
                        accumulated_content += chunk
                        
                        # Broadcast SI streaming activ√©
                        if enable_streaming:
                            await hub.broadcast(user_id, {
                                "type": "llm_stream_chunk",
                                "channel": ws_channel,
                                "payload": {
                                    "message_id": assistant_message_id,
                                    "thread_key": thread_key,
                                    "space_code": collection_name,
                                    "chunk": chunk,
                                    "accumulated": accumulated_content
                                }
                            })
                    
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    # CAS 2 : D√âBUT D'UTILISATION D'OUTIL
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    elif event_type == "tool_use_start":
                        tool_name = event.get("tool_name")
                        logger.info(f"[UNIFIED_WORKFLOW] D√©but outil: {tool_name}")
                        
                        # Broadcast SI streaming activ√©
                        if enable_streaming:
                            await hub.broadcast(user_id, {
                                "type": "tool_use_start",
                                "channel": ws_channel,
                                "payload": {
                                    "message_id": assistant_message_id,
                                    "thread_key": thread_key,
                                    "tool_name": tool_name,
                                    "tool_icon": "üîÑ"
                                }
                            })
                    
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    # CAS 3 : OUTIL UTILIS√â (d√©cision prise)
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    elif event_type == "tool_use":
                        tools_used_this_turn = True
                        
                        tool_name = event.get("tool_name")
                        tool_input = event.get("tool_input")
                        tool_id = event.get("tool_id")
                        
                        logger.info(f"[UNIFIED_WORKFLOW] Outil utilis√©: {tool_name}")
                        
                        # ‚îÄ‚îÄ‚îÄ TERMINATE_TASK ‚îÄ‚îÄ‚îÄ
                        if tool_name == "TERMINATE_TASK":
                            conclusion = tool_input.get("conclusion", "")
                            accumulated_content += f"\n\n{conclusion}"

                            if enable_streaming:
                                await hub.broadcast(user_id, {
                                    "type": "llm_stream_chunk",
                                    "channel": ws_channel,
                                    "payload": {
                                        "message_id": assistant_message_id,
                                        "thread_key": thread_key,
                                        "chunk": f"\n\n{conclusion}",
                                        "is_final": True
                                    }
                                })

                            # ‚≠ê NOUVEAU: Finaliser l'ex√©cution de t√¢che si mode task_execution
                            await self._finalize_task_execution_if_needed(brain, tool_input)

                            # ‚úÖ CORRECTION: Ne pas break ici, laisser recevoir tool_result
                            # pour broadcast tool_use_complete proprement
                            mission_completed = True
                            # Le break se fera naturellement √† la fin du tour (ligne 2275)
                        
                        # ‚îÄ‚îÄ‚îÄ LPT (t√¢che longue) ‚îÄ‚îÄ‚îÄ
                        elif tool_name.startswith("LPT_"):
                            lpt_message = (
                                f"\n\nüîÑ T√¢che longue {tool_name} lanc√©e en arri√®re-plan.\n"
                                f"Je continue √† √™tre disponible pendant son ex√©cution."
                            )
                            accumulated_content += lpt_message
                            
                            if enable_streaming:
                                await hub.broadcast(user_id, {
                                    "type": "llm_stream_chunk",
                                    "channel": ws_channel,
                                    "payload": {
                                        "message_id": assistant_message_id,
                                        "thread_key": thread_key,
                                        "chunk": lpt_message
                                    }
                                })
                        
                        # ‚îÄ‚îÄ‚îÄ SPT (t√¢che courte) ‚îÄ‚îÄ‚îÄ
                        else:
                            # SPT ex√©cut√©, feedback ajout√© automatiquement
                            pass
                    
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    # CAS 4 : R√âSULTAT D'OUTIL
                    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    elif event_type == "tool_result":
                        tool_name = event.get("tool_name")
                        tool_result = event.get("result")
                        logger.info(f"[UNIFIED_WORKFLOW] R√©sultat outil re√ßu")
                        
                        # Notifier fin d'utilisation d'outil
                        if enable_streaming:
                            await hub.broadcast(user_id, {
                                "type": "tool_use_complete",
                                "channel": ws_channel,
                                "payload": {
                                    "message_id": assistant_message_id,
                                    "thread_key": thread_key,
                                    "tool_name": tool_name,
                                    "success": "error" not in tool_result if tool_result else True
                                }
                            })
                        
                        # Le r√©sultat sera r√©inject√© dans le prochain tour
                
                # ‚îÄ‚îÄ‚îÄ FIN DU TOUR : Pr√©parer prochain input ‚îÄ‚îÄ‚îÄ
                if mission_completed:
                    break
                
                # Si que du texte (pas d'outils) ‚Üí Mission compl√©t√©e
                if text_generated_this_turn and not tools_used_this_turn:
                    logger.info(
                        f"[UNIFIED_WORKFLOW] Texte simple sans outils ‚Üí "
                        f"Mission compl√©t√©e"
                    )
                    mission_completed = True
                    break
                
                # Continuer avec feedback des outils
                # (Le feedback est d√©j√† dans l'historique du provider)
                current_input = ""  # Input vide pour continuer avec l'historique
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 5 : √âCRITURE FINALE RTDB (TOUJOURS, UI ET BACKEND)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
            assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
            
            # ‚≠ê Utiliser le formatter pour garantir compatibilit√© UI
            final_message_data = self.rtdb_formatter.format_ai_message(
                content=accumulated_content,
                user_id=user_id,
                message_id=assistant_message_id,
                timestamp=assistant_timestamp,
                metadata={
                    "status": "complete",
                    "streaming_progress": 1.0,
                    "mode": mode,
                    "turns": turn_count,
                    "mission_completed": mission_completed,
                    "completed_at": datetime.now(timezone.utc).isoformat()
                }
            )
            
            assistant_msg_ref.set(final_message_data)
            
            logger.info(
                f"[UNIFIED_WORKFLOW] Message final √©crit dans RTDB - "
                f"length={len(accumulated_content)}"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 6 : NOTIFIER FIN (SI STREAMING ACTIV√â)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if enable_streaming:
                await hub.broadcast(user_id, {
                    "type": "llm_stream_complete",
                    "channel": ws_channel,
                    "payload": {
                        "message_id": assistant_message_id,
                        "thread_key": thread_key,
                        "full_content": accumulated_content,
                        "turns": turn_count,
                        "mission_completed": mission_completed
                    }
                })
                logger.info(f"[UNIFIED_WORKFLOW] WebSocket stream_complete envoy√©")
            
            logger.info(
                f"[UNIFIED_WORKFLOW] ‚úÖ Termin√© - mode={mode} "
                f"turns={turn_count} content_length={len(accumulated_content)}"
            )
            
            return {
                "success": True,
                "content": accumulated_content,
                "turns": turn_count,
                "mission_completed": mission_completed,
                "mode": mode
            }
            
        except asyncio.CancelledError:
            # Gestion sp√©cifique de l'interruption par l'utilisateur
            logger.info(
                f"[UNIFIED_WORKFLOW] ‚è∏Ô∏è Streaming interrompu par l'utilisateur - "
                f"thread={thread_key} content_length={len(accumulated_content)}"
            )
            
            # Sauvegarder le contenu accumul√© jusqu'√† l'interruption
            try:
                assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
                assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
                assistant_msg_ref.update({
                    "content": accumulated_content
                })
                logger.info(f"[UNIFIED_WORKFLOW] üíæ Contenu partiel sauvegard√© dans RTDB")
            except Exception as update_error:
                logger.error(
                    f"[UNIFIED_WORKFLOW] Erreur sauvegarde contenu partiel: {update_error}"
                )
            
            # Notifier interruption via WebSocket (si streaming activ√©)
            if enable_streaming:
                try:
                    await hub.broadcast(user_id, {
                        "type": "llm_stream_interrupted",
                        "channel": ws_channel,
                        "payload": {
                            "message_id": assistant_message_id,
                            "thread_key": thread_key,
                            "accumulated_content": accumulated_content,
                            "reason": "user_cancelled"
                        }
                    })
                    logger.info(f"[UNIFIED_WORKFLOW] üì° Notification interruption envoy√©e")
                except Exception as broadcast_error:
                    logger.error(
                        f"[UNIFIED_WORKFLOW] Erreur notification interruption: {broadcast_error}"
                    )
            
            # Re-raise pour propager l'annulation
            raise
            
        except Exception as e:
            logger.error(f"[UNIFIED_WORKFLOW] ‚ùå Erreur: {e}", exc_info=True)
            
            # Marquer comme erreur dans RTDB (toujours)
            try:
                assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
                assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
                assistant_msg_ref.update({
                    "status": "error",
                    "error": str(e),
                    "error_at": datetime.now(timezone.utc).isoformat()
                })
            except Exception as update_error:
                logger.error(
                    f"[UNIFIED_WORKFLOW] Erreur mise √† jour erreur RTDB: {update_error}"
                )
            
            # Notifier erreur (si streaming activ√©)
            if enable_streaming:
                try:
                    await hub.broadcast(user_id, {
                        "type": "llm_stream_error",
                        "channel": ws_channel,
                        "payload": {
                            "message_id": assistant_message_id,
                            "error": str(e)
                        }
                    })
                except Exception:
                    pass
            
            return {
                "success": False,
                "error": str(e),
                "mode": mode
            }
        
        finally:
            # D√©senregistrer le stream dans tous les cas (succ√®s, erreur, annulation)
            try:
                await self.streaming_controller.unregister_stream(
                    session_key=f"{user_id}:{collection_name}",
                    thread_key=thread_key
                )
                logger.info(
                    f"[UNIFIED_WORKFLOW] üßπ Stream d√©senregistr√© - "
                    f"session={user_id}:{collection_name} thread={thread_key}"
                )
            except Exception as cleanup_error:
                logger.error(
                    f"[UNIFIED_WORKFLOW] Erreur d√©senregistrement stream: {cleanup_error}"
                )
    
   
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # M√âTHODES AUXILIAIRES POUR LPT
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    

    async def handle_approval_response(
        self,
        user_id: str,
        thread_key: str,
        plan_id: str,
        approved: bool,
        collection_name: str = "",
        user_comment: str = ""
        ):
        """
        Appel√© quand l'utilisateur r√©pond √† une demande d'approbation.
        Cette m√©thode sera appel√©e via WebSocket ou RPC depuis Reflex.
        
        Args:
            user_id: Firebase user ID
            thread_key: Chat thread key
            plan_id: Unique plan ID
            approved: True if approved, False if rejected
            collection_name: Company ID (for validation and logging)
            user_comment: Optional user comment explaining the decision
            
        Returns:
            dict: {"success": bool, "error": str (if failure)}
        """
        approval_key = f"{user_id}:{thread_key}:{plan_id}"
        
        # Logging enrichi avec collection_name et commentaire
        log_msg = f"[APPROBATION] {user_id}"
        if collection_name:
            log_msg += f"@{collection_name}"
        log_msg += f" - plan={plan_id} - {'‚úÖ APPROUV√â' if approved else '‚ùå REFUS√â'}"
        logger.info(log_msg)
        
        if user_comment:
            logger.info(f"[APPROBATION] Commentaire utilisateur: {user_comment}")
        
        if not hasattr(self, 'pending_approvals'):
            logger.warning(f"[APPROBATION] Aucune approbation en attente pour: {approval_key}")
            return {"success": False, "error": "No pending approval system initialized"}
        
        future = self.pending_approvals.get(approval_key)
        
        if future and not future.done():
            # R√©soudre le Future avec approved ET user_comment
            future.set_result({
                "approved": approved,
                "user_comment": user_comment,
                "collection_name": collection_name
            })
            logger.info(f"[APPROBATION] R√©ponse enregistr√©e avec succ√®s: {approval_key}")
            return {"success": True}
        else:
            logger.warning(f"[APPROBATION] Future non trouv√©e ou d√©j√† termin√©e: {approval_key}")
            return {"success": False, "error": "No pending approval found or already processed"}
    
    async def _resume_workflow_after_lpt(
        self,
        user_id: str,
        company_id: str,
        thread_key: str,
        task_id: str,
        task_data: dict,
        lpt_response: dict,
        original_payload: dict,
        user_connected: bool,
        is_planned_task: bool = False
        ):
        """
        Point d'entr√©e MODE BACKEND/UI : Reprend le workflow apr√®s qu'un LPT ait termin√©.
        
        ‚≠ê COMPORTEMENT ADAPTATIF :
        
        CAS 1 - T√¢che Planifi√©e (is_planned_task=True) :
        - Checklist existe ‚Üí Demander UPDATE_STEP
        - Prompt syst√®me avec instructions checklist
        - Mode UI ou BACKEND selon user_connected
        
        CAS 2 - LPT Simple + User Actif (is_planned_task=False + user_connected=True) :
        - Session active ‚Üí Chat history d√©j√† charg√©
        - Message simple sans mention de checklist
        - Pas de prompt syst√®me sp√©cial
        - R√©ponse LPT inject√©e comme continuation naturelle
        
        CAS 3 - LPT Simple + User Inactif (is_planned_task=False + user_connected=False) :
        - Charger historique RTDB
        - Message simple sauvegard√© dans RTDB
        - User verra au retour
        
        Args:
            user_id: ID Firebase de l'utilisateur
            company_id: ID de la soci√©t√© (collection_name)
            thread_key: Cl√© du thread de conversation
            task_id: ID de la t√¢che LPT qui a termin√©
            task_data: Donn√©es de la t√¢che (d√©j√† r√©cup√©r√©es depuis Firebase)
            lpt_response: R√©ponse du LPT (status, result, error, etc.)
            original_payload: Payload complet envoy√© au LPT (format englobeur)
            user_connected: True si user sur ce thread (Mode UI), False sinon (Mode BACKEND)
            is_planned_task: True si t√¢che planifi√©e (avec checklist), False si LPT simple
        """
        # ‚≠ê CORRECTION : Import de hub pour les broadcasts WebSocket
        from ..ws_hub import hub
        
        messages_base_path = self._get_messages_base_path(company_id, thread_key, None)

        try:
            mode = "UI" if user_connected else "BACKEND"
            
            logger.info(
                f"[WORKFLOW_RESUME] üöÄ MODE {mode} - user={user_id} company={company_id} "
                f"thread={thread_key} task={task_id} is_planned_task={is_planned_task}"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 1 : GARANTIR INITIALISATION SESSION (‚≠ê CRITIQUE)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            session = await self._ensure_session_initialized(
                user_id=user_id,
                collection_name=company_id,
                chat_mode="general_chat"
            )
            
            logger.info(
                f"[WORKFLOW_RESUME] ‚úÖ Session garantie avec donn√©es permanentes "
                f"(user_context, jobs_data, jobs_metrics)"
            )
            messages_base_path = self._get_messages_base_path(
                company_id, thread_key, session.context.chat_mode
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : GARANTIR BRAIN POUR CE THREAD
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if thread_key not in session.active_brains:
                logger.warning(
                    f"[WORKFLOW_RESUME] ‚ö†Ô∏è Brain non trouv√© pour thread={thread_key}, "
                    f"chargement automatique..."
                )
                
                # Charger historique depuis RTDB
                history = await self._load_history_from_rtdb(company_id, thread_key, session.context.chat_mode)
                
                # Cr√©er brain pour ce thread
                load_result = await self.load_chat_history(
                    user_id=user_id,
                    collection_name=company_id,
                    thread_key=thread_key,
                    history=history
                )
                
                if not load_result.get("success"):
                    logger.error(
                        f"[WORKFLOW_RESUME] ‚ùå √âchec cr√©ation brain: {load_result}"
                    )
                    return
                
                logger.info(f"[WORKFLOW_RESUME] ‚úÖ Brain cr√©√© automatiquement")
            else:
                logger.info(f"[WORKFLOW_RESUME] ‚úÖ Brain existant trouv√©")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 3 : R√âCUP√âRER MISSION DEPUIS FIREBASE (si execution_id)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            brain = session.active_brains.get(thread_key)
            mission_data = None
            execution_data = None
            task_id = None
            execution_id = None
            mandate_path = None
            
            if brain and self._is_onboarding_like(session.context.chat_mode):
                # Charger les donn√©es selon le mode
                if session.context.chat_mode == "onboarding_chat":
                    await brain.load_onboarding_data()
                elif session.context.chat_mode in ("router_chat", "banker_chat", "apbookeeper_chat"):
                    # Pour ces modes, le job_id est le thread_key
                    job_id = thread_key
                    await brain.load_job_data(job_id)
                log_entries = await self._load_onboarding_log_history(
                    brain=brain,
                    collection_name=company_id,
                    session=session,
                    thread_key=thread_key
                )
                await self._ensure_onboarding_listener(
                    session=session,
                    brain=brain,
                    collection_name=company_id,
                    thread_key=thread_key,
                    initial_entries=log_entries
                )

            # Essayer de r√©cup√©rer les IDs depuis brain.active_task_data
            if brain and hasattr(brain, 'active_task_data') and brain.active_task_data:
                task_id = brain.active_task_data.get("task_id")
                execution_id = brain.active_task_data.get("execution_id")
                mandate_path = brain.active_task_data.get("mandate_path")
                logger.info(f"[WORKFLOW_RESUME] IDs r√©cup√©r√©s depuis brain.active_task_data")
            
            # Sinon, essayer depuis le traceability du payload original
            if not (task_id and execution_id):
                traceability = original_payload.get("traceability", {})
                execution_id = traceability.get("execution_id")
                mandate_path = original_payload.get("mandates_path")
                # Pour task_id, on peut utiliser batch_id ou chercher dans Firebase
                if execution_id and mandate_path:
                    logger.info(f"[WORKFLOW_RESUME] execution_id trouv√© dans traceability: {execution_id}")
            
            # Si on a execution_id et mandate_path, r√©cup√©rer la mission depuis Firebase
            if execution_id and mandate_path:
                try:
                    from ..firebase_providers import get_firebase_management
                    fbm = get_firebase_management()
                    
                    # Si on n'a pas task_id, essayer de le trouver via l'execution
                    if not task_id:
                        # L'execution_id contient normalement le task_id
                        # Format: exec_{task_id}_{timestamp}
                        # On doit chercher dans Firebase
                        logger.warning(f"[WORKFLOW_RESUME] task_id manquant, impossible de r√©cup√©rer mission")
                    else:
                        # R√©cup√©rer execution depuis Firebase
                        execution_data = fbm.get_task_execution(mandate_path, task_id, execution_id)
                        
                        if execution_data:
                            mission_data = execution_data.get("mission")
                            logger.info(
                                f"[WORKFLOW_RESUME] ‚úÖ Mission r√©cup√©r√©e depuis Firebase: "
                                f"task_id={task_id}, execution_id={execution_id}"
                            )
                        else:
                            logger.warning(
                                f"[WORKFLOW_RESUME] ‚ö†Ô∏è Execution non trouv√©e dans Firebase: "
                                f"task_id={task_id}, execution_id={execution_id}"
                            )
                except Exception as e:
                    logger.warning(f"[WORKFLOW_RESUME] ‚ö†Ô∏è Erreur r√©cup√©ration mission: {e}")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 4 : CONSTRUIRE PROMPT SYST√àME + MESSAGE (ADAPTATIF)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            # R√©cup√©rer user_context depuis session
            user_context = session.user_context or {}
            
            # ‚≠ê COMPORTEMENT ADAPTATIF selon le type de t√¢che
            if is_planned_task:
                # ‚ïê‚ïê‚ïê CAS 1 : T√ÇCHE PLANIFI√âE (avec checklist) ‚ïê‚ïê‚ïê
                logger.info(f"[WORKFLOW_RESUME] üìã T√¢che planifi√©e ‚Üí Prompt avec checklist")
                
                # Construire prompt syst√®me de base
                from ...pinnokio_agentic_workflow.orchestrator.system_prompt_principal_agent import build_principal_agent_prompt
                base_system_prompt = build_principal_agent_prompt(
                    user_context=user_context,
                    jobs_metrics=session.jobs_metrics or {}
                )
            
                # Construire le prompt callback LPT avec instructions checklist
                from ...pinnokio_agentic_workflow.orchestrator.system_prompt_lpt_callback import build_lpt_callback_prompt
                lpt_callback_addition = build_lpt_callback_prompt(
                    user_context=user_context,
                    lpt_response=lpt_response,
                    original_payload=original_payload
                )
                
                # Si mission disponible, ajouter le context de la t√¢che
                if mission_data:
                    task_context_addition = self._build_task_execution_addition(
                        mission=mission_data,
                        last_report=execution_data.get("last_execution_report") if execution_data else None,
                        execution_plan=original_payload.get("traceability", {}).get("execution_plan")
                    )
                    lpt_callback_system_prompt = f"{base_system_prompt}\n\n{task_context_addition}\n\n{lpt_callback_addition}"
                else:
                    lpt_callback_system_prompt = f"{base_system_prompt}\n\n{lpt_callback_addition}"
                
            else:
                # ‚ïê‚ïê‚ïê CAS 2 : LPT SIMPLE (sans checklist) ‚ïê‚ïê‚ïê
                logger.info(f"[WORKFLOW_RESUME] üí¨ LPT simple ‚Üí Pas de prompt sp√©cial")
                
                # Pas de prompt syst√®me sp√©cial pour LPT simple
                # L'agent continue naturellement la conversation
                lpt_callback_system_prompt = None
            
            logger.info(f"[WORKFLOW_RESUME] ‚úÖ Configuration prompt termin√©e (is_planned={is_planned_task})")
            
            # Extraire informations pour le message
            task_type = original_payload.get("task_type", "LPT")
            status = lpt_response.get("status", "completed")
            result = lpt_response.get("result", {})
            summary = result.get("summary", "T√¢che termin√©e") if result else "T√¢che termin√©e"
            error = lpt_response.get("error")
            
            # ‚≠ê CONSTRUCTION MESSAGE ADAPTATIF selon le type
            if is_planned_task:
                # ‚ïê‚ïê‚ïê CAS 1 : T√ÇCHE PLANIFI√âE ‚Üí Demander UPDATE_STEP ‚ïê‚ïê‚ïê
                if status == "completed":
                    continuation_message = f"""
                        üîÑ **R√âPONSE DE L'OUTIL {task_type}**

                        ‚úÖ **{summary}**

                        ---

                        ‚ö†Ô∏è **ACTIONS REQUISES** :

                        1. **METTRE √Ä JOUR LA CHECKLIST** (üî¥ PRIORIT√â ABSOLUE)
                        - Utilisez `UPDATE_STEP` pour marquer l'√©tape concern√©e comme termin√©e
                        - Message : "{summary}"

                        2. **ANALYSER ET CONTINUER**
                        - Consultez votre plan initial (dans l'historique)
                        - D√©terminez la prochaine √©tape ou terminez si tout est fait
                        - Ajustez le plan si n√©cessaire selon les r√©sultats

                        **Rappel** : Vous avez acc√®s √† tous les outils (SPT et LPT) pour continuer le workflow.
                        """
                elif status == "failed":
                    continuation_message = f"""
                        üîÑ **R√âPONSE DE L'OUTIL {task_type}**

                        ‚ùå **{error or "√âchec de l'ex√©cution"}**

                        ---

                        ‚ö†Ô∏è **ACTIONS REQUISES** :

                        1. **METTRE √Ä JOUR LA CHECKLIST** (üî¥ PRIORIT√â ABSOLUE)
                        - Utilisez `UPDATE_STEP` pour marquer l'√©tape comme "error"
                        - Message : "‚ùå {error or '√âchec'}"

                        2. **ANALYSER ET D√âCIDER**
                        - Proposez des actions correctives
                        - Ajustez le plan si n√©cessaire
                        - Continuez ou terminez avec un rapport d'√©chec

                        **Rappel** : G√©rez l'√©chec de mani√®re proactive et proposez une solution.
                        """
                else:  # partial
                    continuation_message = f"""
                    üîÑ **R√âPONSE DE L'OUTIL {task_type}**

                    ‚ö†Ô∏è **{summary}**

                    ---

                    ‚ö†Ô∏è **ACTIONS REQUISES** :

                    1. **METTRE √Ä JOUR LA CHECKLIST** (üî¥ PRIORIT√â ABSOLUE)
                    - Utilisez `UPDATE_STEP` avec status appropri√©
                    - Message : "‚ö†Ô∏è {summary}"

                    2. **ANALYSER ET CONTINUER**
                    - Expliquez pourquoi le r√©sultat est partiel
                    - Proposez des actions pour compl√©ter (relancer, ajuster, etc.)
                    - Continuez selon le plan ajust√©

                    **Rappel** : Un r√©sultat partiel n√©cessite une attention particuli√®re.
                    """
            else:
                # ‚ïê‚ïê‚ïê CAS 2 : LPT SIMPLE ‚Üí Message simple, pas de checklist ‚ïê‚ïê‚ïê
                if status == "completed":
                    # R√©sultat d√©taill√© si disponible
                    result_details = ""
                    if result and isinstance(result, dict):
                        processed_items = result.get("processed_items", 0)
                        if processed_items:
                            result_details = f"\n\n**Items trait√©s** : {processed_items}"
                    
                    continuation_message = f"‚úÖ {task_type} termin√© avec succ√®s.\n\n**R√©sultat** : {summary}{result_details}"
                
                elif status == "failed":
                    continuation_message = f"‚ùå {task_type} a √©chou√©.\n\n**Erreur** : {error or 'Erreur inconnue'}"
                
                else:  # partial
                    continuation_message = f"‚ö†Ô∏è {task_type} termin√© partiellement.\n\n**R√©sum√©** : {summary}"
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 5 : PR√âPARER MESSAGE RTDB
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            assistant_message_id = str(uuid.uuid4())
            assistant_timestamp = datetime.now(timezone.utc).isoformat()
            
            assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
            assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
            
            # ‚≠ê CRITIQUE : Pour les callbacks LPT, broadcaster AVANT de cr√©er le message RTDB
            # Cela permet √† Reflex de cr√©er le placeholder SYNCHRONEMENT avant que les chunks n'arrivent
            if user_connected:
                ws_channel = f"chat:{user_id}:{company_id}:{thread_key}"
                
                placeholder_event = {
                    "type": "assistant_message_placeholder",
                    "channel": ws_channel,
                    "payload": {
                        "message_id": assistant_message_id,  # ‚úÖ Structure standard : message_id (comme llm_stream_start)
                        "thread_key": thread_key,
                        "space_code": company_id,
                        "timestamp": assistant_timestamp,
                        "triggered_by": "lpt_callback",
                        "mode": mode,
                        "task_id": task_id,
                        "task_type": task_type
                    }
                }
                
                await hub.broadcast(user_id, placeholder_event)
                logger.info(f"[WORKFLOW_RESUME] ‚ö° Signal placeholder envoy√© au frontend (message_id={assistant_message_id})")
            
            # ‚≠ê Utiliser le formatter pour garantir compatibilit√© UI
            initial_message_data = self.rtdb_formatter.format_ai_message(
                content="",
                user_id=user_id,
                message_id=assistant_message_id,
                timestamp=assistant_timestamp,
                metadata={
                    "status": "streaming" if user_connected else "thinking",  # ‚úÖ CORRECTION : M√™me status que send_message pour activer streaming UI
                    "streaming_progress": 0.0 if user_connected else None,
                    "triggered_by": "lpt_callback",
                    "mode": mode,
                    "task_id": task_id,
                    "task_type": task_type
                }
            )
            
            assistant_msg_ref.set(initial_message_data)
            
            logger.info(f"[WORKFLOW_RESUME] Message RTDB initial cr√©√©")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 6 : LANCER WORKFLOW UNIFI√â AVEC PROMPT SP√âCIAL
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            result = await self._process_unified_workflow(
                session=session,
                user_id=user_id,
                collection_name=company_id,
                thread_key=thread_key,
                message=continuation_message,
                assistant_message_id=assistant_message_id,
                assistant_timestamp=assistant_timestamp,
                enable_streaming=user_connected,  # ‚Üê Streaming conditionnel bas√© sur connexion user
                chat_mode=session.context.chat_mode,
                system_prompt=lpt_callback_system_prompt  # ‚≠ê NOUVEAU : Prompt syst√®me sp√©cial callback
            )
            
            if result.get("success"):
                logger.info(
                    f"[WORKFLOW_RESUME] ‚úÖ Termin√© avec succ√®s - mode={mode} "
                    f"content_length={len(result.get('content', ''))}"
                )
            else:
                logger.error(
                    f"[WORKFLOW_RESUME] ‚ùå √âchec workflow - mode={mode} "
                    f"error={result.get('error')}"
                )
            
        except Exception as e:
            logger.error(f"[WORKFLOW_RESUME] ‚ùå Erreur: {e}", exc_info=True)
            
            # Tenter de marquer comme erreur dans RTDB
            try:
                assistant_msg_path = f"{messages_base_path}/{assistant_message_id}"
                assistant_msg_ref = self._get_rtdb_ref(assistant_msg_path)
                assistant_msg_ref.update({
                    "status": "error",
                    "error": str(e),
                    "error_at": datetime.now(timezone.utc).isoformat()
                })
            except Exception as update_error:
                logger.error(
                    f"[WORKFLOW_RESUME] Erreur mise √† jour erreur RTDB: {update_error}"
                )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # SYST√àME D'APPROBATION G√âN√âRIQUE VIA CARTES INTERACTIVES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    async def request_approval_with_card(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        card_type: str,
        card_params: Dict[str, Any],
        timeout: int = 900,
        assistant_message_id: str = None
        ) -> Dict[str, Any]:
        """
        Workflow complet d'approbation via carte interactive.
        
        üîÑ FLUX COMPLET :
        1. Construction carte (via ApprovalCardBuilder)
        2. G√©n√©ration message_id unique
        3. Envoi WebSocket (type: "CARD")
        4. Sauvegarde RTDB (persistence)
        5. Cr√©ation Future (attente r√©ponse)
        6. Attente avec timeout (15 min par d√©faut)
        7. R√©solution Future (via RPC send_card_response)
        8. Mise √† jour RTDB (status: responded/timeout)
        9. Retour r√©sultat
        
        Args:
            user_id: ID Firebase utilisateur
            collection_name: ID soci√©t√© (space_code)
            thread_key: Cl√© du thread de chat
            card_type: Type de carte ('approval_card', 'text_modification_approval')
            card_params: Param√®tres sp√©cifiques √† la carte
                Exemple approval_card:
                {
                    "title": "Confirmer l'action",
                    "subtitle": "Saisie de 5 factures",
                    "text": "D√©tails...",
                    "input_label": "Commentaire optionnel",
                    "button_text": "Approuver"
                }
                
                Exemple text_modification_approval:
                {
                    "context_type": "router",
                    "original_text": "...",
                    "operations_log": [...],
                    "final_text": "...",
                    "warnings": [...]
                }
            timeout: Timeout en secondes (d√©faut: 900s = 15 min)
            assistant_message_id: ID message assistant (pour lien visuel)
            
        Returns:
            {
                "approved": bool,
                "action": str,  # 'approve_four_eyes' | 'reject_four_eyes'
                "user_message": str,
                "card_message_id": str,
                "responded_at": str (ISO),
                "timeout": bool
            }
        
        Raises:
            ValueError: Si card_type inconnu
            Exception: Si erreur construction/envoi
        """
        from ..ws_hub import hub
        
        try:
            logger.info(
                f"[APPROVAL_CARD] üÉè Demande approbation - "
                f"type={card_type}, thread={thread_key}"
            )
            session_key = f"{user_id}:{collection_name}"
            with self._lock:
                session = self.sessions.get(session_key)

            chat_mode = session.context.chat_mode if session else None
            messages_base_path = self._get_messages_base_path(
                collection_name, thread_key, chat_mode
            )
            
            # ‚ïê‚ïê‚ïê √âTAPE 1 : Construction de la carte ‚ïê‚ïê‚ïê
            builder = ApprovalCardBuilder()
            
            if card_type == "approval_card":
                card_content = builder.build_approval_card(
                    card_id=card_type,
                    **card_params
                )
            elif card_type == "task_creation_approval":
                # Carte d'approbation de cr√©ation de t√¢che (m√™me format que approval_card)
                card_content = builder.build_approval_card(
                    card_id=card_type,
                    execution_mode=card_params.get("execution_mode"),  # ‚úÖ Passer le mode d'ex√©cution
                    **{k: v for k, v in card_params.items() if k != "execution_mode"}
                )
            elif card_type == "text_modification_approval":
                card_content = builder.build_text_modification_card(**card_params)
            else:
                raise ValueError(f"Type de carte inconnu: {card_type}")
            
            logger.info(f"[APPROVAL_CARD] ‚úÖ Carte construite: {card_type}")
            
            # ‚ïê‚ïê‚ïê √âTAPE 2 : G√©n√©ration IDs ‚ïê‚ïê‚ïê
            card_message_id = f"card_{uuid.uuid4().hex[:12]}"
            approval_key = f"{user_id}:{thread_key}:{card_message_id}"
            
            # ‚ïê‚ïê‚ïê √âTAPE 3 : Cr√©ation Future ‚ïê‚ïê‚ïê
            approval_future = asyncio.Future()
            
            if not hasattr(self, 'pending_approvals'):
                self.pending_approvals = {}
            
            self.pending_approvals[approval_key] = approval_future
            
            logger.info(
                f"[APPROVAL_CARD] Future cr√©√©: {approval_key} "
                f"(timeout={timeout}s)"
            )
            
            # ‚ïê‚ïê‚ïê √âTAPE 4 : Construction message WebSocket ‚ïê‚ïê‚ïê
            ws_message = {
                "type": "CARD",
                "thread_key": thread_key,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "message_id": card_message_id,
                "content": json.dumps(card_content)  # ‚Üê IMPORTANT: JSON stringifi√©
            }
            
            # ‚ïê‚ïê‚ïê √âTAPE 5 : Envoi WebSocket ‚ïê‚ïê‚ïê
            ws_channel = f"chat:{user_id}:{collection_name}:{thread_key}"
            
            await hub.broadcast(user_id, {
                "type": "CARD",  # ‚úÖ Type explicite et coh√©rent avec llm_stream_*, tool_use_*
                "channel": ws_channel,
                "payload": ws_message
            })
            
            logger.info(f"[APPROVAL_CARD] üì° Carte envoy√©e via WebSocket")
            
            # ‚ïê‚ïê‚ïê √âTAPE 6 : Sauvegarde RTDB (OBLIGATOIRE pour persistence) ‚ïê‚ïê‚ïê
            rtdb_path = f"{messages_base_path}/{card_message_id}"
            rtdb_ref = self._get_rtdb_ref(rtdb_path)
            
            rtdb_ref.set({
                **ws_message,
                "role": "assistant",  # ‚Üê Pour coh√©rence avec messages chat
                "status": "pending_approval",
                "created_at": datetime.now(timezone.utc).isoformat(),
                "timeout_at": (datetime.now(timezone.utc) + timedelta(seconds=timeout)).isoformat(),
                "card_type": card_type
            })
            
            logger.info(f"[APPROVAL_CARD] üíæ Carte sauvegard√©e dans RTDB: {rtdb_path}")
            
            # ‚ïê‚ïê‚ïê √âTAPE 6.5 : Envoi notification de message direct ‚ïê‚ïê‚ïê
            notif_message_id = None
            try:
                from ..firebase_providers import FirebaseRealtimeChat
                
                # R√©cup√©rer le nom du thread
                realtime = FirebaseRealtimeChat()
                
                preferred_mode = self._resolve_messages_container(chat_mode)
                chat_name = realtime.get_thread_name(
                    space_code=collection_name,
                    thread_key=thread_key,
                    mode=preferred_mode
                )

                if not chat_name and preferred_mode != 'chats':
                    chat_name = realtime.get_thread_name(
                        space_code=collection_name,
                        thread_key=thread_key,
                        mode='chats'
                    )

                if not chat_name:
                    chat_name = realtime.get_thread_name(
                        space_code=collection_name,
                        thread_key=thread_key,
                        mode='job_chats'
                    )
                
                # Si toujours pas trouv√©, fallback sur thread_key
                if not chat_name:
                    chat_name = thread_key
                    logger.warning(
                        f"[APPROVAL_CARD] ‚ö†Ô∏è thread_name non trouv√© dans 'chats' ni 'job_chats', "
                        f"utilisation de thread_key comme fallback"
                    )
                
                # Construire le message de notification
                direct_message_notif = {
                    "file_name": f"Approbation - {card_type}",
                    "job_id": card_message_id,
                    "file_id": None,
                    "function_name": "Chat",
                    "collection_id": collection_name,
                    "status": "Action required",
                    "timestamp": str(datetime.now()),
                    "chat_mode": chat_mode or "general_chat",
                    "thread_key": thread_key,
                    "chat_name": chat_name  # ‚úÖ Utiliser le thread_name r√©cup√©r√©
                }
                
                notif_message_id = realtime.send_direct_message(user_id, user_id, direct_message_notif)
                
                logger.info(
                    f"[APPROVAL_CARD] üîî Notification envoy√©e - "
                    f"notif_id={notif_message_id}"
                )
            except Exception as notif_error:
                logger.warning(
                    f"[APPROVAL_CARD] ‚ö†Ô∏è √âchec envoi notification: {notif_error}"
                )
                # Continuer m√™me si notification √©choue
            
            # ‚ïê‚ïê‚ïê √âTAPE 7 : Attente r√©ponse avec timeout ‚ïê‚ïê‚ïê
            try:
                logger.info(
                    f"[APPROVAL_CARD] ‚è≥ Attente r√©ponse utilisateur "
                    f"(timeout={timeout}s)..."
                )
                
                result = await asyncio.wait_for(approval_future, timeout=timeout)
                
                # Mise √† jour RTDB
                rtdb_ref.update({
                    "status": "responded",
                    "responded_at": datetime.now(timezone.utc).isoformat(),
                    "action": result.get("action"),
                    "user_message": result.get("user_message", "")
                })
                
                logger.info(
                    f"[APPROVAL_CARD] ‚úÖ R√©ponse re√ßue - "
                    f"approved={result.get('approved')}"
                )
                
                return result
                
            except asyncio.TimeoutError:
                # Mise √† jour RTDB
                rtdb_ref.update({
                    "status": "timeout",
                    "timeout_at": datetime.now(timezone.utc).isoformat()
                })
                
                logger.warning(
                    f"[APPROVAL_CARD] ‚è∞ Timeout - Aucune r√©ponse apr√®s {timeout}s"
                )
                
                return {
                    "approved": False,
                    "timeout": True,
                    "card_message_id": card_message_id,
                    "reason": "timeout"
                }
                
            finally:
                # Nettoyer
                self.pending_approvals.pop(approval_key, None)
                logger.info(f"[APPROVAL_CARD] üßπ Future nettoy√©: {approval_key}")
                
                # Supprimer la notification de message direct
                if notif_message_id:
                    try:
                        from ..firebase_providers import FirebaseRealtimeChat
                        realtime = FirebaseRealtimeChat()  # ‚úÖ Singleton - pas d'argument
                        realtime.delete_direct_message(user_id, notif_message_id)
                        logger.info(
                            f"[APPROVAL_CARD] üóëÔ∏è Notification supprim√©e - "
                            f"notif_id={notif_message_id}"
                        )
                    except Exception as del_error:
                        logger.warning(
                            f"[APPROVAL_CARD] ‚ö†Ô∏è √âchec suppression notification: {del_error}"
                        )
        
        except Exception as e:
            logger.error(
                f"[APPROVAL_CARD] ‚ùå Erreur workflow approbation: {e}",
                exc_info=True
            )
            raise
    
    async def send_card_response(
        self,
        user_id: str,
        collection_name: str,
        thread_key: str,
        card_name: str,
        card_message_id: str,
        action: str,
        user_message: str = ""
        ) -> Dict[str, Any]:
        """
        Point de terminaison RPC pour r√©ception de r√©ponse carte.
        
        Appel√© par Reflex via LLM.send_card_response.
        
        Args:
            user_id: ID Firebase utilisateur
            collection_name: ID soci√©t√©
            thread_key: Cl√© du thread
            card_name: Type de carte (ex: 'approval_card', 'text_modification_approval')
            card_message_id: ID du message RTDB
            action: Action utilisateur ('approve_four_eyes', 'reject_four_eyes', etc.)
            user_message: Commentaire optionnel
            
        Returns:
            {"success": bool, "error": str (si √©chec)}
        """
        approval_key = f"{user_id}:{thread_key}:{card_message_id}"
        
        logger.info(
            f"[CARD_RESPONSE] üì• R√©ception r√©ponse - "
            f"card={card_name}, action={action}, key={approval_key}"
        )
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # √âTAPE 1 : V√âRIFIER SI MODE ONBOARDING_CHAT
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        try:
            session_key = f"{user_id}:{collection_name}"
            with self._lock:
                session = self.sessions.get(session_key)
            
            if session and self._is_onboarding_like(session.context.chat_mode):
                # ‚ïê‚ïê‚ïê MODE ONBOARDING : Envoyer √† l'application m√©tier ‚ïê‚ïê‚ïê
                listener_info = session.onboarding_listeners.get(thread_key)
                if not listener_info:
                    logger.warning(
                        f"[CARD_RESPONSE_ONBOARDING] ‚ö†Ô∏è Listener introuvable pour thread={thread_key}"
                    )
                    return {"success": False, "error": "Onboarding listener not found"}
                
                job_id = listener_info.get("job_id")
                if not job_id:
                    logger.warning(
                        f"[CARD_RESPONSE_ONBOARDING] ‚ö†Ô∏è job_id introuvable pour thread={thread_key}"
                    )
                    return {"success": False, "error": "Job ID not found"}
                
                # Construire le payload au format CARD_CLICKED_PINNOKIO
                # ‚≠ê FORMAT EXACT comme Reflex : Structure Google Chat Card compl√®te
                message_id = str(uuid.uuid4())
                timestamp = datetime.now(timezone.utc).isoformat()
                
                # D√©terminer le statut de l'action pour le subtitle
                action_status = "APPROUV√â" if "approve" in action else "REFUS√â"
                
                card_response_data = {
                    "type": "CARD_CLICKED",
                    "threadKey": thread_key,
                    "message": {
                        "cardsV2": [{
                            "cardId": card_name,  # 'approval_card' ou 'four_eyes_approval_card'
                            "card": {
                                "header": {
                                    "title": "R√©ponse de validation",
                                    "subtitle": f"Action: {action_status}"
                                },
                                "sections": [{
                                    "widgets": [{
                                        "textParagraph": {
                                            "text": user_message or ""
                                        }
                                    }]
                                }]
                            }
                        }]
                    },
                    "common": {
                        "formInputs": {
                            "user_message": {
                                "stringInputs": {
                                    "value": [user_message or ""]
                                }
                            },
                            "action": {
                                "stringInputs": {
                                    "value": [action]
                                }
                            }
                        },
                        "invokedFunction": action
                    },
                    "message_type": "CARD_CLICKED_PINNOKIO",
                    "timestamp": timestamp,
                    "sender_id": user_id,
                    "read": False
                }
                
                # Envoyer dans job_chats/{job_id}/messages
                rtdb_path = f"{collection_name}/job_chats/{job_id}/messages/{message_id}"
                self._get_rtdb_ref(rtdb_path).set(card_response_data)
                
                logger.info(
                    f"[CARD_RESPONSE_ONBOARDING] ‚úÖ R√©ponse carte envoy√©e √† application m√©tier - "
                    f"job_id={job_id} message_id={message_id} action={action}"
                )
                
                return {"success": True, "message_id": message_id, "mode": "onboarding"}
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # √âTAPE 2 : MODE GENERAL_CHAT (logique Future existante)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if not hasattr(self, 'pending_approvals'):
                logger.warning(f"[CARD_RESPONSE] ‚ö†Ô∏è Syst√®me approvals non initialis√©")
                return {"success": False, "error": "No approval system initialized"}
            
            future = self.pending_approvals.get(approval_key)
            
            if future and not future.done():
                # R√©soudre Future
                approved = action.startswith("approve")  # approve_four_eyes ‚Üí True
                
                future.set_result({
                    "approved": approved,
                    "action": action,
                    "user_message": user_message,
                    "card_name": card_name,
                    "card_message_id": card_message_id,
                    "collection_name": collection_name,
                    "responded_at": datetime.now(timezone.utc).isoformat()
                })
                
                logger.info(
                    f"[CARD_RESPONSE] ‚úÖ Future r√©solu - approved={approved}, "
                    f"comment={'Yes' if user_message else 'No'}"
                )
                return {"success": True}
            else:
                logger.warning(
                    f"[CARD_RESPONSE] ‚ö†Ô∏è Future non trouv√© ou d√©j√† r√©solu: {approval_key}"
                )
                return {
                    "success": False,
                    "error": "No pending approval found or already processed"
                }
                
        except Exception as e:
            logger.error(
                f"[CARD_RESPONSE] ‚ùå Erreur traitement r√©ponse carte: {e}",
                exc_info=True
            )
            return {
                "success": False,
                "error": str(e)
            }


# Singleton pour le gestionnaire LLM
_llm_manager: Optional[LLMManager] = None

def get_llm_manager() -> LLMManager:
    """R√©cup√®re l'instance singleton du LLM Manager."""
    global _llm_manager
    if _llm_manager is None:
        _llm_manager = LLMManager()
    return _llm_manager


