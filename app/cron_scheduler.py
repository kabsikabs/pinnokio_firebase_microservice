"""
CRON Scheduler pour l'exÃ©cution automatique des tÃ¢ches planifiÃ©es.

Fonctionnement:
    1. Boucle toutes les N secondes (dÃ©faut: 60s)
    2. Appelle firebase.get_tasks_ready_for_execution_utc(now_utc)
    3. Pour chaque tÃ¢che due:
       a. CrÃ©er execution_id
       b. CrÃ©er thread_key
       c. Lancer _execute_scheduled_task()
       d. Mettre Ã  jour next_execution (si SCHEDULED)
       e. DÃ©sactiver tÃ¢che (si ONE_TIME)

â­ Architecture Multi-Instance:
    - Lock Redis distribuÃ© pour Ã©viter les exÃ©cutions en double
    - Seule une instance peut exÃ©cuter une tÃ¢che Ã  la fois
"""

import asyncio
import logging
import uuid
from datetime import datetime, timezone
from typing import Optional
from google.cloud import firestore

logger = logging.getLogger("cron_scheduler")


class DistributedLock:
    """
    Lock distribuÃ© utilisant Redis pour coordonner les instances.
    
    Utilise SET NX EX (atomic) pour garantir l'exclusivitÃ©.
    """
    
    # PrÃ©fixe pour les clÃ©s de lock
    KEY_PREFIX = "lock:cron"
    
    # TTL par dÃ©faut: 5 minutes (pour Ã©viter les locks orphelins)
    DEFAULT_TTL = 300
    
    def __init__(self, redis_client=None):
        self._redis = redis_client
    
    @property
    def redis(self):
        """Lazy loading du client Redis."""
        if self._redis is None:
            from .redis_client import get_redis
            self._redis = get_redis()
        return self._redis
    
    def acquire(self, task_id: str, instance_id: str, ttl: int = None) -> bool:
        """
        Tente d'acquÃ©rir un lock sur une tÃ¢che.
        
        Args:
            task_id: ID de la tÃ¢che Ã  verrouiller
            instance_id: ID unique de cette instance
            ttl: TTL du lock en secondes (dÃ©faut: 5 min)
            
        Returns:
            True si lock acquis, False si dÃ©jÃ  verrouillÃ©
        """
        try:
            key = f"{self.KEY_PREFIX}:{task_id}"
            ttl_seconds = ttl or self.DEFAULT_TTL
            
            # SET NX EX = atomic "set if not exists" avec TTL
            result = self.redis.set(key, instance_id, nx=True, ex=ttl_seconds)
            
            if result:
                logger.debug(f"[LOCK] âœ… Lock acquis: {task_id} (instance={instance_id})")
                return True
            else:
                # Lock dÃ©jÃ  pris, voir par qui
                current_holder = self.redis.get(key)
                if isinstance(current_holder, bytes):
                    current_holder = current_holder.decode('utf-8')
                logger.debug(f"[LOCK] âŒ Lock occupÃ©: {task_id} (holder={current_holder})")
                return False
                
        except Exception as e:
            logger.error(f"[LOCK] Erreur acquire: {e}")
            return False
    
    def release(self, task_id: str, instance_id: str) -> bool:
        """
        LibÃ¨re un lock (seulement si cette instance le dÃ©tient).
        
        Args:
            task_id: ID de la tÃ¢che
            instance_id: ID de cette instance
            
        Returns:
            True si lock libÃ©rÃ©, False sinon
        """
        try:
            key = f"{self.KEY_PREFIX}:{task_id}"
            
            # VÃ©rifier que c'est bien nous qui dÃ©tenons le lock
            current_holder = self.redis.get(key)
            if isinstance(current_holder, bytes):
                current_holder = current_holder.decode('utf-8')
            
            if current_holder == instance_id:
                self.redis.delete(key)
                logger.debug(f"[LOCK] ðŸ”“ Lock libÃ©rÃ©: {task_id}")
                return True
            else:
                logger.warning(f"[LOCK] Tentative de libÃ©rer un lock non dÃ©tenu: {task_id}")
                return False
                
        except Exception as e:
            logger.error(f"[LOCK] Erreur release: {e}")
            return False
    
    def extend(self, task_id: str, instance_id: str, ttl: int = None) -> bool:
        """
        Prolonge le TTL d'un lock (seulement si cette instance le dÃ©tient).
        
        Args:
            task_id: ID de la tÃ¢che
            instance_id: ID de cette instance
            ttl: Nouveau TTL en secondes
            
        Returns:
            True si TTL prolongÃ©, False sinon
        """
        try:
            key = f"{self.KEY_PREFIX}:{task_id}"
            ttl_seconds = ttl or self.DEFAULT_TTL
            
            # VÃ©rifier que c'est bien nous
            current_holder = self.redis.get(key)
            if isinstance(current_holder, bytes):
                current_holder = current_holder.decode('utf-8')
            
            if current_holder == instance_id:
                self.redis.expire(key, ttl_seconds)
                logger.debug(f"[LOCK] â° TTL prolongÃ©: {task_id} ({ttl_seconds}s)")
                return True
            else:
                return False
                
        except Exception as e:
            logger.error(f"[LOCK] Erreur extend: {e}")
            return False
    
    def is_locked(self, task_id: str) -> bool:
        """VÃ©rifie si une tÃ¢che est verrouillÃ©e."""
        key = f"{self.KEY_PREFIX}:{task_id}"
        return bool(self.redis.exists(key))


class CronScheduler:
    """
    Scheduler CRON pour l'exÃ©cution automatique des tÃ¢ches.
    
    â­ Multi-Instance: Utilise un lock Redis distribuÃ© pour Ã©viter
    que plusieurs instances exÃ©cutent la mÃªme tÃ¢che.
    """

    def __init__(self, check_interval: int = 60):
        """
        Initialise le scheduler.

        Args:
            check_interval: Intervalle en secondes entre chaque vÃ©rification (dÃ©faut: 60)
        """
        self.check_interval = check_interval
        self.running = False
        self._task: Optional[asyncio.Task] = None
        
        # â­ Multi-Instance: Lock distribuÃ© + ID unique par instance
        self._lock = DistributedLock()
        self._instance_id = f"cron_{uuid.uuid4().hex[:8]}"

        logger.info(f"[CRON] Scheduler initialisÃ© (intervalle: {check_interval}s, instance={self._instance_id})")

    async def start(self):
        """DÃ©marre le scheduler."""
        if self.running:
            logger.warning("[CRON] Scheduler dÃ©jÃ  en cours d'exÃ©cution")
            return

        self.running = True
        self._task = asyncio.create_task(self._run_loop())
        logger.info("[CRON] Scheduler dÃ©marrÃ©")

    async def stop(self):
        """ArrÃªte le scheduler."""
        if not self.running:
            logger.warning("[CRON] Scheduler dÃ©jÃ  arrÃªtÃ©")
            return

        self.running = False

        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass

        logger.info("[CRON] Scheduler arrÃªtÃ©")

    async def _run_loop(self):
        """Boucle principale du scheduler."""
        logger.info("[CRON] Boucle principale dÃ©marrÃ©e")

        while self.running:
            try:
                await self._check_and_execute_tasks()
            except Exception as e:
                logger.error(f"[CRON] Erreur dans la boucle: {e}", exc_info=True)

            # Attendre avant la prochaine itÃ©ration
            await asyncio.sleep(self.check_interval)

    async def _check_and_execute_tasks(self):
        """
        VÃ©rifie et exÃ©cute les tÃ¢ches dues.

        Steps:
            1. Obtenir now_utc
            2. Appeler firebase.get_tasks_ready_for_execution_utc(now_utc)
            3. Pour chaque tÃ¢che:
               await self._execute_task(task_data, now_utc)
        """
        try:
            from .firebase_providers import get_firebase_management
            fbm = get_firebase_management()

            # 1. Timestamp UTC actuel
            now_utc = datetime.now(timezone.utc)

            logger.debug(f"[CRON] VÃ©rification des tÃ¢ches Ã  {now_utc.isoformat()}")

            # 2. RÃ©cupÃ©rer les tÃ¢ches prÃªtes
            tasks_ready = fbm.get_tasks_ready_for_execution_utc(now_utc)

            if not tasks_ready:
                logger.debug("[CRON] Aucune tÃ¢che prÃªte pour exÃ©cution")
                return

            logger.info(f"[CRON] {len(tasks_ready)} tÃ¢che(s) prÃªte(s) pour exÃ©cution")

            # 3. ExÃ©cuter chaque tÃ¢che
            for task_data in tasks_ready:
                try:
                    await self._execute_task(task_data, now_utc)
                except Exception as e:
                    task_id = task_data.get("task_id", "unknown")
                    logger.error(f"[CRON] Erreur exÃ©cution tÃ¢che {task_id}: {e}", exc_info=True)

        except Exception as e:
            logger.error(f"[CRON] Erreur _check_and_execute_tasks: {e}", exc_info=True)

    async def _execute_task(self, task_data: dict, triggered_at: datetime):
        """
        ExÃ©cute une tÃ¢che.

        â­ Multi-Instance: Utilise un lock Redis pour Ã©viter les exÃ©cutions en double.

        Steps:
            0. AcquÃ©rir lock distribuÃ© (skip si dÃ©jÃ  pris)
            1. GÃ©nÃ©rer execution_id et thread_key
            2. CrÃ©er document d'exÃ©cution (firebase.create_task_execution)
            3. CrÃ©er chat RTDB (firebase_realtime.create_chat)
            4. Lancer execution via LLM Manager (asyncio.create_task)
            5. Mettre Ã  jour next_execution:
               - SCHEDULED: Calculer prochaine occurrence
               - ONE_TIME: DÃ©sactiver la tÃ¢che
            6. LibÃ©rer le lock
        """
        try:
            task_id = task_data["task_id"]
            user_id = task_data["user_id"]
            company_id = task_data["company_id"]
            mandate_path = task_data["mandate_path"]
            execution_plan = task_data["execution_plan"]
            
            # â­ STEP 0: AcquÃ©rir le lock distribuÃ©
            if not self._lock.acquire(task_id, self._instance_id):
                logger.info(f"[CRON] â­ï¸ TÃ¢che ignorÃ©e (dÃ©jÃ  en cours sur autre instance): {task_id}")
                return

            logger.info(f"[CRON] ðŸš€ ExÃ©cution tÃ¢che: {task_id} (user={user_id}, company={company_id}, instance={self._instance_id})")

            # 1. GÃ©nÃ©rer IDs
            execution_id = f"exec_{uuid.uuid4().hex[:12]}"
            
            # â­ UTILISER task_id DIRECTEMENT comme thread_key (chat persistant)
            thread_key = task_id
            logger.info(f"[CRON] ðŸ“ Utilisation du thread_key persistant: {thread_key}")

            # 2. CrÃ©er document d'exÃ©cution
            from .firebase_providers import get_firebase_management
            fbm = get_firebase_management()

            execution_data = {
                "execution_id": execution_id,
                "task_id": task_id,
                "thread_key": thread_key,
                "status": "running",
                "started_at": triggered_at.isoformat(),
                "workflow_checklist": None,  # Sera crÃ©Ã©e par l'agent
                "lpt_tasks": {}
            }

            fbm.create_task_execution(mandate_path, task_id, execution_data)

            # 3. VÃ©rifier et crÃ©er chat RTDB SEULEMENT s'il n'existe pas
            from .firebase_providers import get_firebase_realtime
            rtdb = get_firebase_realtime()

            # VÃ©rifier si le chat existe dÃ©jÃ 
            chat_path = f"{company_id}/chats/{thread_key}"
            existing_chat = rtdb.db.child(chat_path).get()
            
            if existing_chat:
                logger.info(f"[CRON] âœ… Chat existant trouvÃ©: {thread_key} - RÃ©utilisation avec historique")
                # Chat existe dÃ©jÃ , pas besoin de le crÃ©er
                chat_result = {
                    "success": True,
                    "thread_key": thread_key,
                    "mode": "chats",
                    "chat_mode": "task_execution",
                    "existing": True
                }
            else:
                # CrÃ©er un nouveau chat
                logger.info(f"[CRON] ðŸ†• CrÃ©ation nouveau chat: {thread_key}")
                mission_title = task_data.get("mission", {}).get("title", "TÃ¢che planifiÃ©e")
                
                chat_result = rtdb.create_chat(
                    user_id=user_id,
                    space_code=company_id,
                    thread_name=mission_title,
                    mode="chats",
                    chat_mode="task_execution",
                    thread_key=thread_key
                )

                if not chat_result.get("success"):
                    raise ValueError(f"Ã‰chec crÃ©ation chat: {chat_result}")

            # 4. Lancer l'exÃ©cution (async task)
            from .llm_service.llm_manager import get_llm_manager
            llm_manager = get_llm_manager()

            asyncio.create_task(
                llm_manager._execute_scheduled_task(
                    user_id=user_id,
                    company_id=company_id,
                    task_data=task_data,
                    thread_key=thread_key,
                    execution_id=execution_id
                )
            )

            logger.info(f"[CRON] âœ… TÃ¢che lancÃ©e: {task_id} | Thread: {thread_key}")

            # 5. Mettre Ã  jour next_execution
            if execution_plan == "SCHEDULED":
                await self._update_scheduled_task(fbm, task_data, triggered_at)

            elif execution_plan == "ONE_TIME":
                await self._disable_one_time_task(fbm, task_data, triggered_at)

        except Exception as e:
            logger.error(f"[CRON] Erreur _execute_task: {e}", exc_info=True)
        
        finally:
            # â­ STEP 6: LibÃ©rer le lock (toujours, mÃªme en cas d'erreur)
            task_id = task_data.get("task_id", "unknown")
            self._lock.release(task_id, self._instance_id)

    async def _update_scheduled_task(self, fbm, task_data: dict, triggered_at: datetime):
        """
        Met Ã  jour une tÃ¢che SCHEDULED aprÃ¨s dÃ©clenchement.

        Actions:
            - Calculer next_execution (local_time et UTC)
            - Mettre Ã  jour task document
            - Mettre Ã  jour /scheduled_tasks
        """
        try:
            task_id = task_data["task_id"]
            mandate_path = task_data["mandate_path"]
            schedule = task_data.get("schedule", {})

            cron_expr = schedule.get("cron_expression")
            timezone_str = schedule.get("timezone")

            if not cron_expr or not timezone_str:
                logger.error(f"[CRON] DonnÃ©es schedule manquantes pour {task_id}")
                return

            # Calculer prochaine occurrence
            next_local, next_utc = fbm.calculate_task_next_execution(
                cron_expr, timezone_str, from_time=triggered_at
            )

            if not next_local or not next_utc:
                logger.error(f"[CRON] Erreur calcul next_execution pour {task_id}")
                return

            # Mettre Ã  jour task document
            fbm.update_task(
                mandate_path, task_id,
                {
                    "schedule.next_execution_local_time": next_local,
                    "schedule.next_execution_utc": next_utc,
                    "execution_count": task_data.get("execution_count", 0) + 1
                }
            )

            # Mettre Ã  jour aussi dans /scheduled_tasks
            job_id = f"{mandate_path.replace('/', '_')}_{task_id}"
            scheduler_ref = fbm.db.collection("scheduled_tasks").document(job_id)

            scheduler_ref.update({
                "next_execution_local_time": next_local,
                "next_execution_utc": next_utc,
                "updated_at": firestore.SERVER_TIMESTAMP
            })

            logger.info(f"[CRON] Prochaine exÃ©cution: {next_local} (local) | {next_utc} (UTC)")

        except Exception as e:
            logger.error(f"[CRON] Erreur _update_scheduled_task: {e}", exc_info=True)

    async def _disable_one_time_task(self, fbm, task_data: dict, triggered_at: datetime):
        """
        DÃ©sactive une tÃ¢che ONE_TIME aprÃ¨s exÃ©cution.

        Actions:
            - Marquer enabled=False et status=completed
            - Supprimer de /scheduled_tasks
        """
        try:
            task_id = task_data["task_id"]
            mandate_path = task_data["mandate_path"]

            # DÃ©sactiver la tÃ¢che
            fbm.update_task(
                mandate_path, task_id,
                {
                    "enabled": False,
                    "status": "completed",
                    "completed_at": triggered_at.isoformat()
                }
            )

            # Supprimer de /scheduled_tasks
            job_id = f"{mandate_path.replace('/', '_')}_{task_id}"
            fbm.delete_scheduler_job_completely(job_id)

            logger.info(f"[CRON] TÃ¢che ONE_TIME dÃ©sactivÃ©e: {task_id}")

        except Exception as e:
            logger.error(f"[CRON] Erreur _disable_one_time_task: {e}", exc_info=True)


# Singleton global
_CRON_SCHEDULER_SINGLETON: Optional[CronScheduler] = None


def get_cron_scheduler() -> CronScheduler:
    """Retourne l'instance singleton du scheduler CRON."""
    global _CRON_SCHEDULER_SINGLETON

    if _CRON_SCHEDULER_SINGLETON is None:
        _CRON_SCHEDULER_SINGLETON = CronScheduler(check_interval=60)

    return _CRON_SCHEDULER_SINGLETON
