"""
JobTools - Outils de recherche et filtrage des jobs par d√©partement
3 outils distincts : APBookkeeper, Router, Bank + Context Tools
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone
import pandas as pd

logger = logging.getLogger("pinnokio.job_tools")


class APBookkeeperJobTools:
    """
    Outil GET_APBOOKEEPER_JOBS pour rechercher les factures fournisseur.
    
    Output enrichi avec drive_file_id pour permettre √† l'agent de voir les documents.
    
    ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
    """
    
    def __init__(self, jobs_data: Dict, user_id: str = None, company_id: str = None, user_context: Dict = None, mode: str = "UI"):
        self.ap_data = jobs_data.get("APBOOKEEPER", {})  # Donn√©es initiales (fallback)
        self.user_id = user_id
        self.company_id = company_id
        self.user_context = user_context or {}
        self.mode = mode
        logger.info(f"[APBOOKEEPER_TOOLS] Initialis√© avec {len(self.ap_data.get('to_do', []))} factures to_do (mode={mode})")
    
    def get_tool_definition(self) -> Dict:
        """D√©finition COURTE de l'outil GET_APBOOKEEPER_JOBS (pour l'API)."""
        return {
            "name": "GET_APBOOKEEPER_JOBS",
            "description": "üìã Recherche les factures fournisseur par statut/nom. Retourne job_id, drive_file_id, file_name, status. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "enum": ["to_do", "in_process", "pending", "processed", "all"],
                        "description": "Filtrer par statut (d√©faut: to_do)"
                    },
                    "file_name_contains": {
                        "type": "string",
                        "description": "Rechercher dans le nom du fichier (case insensitive)"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Nombre max de r√©sultats (d√©faut: 50, max: 200)",
                        "default": 50
                    }
                },
                "required": []
            }
        }
    
    async def search(
        self,
        status: str = "to_do",
        file_name_contains: str = None,
        limit: int = 50
    ) -> Dict:
        """
        Recherche les factures APBookkeeper.
        
        ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
        """
        try:
            logger.info(f"[GET_APBOOKEEPER_JOBS] Recherche - status={status}, file_name={file_name_contains}, limit={limit}")
            
            # ‚≠ê Recharger depuis Redis si mode UI (donn√©es √† jour)
            ap_data = self.ap_data  # Fallback vers donn√©es initiales
            if self.mode == "UI" and self.user_id and self.company_id:
                try:
                    from ..tools.job_loader import JobLoader
                    loader = JobLoader(
                        user_id=self.user_id,
                        company_id=self.company_id,
                        client_uuid=self.user_context.get("client_uuid")
                    )
                    # Recharger uniquement APBookkeeper depuis Redis
                    fresh_ap_data = await loader.load_apbookeeper_jobs(mode="UI")
                    if fresh_ap_data:
                        ap_data = fresh_ap_data
                        logger.info(f"[GET_APBOOKEEPER_JOBS] ‚úÖ Donn√©es recharg√©es depuis Redis - {len(ap_data.get('to_do', []))} factures to_do")
                except Exception as e:
                    logger.warning(f"[GET_APBOOKEEPER_JOBS] ‚ö†Ô∏è Erreur rechargement Redis: {e} - Utilisation donn√©es initiales")
            
            limit = min(limit, 200)
            
            # R√©cup√©rer les jobs selon le statut
            if status == "all":
                all_jobs = []
                all_jobs.extend(ap_data.get("to_do", []))  # ‚úÖ Utiliser donn√©es recharg√©es
                all_jobs.extend(ap_data.get("in_process", []))
                all_jobs.extend(ap_data.get("pending", []))
                all_jobs.extend(ap_data.get("processed", []))
            else:
                status_key = "processed" if status == "completed" else status
                all_jobs = ap_data.get(status_key, [])
            
            # Filtrer par nom de fichier
            filtered_jobs = all_jobs
            if file_name_contains:
                filtered_jobs = [
                    job for job in filtered_jobs
                    if file_name_contains.lower() in job.get("file_name", "").lower()
                ]
            
            # Limiter les r√©sultats
            filtered_jobs = filtered_jobs[:limit]
            
            # Output enrichi avec drive_file_id pour visualisation
            results = []
            for job in filtered_jobs:
                results.append({
                    "job_id": job.get("job_id"),
                    "drive_file_id": job.get("drive_file_id"),  # üîç Pour voir le document
                    "uri_drive_link": job.get("uri_drive_link"),  # Lien direct
                    "file_name": job.get("file_name"),
                    "status": job.get("status"),
                    "timestamp": job.get("timestamp"),
                    "source": job.get("source", ""),
                    "client": job.get("client", "")
                })
            
            return {
                "success": True,
                "department": "APBOOKEEPER",
                "filters_applied": {
                    "status": status,
                    "file_name_contains": file_name_contains
                },
                "total_found": len(results),
                "results": results,
                "summary": f"üìã {len(results)} facture(s) fournisseur (statut: {status})"
            }
        
        except Exception as e:
            logger.error(f"[GET_APBOOKEEPER_JOBS] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "results": []
            }


class RouterJobTools:
    """
    Outil GET_ROUTER_JOBS pour rechercher les documents √† router.
    
    Output enrichi avec drive_file_id et router_drive_view_link pour visualisation.
    
    ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
    """
    
    def __init__(self, jobs_data: Dict, user_id: str = None, company_id: str = None, user_context: Dict = None, mode: str = "UI"):
        self.router_data = jobs_data.get("ROUTER", {})  # Donn√©es initiales (fallback)
        self.user_id = user_id
        self.company_id = company_id
        self.user_context = user_context or {}
        self.mode = mode
        logger.info(f"[ROUTER_TOOLS] Initialis√© avec {len(self.router_data.get('to_process', []))} documents to_process (mode={mode})")
    
    def get_tool_definition(self) -> Dict:
        """D√©finition COURTE de l'outil GET_ROUTER_JOBS (pour l'API)."""
        return {
            "name": "GET_ROUTER_JOBS",
            "description": "üóÇÔ∏è Recherche les documents √† router par statut/nom. Retourne drive_file_id, file_name, status. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "enum": ["to_process", "in_process", "all"],
                        "description": "Filtrer par statut (d√©faut: to_process)"
                    },
                    "file_name_contains": {
                        "type": "string",
                        "description": "Rechercher dans le nom du fichier (case insensitive)"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Nombre max de r√©sultats (d√©faut: 50, max: 200)",
                        "default": 50
                    }
                },
                "required": []
            }
        }
    
    async def search(
        self,
        status: str = "to_process",
        file_name_contains: str = None,
        limit: int = 50
    ) -> Dict:
        """
        Recherche les documents Router.
        
        ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
        """
        try:
            logger.info(f"[GET_ROUTER_JOBS] Recherche - status={status}, file_name={file_name_contains}, limit={limit}")
            
            # ‚≠ê Recharger depuis Redis si mode UI (donn√©es √† jour)
            router_data = self.router_data  # Fallback vers donn√©es initiales
            if self.mode == "UI" and self.user_id and self.company_id:
                try:
                    from ..tools.job_loader import JobLoader
                    loader = JobLoader(
                        user_id=self.user_id,
                        company_id=self.company_id,
                        client_uuid=self.user_context.get("client_uuid")
                    )
                    # Recharger uniquement Router depuis Redis
                    fresh_router_data = await loader.load_router_jobs(mode="UI", user_context=self.user_context)
                    if fresh_router_data:
                        router_data = fresh_router_data
                        logger.info(f"[GET_ROUTER_JOBS] ‚úÖ Donn√©es recharg√©es depuis Redis - {len(router_data.get('to_process', []))} documents to_process")
                except Exception as e:
                    logger.warning(f"[GET_ROUTER_JOBS] ‚ö†Ô∏è Erreur rechargement Redis: {e} - Utilisation donn√©es initiales")
            
            limit = min(limit, 200)
            
            # Mapping statut pour format Reflex
            status_mapping = {
                "to_process": "to_process",  # ‚úÖ Corrig√© : doit correspondre √† job_loader
                "in_process": "in_process",
                "processed": "processed"
            }
            
            # R√©cup√©rer les jobs selon le statut (format Reflex)
            if status == "all":
                all_jobs = []
                all_jobs.extend(router_data.get("to_process", []))  # ‚úÖ Utiliser donn√©es recharg√©es
                all_jobs.extend(router_data.get("in_process", []))
                all_jobs.extend(router_data.get("processed", []))
            else:
                reflex_status = status_mapping.get(status, status)
                all_jobs = router_data.get(reflex_status, [])
            
            # Filtrer par nom de fichier (format Reflex utilise "name")
            filtered_jobs = all_jobs
            if file_name_contains:
                filtered_jobs = [
                    job for job in filtered_jobs
                    if file_name_contains.lower() in job.get("name", "").lower()
                ]
            
            # Limiter les r√©sultats
            filtered_jobs = filtered_jobs[:limit]
            
            # Output enrichi avec drive_file_id pour visualisation
            results = []
            for job in filtered_jobs:
                results.append({
                    "drive_file_id": job.get("id"),  # üîç Pour voir le document (format Reflex)
                    "router_drive_view_link": job.get("router_drive_view_link"),  # Lien direct
                    "file_name": job.get("name"),  # Format Reflex utilise "name"
                    "status": job.get("status"),
                    "created_time": job.get("created_time")
                })
            
            return {
                "success": True,
                "department": "ROUTER",
                "filters_applied": {
                    "status": status,
                    "file_name_contains": file_name_contains
                },
                "total_found": len(results),
                "results": results,
                "summary": f"üóÇÔ∏è {len(results)} document(s) √† router (statut: {status})"
            }
        
        except Exception as e:
            logger.error(f"[GET_ROUTER_JOBS] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "results": []
            }


class BankJobTools:
    """
    Outil GET_BANK_TRANSACTIONS pour rechercher les transactions bancaires.
    
    Output complet avec tous les d√©tails des transactions pour analyse approfondie.
    
    ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
    """
    
    def __init__(self, jobs_data: Dict, user_id: str = None, company_id: str = None, user_context: Dict = None, mode: str = "UI"):
        self.bank_data = jobs_data.get("BANK", {})  # Donn√©es initiales (fallback)
        self.user_id = user_id
        self.company_id = company_id
        self.user_context = user_context or {}
        self.mode = mode
        logger.info(f"[BANK_TOOLS] Initialis√© avec {len(self.bank_data.get('to_reconcile', []))} transactions to_reconcile (mode={mode})")
    
    def get_tool_definition(self) -> Dict:
        """D√©finition COURTE de l'outil GET_BANK_TRANSACTIONS (pour l'API)."""
        return {
            "name": "GET_BANK_TRANSACTIONS",
            "description": "üè¶ Recherche les transactions bancaires par statut/compte/montant/date. Retourne transaction_id, journal_id, amount, date, partner. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "enum": ["to_reconcile", "in_process", "pending", "all"],
                        "description": "Filtrer par statut (d√©faut: to_reconcile)"
                    },
                    "journal_id": {
                        "type": "string",
                        "description": "Filtrer par compte bancaire (journal_id)"
                    },
                    "date_from": {
                        "type": "string",
                        "description": "Date de d√©but (YYYY-MM-DD)"
                    },
                    "date_to": {
                        "type": "string",
                        "description": "Date de fin (YYYY-MM-DD)"
                    },
                    "amount_min": {
                        "type": "number",
                        "description": "Montant minimum (‚Ç¨)"
                    },
                    "amount_max": {
                        "type": "number",
                        "description": "Montant maximum (‚Ç¨)"
                    },
                    "partner_name_contains": {
                        "type": "string",
                        "description": "Rechercher dans le nom du partenaire (case insensitive)"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Nombre max de r√©sultats (d√©faut: 50, max: 200)",
                        "default": 50
                    }
                },
                "required": []
            }
        }
    
    async def search(
        self,
        status: str = "to_reconcile",
        journal_id: str = None,
        date_from: str = None,
        date_to: str = None,
        amount_min: float = None,
        amount_max: float = None,
        partner_name_contains: str = None,
        limit: int = 50
    ) -> Dict:
        """
        Recherche les transactions bancaires.
        
        ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
        """
        try:
            logger.info(f"[GET_BANK_TRANSACTIONS] Recherche - status={status}, journal={journal_id}, limit={limit}")
            
            # ‚≠ê Recharger depuis Redis si mode UI (donn√©es √† jour)
            bank_data = self.bank_data  # Fallback vers donn√©es initiales
            if self.mode == "UI" and self.user_id and self.company_id:
                try:
                    from ..tools.job_loader import JobLoader
                    loader = JobLoader(
                        user_id=self.user_id,
                        company_id=self.company_id,
                        client_uuid=self.user_context.get("client_uuid")
                    )
                    # Recharger uniquement Bank depuis Redis
                    fresh_bank_data = await loader.load_bank_transactions(mode="UI", user_context=self.user_context)
                    if fresh_bank_data:
                        bank_data = fresh_bank_data
                        logger.info(f"[GET_BANK_TRANSACTIONS] ‚úÖ Donn√©es recharg√©es depuis Redis - {len(bank_data.get('to_reconcile', []))} transactions to_reconcile")
                except Exception as e:
                    logger.warning(f"[GET_BANK_TRANSACTIONS] ‚ö†Ô∏è Erreur rechargement Redis: {e} - Utilisation donn√©es initiales")
            
            limit = min(limit, 200)
            
            # R√©cup√©rer les transactions selon le statut
            if status == "all":
                all_txs = []
                all_txs.extend(bank_data.get("to_reconcile", []))  # ‚úÖ Utiliser donn√©es recharg√©es
                all_txs.extend(bank_data.get("pending", []))
                all_txs.extend(bank_data.get("in_process", []))
            else:
                all_txs = bank_data.get(status, [])
            
            if not all_txs:
                return {
                    "success": True,
                    "department": "BANK",
                    "filters_applied": {},
                    "total_found": 0,
                    "total_amount": 0,
                    "results": [],
                    "summary": "üè¶ Aucune transaction bancaire trouv√©e"
                }
            
            # Convertir en DataFrame pour filtrage avanc√©
            df = pd.DataFrame(all_txs)
            
            # Appliquer les filtres
            if journal_id:
                df = df[df['journal_id'].astype(str).str.contains(journal_id, case=False, na=False)]
            
            if date_from:
                df = df[df['date'] >= date_from]
            
            if date_to:
                df = df[df['date'] <= date_to]
            
            if amount_min is not None:
                df = df[df['amount'] >= amount_min]
            
            if amount_max is not None:
                df = df[df['amount'] <= amount_max]
            
            if partner_name_contains:
                df = df[df['partner_name'].astype(str).str.contains(partner_name_contains, case=False, na=False)]
            
            # Limiter les r√©sultats
            df = df.head(limit)
            
            # Output complet avec tous les d√©tails
            results = []
            for _, row in df.iterrows():
                results.append({
                    "transaction_id": row.get("transaction_id"),  # ID pour payload LPT
                    "journal_id": row.get("journal_id"),  # Compte bancaire
                    "date": str(row.get("date", "")),
                    "amount": float(row.get("amount", 0)),
                    "partner_name": str(row.get("partner_name", "")),
                    "partner_id": row.get("partner_id"),
                    "payment_ref": str(row.get("payment_ref", "")),
                    "ref": str(row.get("ref", "")),
                    "transaction_type": str(row.get("transaction_type", "")),
                    "currency_id": str(row.get("currency_id", "")),
                    "amount_residual": float(row.get("amount_residual", 0)),
                    "is_reconciled": bool(row.get("is_reconciled", False)),
                    "display_name": str(row.get("display_name", "")),
                    "state": str(row.get("state", "")),
                    "status": str(row.get("status", "to_reconcile"))
                })
            
            # Calculer le total
            total_amount = sum(r["amount"] for r in results)
            
            # R√©sum√©
            journal_info = f" sur {journal_id}" if journal_id else ""
            partner_info = f" pour {partner_name_contains}" if partner_name_contains else ""
            
            return {
                "success": True,
                "department": "BANK",
                "filters_applied": {
                    "status": status,
                    "journal_id": journal_id,
                    "date_from": date_from,
                    "date_to": date_to,
                    "amount_min": amount_min,
                    "amount_max": amount_max,
                    "partner_name_contains": partner_name_contains
                },
                "total_found": len(results),
                "total_amount": round(total_amount, 2),
                "results": results,
                "summary": f"üè¶ {len(results)} transaction(s){journal_info}{partner_info} - Total: {total_amount:.2f}‚Ç¨"
            }
        
        except Exception as e:
            logger.error(f"[GET_BANK_TRANSACTIONS] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "results": []
            }


class ExpenseJobTools:
    """
    Outil GET_EXPENSES_INFO pour rechercher les notes de frais.
    
    Output complet avec tous les d√©tails des expenses pour analyse approfondie.
    Inclut drive_file_id pour visualisation des documents.
    
    ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
    """
    
    def __init__(self, jobs_data: Dict, user_id: str = None, company_id: str = None, user_context: Dict = None, mode: str = "UI"):
        self.expenses_data = jobs_data.get("EXPENSES", {})  # Donn√©es initiales (fallback)
        self.user_id = user_id
        self.company_id = company_id
        self.user_context = user_context or {}
        self.mode = mode
        logger.info(f"[EXPENSES_TOOLS] Initialis√© avec {len(self.expenses_data.get('open', []))} expenses open (mode={mode})")
    
    def get_tool_definition(self) -> Dict:
        """D√©finition COURTE de l'outil GET_EXPENSES_INFO (pour l'API)."""
        return {
            "name": "GET_EXPENSES_INFO",
            "description": "üí∞ Recherche les notes de frais par statut/date/montant/fournisseur. Retourne expense_id, drive_file_id, date, amount, supplier, status. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "enum": ["open", "closed", "all"],
                        "description": "Filtrer par statut (open=non saisies, closed=comptabilis√©es, d√©faut: open)"
                    },
                    "date_from": {
                        "type": "string",
                        "description": "Date de d√©but (YYYY-MM-DD)"
                    },
                    "date_to": {
                        "type": "string",
                        "description": "Date de fin (YYYY-MM-DD)"
                    },
                    "amount_min": {
                        "type": "number",
                        "description": "Montant minimum"
                    },
                    "amount_max": {
                        "type": "number",
                        "description": "Montant maximum"
                    },
                    "supplier_contains": {
                        "type": "string",
                        "description": "Rechercher dans le nom du fournisseur (case insensitive)"
                    },
                    "payment_method": {
                        "type": "string",
                        "description": "Filtrer par m√©thode de paiement"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Nombre max de r√©sultats (d√©faut: 50, max: 200)",
                        "default": 50
                    }
                },
                "required": []
            }
        }
    
    async def search(
        self,
        status: str = "open",
        date_from: str = None,
        date_to: str = None,
        amount_min: float = None,
        amount_max: float = None,
        supplier_contains: str = None,
        payment_method: str = None,
        limit: int = 50
    ) -> Dict:
        """
        Recherche les notes de frais.
        
        ‚≠ê NOUVEAU : Recharge depuis Redis √† chaque appel (mode UI) pour donn√©es √† jour
        """
        try:
            logger.info(f"[GET_EXPENSES_INFO] Recherche - status={status}, limit={limit}")
            
            # ‚≠ê Recharger depuis Redis si mode UI (donn√©es √† jour)
            expenses_data = self.expenses_data  # Fallback vers donn√©es initiales
            if self.mode == "UI" and self.user_id and self.company_id:
                try:
                    from ..tools.job_loader import JobLoader
                    loader = JobLoader(
                        user_id=self.user_id,
                        company_id=self.company_id,
                        client_uuid=self.user_context.get("client_uuid")
                    )
                    # Recharger uniquement Expenses depuis Redis
                    fresh_expenses_data = await loader.load_expenses(mode="UI", user_context=self.user_context)
                    if fresh_expenses_data:
                        expenses_data = fresh_expenses_data
                        logger.info(f"[GET_EXPENSES_INFO] ‚úÖ Donn√©es recharg√©es depuis Redis - {len(expenses_data.get('open', []))} open, {len(expenses_data.get('closed', []))} closed")
                except Exception as e:
                    logger.warning(f"[GET_EXPENSES_INFO] ‚ö†Ô∏è Erreur rechargement Redis: {e} - Utilisation donn√©es initiales")
            
            limit = min(limit, 200)
            
            # R√©cup√©rer les expenses selon le statut
            if status == "all":
                all_expenses = []
                all_expenses.extend(expenses_data.get("open", []))  # ‚úÖ Utiliser donn√©es recharg√©es
                all_expenses.extend(expenses_data.get("closed", []))
            elif status == "closed":
                all_expenses = expenses_data.get("closed", [])
            else:  # "open" par d√©faut
                all_expenses = expenses_data.get("open", [])
            
            if not all_expenses:
                return {
                    "success": True,
                    "department": "EXPENSES",
                    "filters_applied": {},
                    "total_found": 0,
                    "total_amount": 0,
                    "results": [],
                    "summary": "üí∞ Aucune note de frais trouv√©e"
                }
            
            # Convertir en DataFrame pour filtrage avanc√©
            df = pd.DataFrame(all_expenses)
            
            # Appliquer les filtres
            if date_from:
                df = df[df['date'] >= date_from]
            
            if date_to:
                df = df[df['date'] <= date_to]
            
            if amount_min is not None:
                df = df[df['amount'] >= amount_min]
            
            if amount_max is not None:
                df = df[df['amount'] <= amount_max]
            
            if supplier_contains:
                df = df[df['supplier'].astype(str).str.contains(supplier_contains, case=False, na=False)]
            
            if payment_method:
                df = df[df['payment_method'].astype(str).str.contains(payment_method, case=False, na=False)]
            
            # Limiter les r√©sultats
            df = df.head(limit)
            
            # Output complet avec tous les d√©tails
            results = []
            for _, row in df.iterrows():
                results.append({
                    "expense_id": row.get("expense_id"),  # ID pour r√©f√©rence
                    "drive_file_id": row.get("drive_file_id"),  # üîç Pour voir le document
                    "date": str(row.get("date", "")),
                    "amount": float(row.get("amount", 0)),
                    "currency": str(row.get("currency", "CHF")),
                    "supplier": str(row.get("supplier", "")),
                    "status": str(row.get("status", "to_process")),  # "to_process" ou "close"
                    "concern": str(row.get("concern", "")),
                    "payment_method": str(row.get("payment_method", "")),
                    "job_id": row.get("job_id", ""),
                    "file_name": row.get("file_name", "")
                })
            
            # Calculer le total
            total_amount = sum(r["amount"] for r in results)
            
            # R√©sum√©
            status_info = f" ({status})" if status != "all" else ""
            supplier_info = f" pour {supplier_contains}" if supplier_contains else ""
            
            return {
                "success": True,
                "department": "EXPENSES",
                "filters_applied": {
                    "status": status,
                    "date_from": date_from,
                    "date_to": date_to,
                    "amount_min": amount_min,
                    "amount_max": amount_max,
                    "supplier_contains": supplier_contains,
                    "payment_method": payment_method
                },
                "total_found": len(results),
                "total_amount": round(total_amount, 2),
                "results": results,
                "summary": f"üí∞ {len(results)} note(s) de frais{status_info}{supplier_info} - Total: {total_amount:.2f}{results[0]['currency'] if results else 'CHF'}"
            }
        
        except Exception as e:
            logger.error(f"[GET_EXPENSES_INFO] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "results": []
            }


class ContextTools:
    """
    Outils d'acc√®s et de modification des contextes (Router, APBookkeeper, Company).
    
    Ces outils permettent √† l'agent principal d'acc√©der directement aux contextes m√©tier
    sans passer par un SPT agent.
    """
    
    def __init__(self, firebase_management, firebase_user_id: str, collection_name: str, brain=None):
        """
        Args:
            firebase_management: Instance FirebaseManagement pour acc√®s aux donn√©es
            firebase_user_id: ID utilisateur Firebase
            collection_name: Nom de la collection (ex: klk_space_id_8b2dce)
            brain: Instance PinnokioBrain pour acc√®s au user_context
        """
        self.firebase_management = firebase_management
        self.firebase_user_id = firebase_user_id
        self.collection_name = collection_name
        self.brain = brain
        
        # R√©cup√©rer le mandate_path depuis le brain (d√©j√† charg√©)
        if brain:
            user_context = brain.get_user_context()
            self.mandate_path = user_context.get("mandate_path")
        else:
            logger.warning("[CONTEXT_TOOLS] Brain non fourni, mandate_path sera None")
            self.mandate_path = None
        
        if not self.mandate_path:
            logger.warning("[CONTEXT_TOOLS] mandate_path non trouv√© dans user_context")
        
        # Initialiser le TextUpdaterAgent pour UPDATE_CONTEXT
        self.text_updater = None
        
        # Stocker les propositions de mise √† jour (avant publication)
        self.pending_proposal = None
        
        logger.info(f"[CONTEXT_TOOLS] Initialis√© avec mandate_path={self.mandate_path}")
    
    def _init_text_updater(self):
        """Initialise le TextUpdaterAgent (lazy loading)."""
        if self.text_updater is None:
            from .text_updater import TextUpdaterAgent
            self.text_updater = TextUpdaterAgent(
                collection_name=self.collection_name,
                firebase_user_id=self.firebase_user_id
            )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # OUTILS DE LECTURE DES CONTEXTES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def get_router_prompt_definition(self) -> Dict:
        """D√©finition COURTE de l'outil ROUTER_PROMPT (pour l'API)."""
        return {
            "name": "ROUTER_PROMPT",
            "description": "üóÇÔ∏è R√®gles de classification par service (hr, invoices, expenses, banks_cash, taxes, contrats, letters, financial_statement). Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "service": {
                        "type": "string",
                        "description": "Nom du service (ex: hr, banks_cash, taxes, legal, etc.)"
                    }
                },
                "required": ["service"]
            }
        }
    
    async def get_router_prompt(self, service: str) -> Dict:
        """
        R√©cup√®re le prompt de routage pour un service sp√©cifique.
        
        Args:
            service: Nom du service (ex: "hr", "banks_cash", etc.)
        
        Returns:
            Dict avec le prompt de routage
        """
        try:
            logger.info(f"[ROUTER_PROMPT] Recherche pour service={service}")
            
            if not self.mandate_path:
                return {
                    "success": False,
                    "error": "mandate_path non configur√©"
                }
            
            # R√©cup√©rer tous les contextes
            all_contexts = self.firebase_management.get_all_contexts(self.mandate_path)
            
            if not all_contexts or "router" not in all_contexts:
                return {
                    "success": False,
                    "error": "router_context non trouv√© dans Firebase"
                }
            
            router_context = all_contexts["router"]
            router_prompt_data = router_context.get("router_prompt", {})
            
            # Extraire le prompt pour le service demand√©
            service_prompt = router_prompt_data.get(service)
            
            if not service_prompt:
                available_services = list(router_prompt_data.keys())
                return {
                    "success": False,
                    "error": f"Service '{service}' non trouv√©",
                    "available_services": available_services,
                    "hint": f"Services disponibles: {', '.join(available_services)}"
                }
            
            return {
                "success": True,
                "service": service,
                "routing_rules": service_prompt,
                "last_refresh": router_context.get("last_refresh"),
                "summary": f"üìã R√®gles de routage pour le service '{service}' r√©cup√©r√©es avec succ√®s"
            }
        
        except Exception as e:
            logger.error(f"[ROUTER_PROMPT] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_apbookeeper_context_definition(self) -> Dict:
        """D√©finition COURTE de l'outil APBOOKEEPER_CONTEXT (pour l'API)."""
        return {
            "name": "APBOOKEEPER_CONTEXT",
            "description": "üìä Contexte comptable complet : r√®gles comptables, TVA, plan comptable, workflows. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    
    async def get_apbookeeper_context(self) -> Dict:
        """
        R√©cup√®re le contexte comptable complet.
        
        Returns:
            Dict avec le contexte comptable
        """
        try:
            logger.info("[APBOOKEEPER_CONTEXT] R√©cup√©ration du contexte comptable")
            
            if not self.mandate_path:
                return {
                    "success": False,
                    "error": "mandate_path non configur√©"
                }
            
            # R√©cup√©rer tous les contextes
            all_contexts = self.firebase_management.get_all_contexts(self.mandate_path)
            
            if not all_contexts or "accounting" not in all_contexts:
                return {
                    "success": False,
                    "error": "accounting_context non trouv√© dans Firebase"
                }
            
            accounting_context = all_contexts["accounting"]
            
            # Extraire accounting_context_0
            accounting_content = accounting_context.get("accounting_context_0", "")
            
            if not accounting_content:
                return {
                    "success": False,
                    "error": "accounting_context_0 est vide"
                }
            
            return {
                "success": True,
                "accounting_context": accounting_content,
                "last_refresh": accounting_context.get("last_refresh"),
                "content_length": len(str(accounting_content)),
                "summary": f"üìä Contexte comptable r√©cup√©r√© ({len(str(accounting_content))} caract√®res)"
            }
        
        except Exception as e:
            logger.error(f"[APBOOKEEPER_CONTEXT] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }

    def get_bank_context_definition(self) -> Dict:
        """D√©finition COURTE de l'outil BANK_CONTEXT (pour l'API)."""
        return {
            "name": "BANK_CONTEXT",
            "description": "üè¶ Contexte bancaire de l'entreprise (r√®gles & conventions de rapprochement, libell√©s, tol√©rances, comptes, etc.). ‚ö†Ô∏è Ne pas confondre avec ROUTER_PROMPT (r√®gles de routage). Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }

    async def get_bank_context(self) -> Dict:
        """
        R√©cup√®re le contexte bancaire complet.
        
        Source Firebase:
            {mandate_path}/context/bank_context (champ data.bank_context_0)
        """
        try:
            logger.info("[BANK_CONTEXT] R√©cup√©ration du contexte bancaire")
            
            if not self.mandate_path:
                return {
                    "success": False,
                    "error": "mandate_path non configur√©"
                }
            
            all_contexts = self.firebase_management.get_all_contexts(self.mandate_path)
            
            if not all_contexts or "bank" not in all_contexts:
                return {
                    "success": False,
                    "error": "bank_context non trouv√© dans Firebase"
                }
            
            bank_context = all_contexts["bank"]
            bank_content = bank_context.get("bank_context_0", "")
            
            if not bank_content:
                return {
                    "success": False,
                    "error": "bank_context_0 est vide"
                }
            
            return {
                "success": True,
                "bank_context": bank_content,
                "last_refresh": bank_context.get("last_refresh"),
                "content_length": len(str(bank_content)),
                "summary": f"üè¶ Contexte bancaire r√©cup√©r√© ({len(str(bank_content))} caract√®res)"
            }
        
        except Exception as e:
            logger.error(f"[BANK_CONTEXT] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_company_context_definition(self) -> Dict:
        """D√©finition COURTE de l'outil COMPANY_CONTEXT (pour l'API)."""
        return {
            "name": "COMPANY_CONTEXT",
            "description": "üè¢ Profil complet de l'entreprise : informations l√©gales, activit√©, structure. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    
    async def get_company_context(self) -> Dict:
        """
        R√©cup√®re le profil complet de l'entreprise.
        
        Returns:
            Dict avec le profil de l'entreprise
        """
        try:
            logger.info("[COMPANY_CONTEXT] R√©cup√©ration du profil entreprise")
            
            if not self.mandate_path:
                return {
                    "success": False,
                    "error": "mandate_path non configur√©"
                }
            
            # R√©cup√©rer tous les contextes
            all_contexts = self.firebase_management.get_all_contexts(self.mandate_path)
            
            if not all_contexts or "general" not in all_contexts:
                return {
                    "success": False,
                    "error": "general_context non trouv√© dans Firebase"
                }
            
            general_context = all_contexts["general"]
            
            # Extraire context_company_profile_report
            company_profile = general_context.get("context_company_profile_report", "")
            
            if not company_profile:
                return {
                    "success": False,
                    "error": "context_company_profile_report est vide"
                }
            
            return {
                "success": True,
                "company_profile": company_profile,
                "last_refresh": general_context.get("last_refresh"),
                "content_length": len(str(company_profile)),
                "summary": f"üè¢ Profil entreprise r√©cup√©r√© ({len(str(company_profile))} caract√®res)"
            }
        
        except Exception as e:
            logger.error(f"[COMPANY_CONTEXT] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # OUTILS DE MODIFICATION DES CONTEXTES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    async def _save_context_to_firebase(
        self,
        context_type: str,
        service_name: str,
        updated_text: str
        ) -> Dict:
        """
        M√©thode interne pour sauvegarder un contexte dans Firebase.
        Extrait de PUBLISH_CONTEXT pour r√©utilisation dans UPDATE_CONTEXT.
        
        Args:
            context_type: Type de contexte (router/accounting/company)
            service_name: Nom du service (requis pour router)
            updated_text: Texte mis √† jour √† sauvegarder
        
        Returns:
            Dict avec success, context_path, last_refresh
        """
        try:
            if context_type == "router":
                if not service_name:
                    return {"success": False, "error": "service_name requis pour context_type='router'"}
                
                # R√©cup√©rer le router_prompt complet actuel
                all_contexts = self.firebase_management.get_all_contexts(self.mandate_path)
                router_context = all_contexts.get("router", {})
                router_prompt_data = router_context.get("router_prompt", {})
                
                # Mettre √† jour uniquement le service modifi√©
                router_prompt_data[service_name] = updated_text
                
                # Sauvegarder avec update_router_context
                success = self.firebase_management.update_router_context(
                    mandate_path=self.mandate_path,
                    updated_content=router_prompt_data
                )
                
                context_path = f"{self.mandate_path}/context/router_context/router_prompt/{service_name}"
            
            elif context_type == "accounting":
                # update_accounting_context attend le texte directement
                success = self.firebase_management.update_accounting_context(
                    mandate_path=self.mandate_path,
                    updated_content=updated_text
                )
                
                context_path = f"{self.mandate_path}/context/accounting_context/data/accounting_context_0"

            elif context_type == "bank":
                success = self.firebase_management.update_bank_context(
                    mandate_path=self.mandate_path,
                    updated_content=updated_text
                )
                
                context_path = f"{self.mandate_path}/context/bank_context/data/bank_context_0"
            
            elif context_type == "company":
                success = self.firebase_management.update_general_context(
                    mandate_path=self.mandate_path,
                    updated_content=updated_text
                )
                
                context_path = f"{self.mandate_path}/context/general_context/context_company_profile_report"
            
            else:
                return {"success": False, "error": f"Type de contexte inconnu: {context_type}"}
            
            if not success:
                return {"success": False, "error": "√âchec de la sauvegarde Firebase"}
            
            last_refresh = datetime.now(timezone.utc).isoformat()
            logger.info(
                f"[SAVE_FIREBASE] ‚úÖ Sauvegarde r√©ussie - "
                f"type={context_type}, path={context_path}"
            )
            
            return {
                "success": True,
                "context_path": context_path,
                "last_refresh": last_refresh
            }
        
        except Exception as e:
            logger.error(f"[SAVE_FIREBASE] ‚ùå Erreur sauvegarde: {e}", exc_info=True)
            return {"success": False, "error": str(e)}
    
    def get_update_context_definition(self) -> Dict:
        """D√©finition COURTE de l'outil UPDATE_CONTEXT (pour l'API)."""
        return {
            "name": "UPDATE_CONTEXT",
            "description": "‚úèÔ∏è Mise √† jour atomique d'un contexte (router/accounting/bank/company). Op√©rations: add, replace, delete. Demande approbation automatique. ‚ö†Ô∏è router=R√®gles de routage, bank=Contexte bancaire. Utilisez GET_TOOL_HELP pour plus de d√©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "context_type": {
                        "type": "string",
                        "enum": ["router", "accounting", "bank", "company"],
                        "description": "Type de contexte √† modifier"
                    },
                    "service_name": {
                        "type": "string",
                        "description": "Nom du service (requis si context_type=router, ex: hr, banks_cash, etc.)"
                    },
                    "operations": {
                        "type": "array",
                        "description": "Liste des op√©rations de mise √† jour √† appliquer",
                        "items": {
                            "type": "object",
                            "properties": {
                                "section_type": {
                                    "type": "string",
                                    "enum": ["beg", "mid", "end"],
                                    "description": "Partie du texte : d√©but (beg), milieu (mid), fin (end)"
                                },
                                "operation": {
                                    "type": "string",
                                    "enum": ["add", "replace", "delete"],
                                    "description": "Type d'op√©ration"
                                },
                                "new_content": {
                                    "type": "string",
                                    "description": "Nouveau contenu (pour add/replace)"
                                },
                                "context": {
                                    "type": "string",
                                    "description": "Texte exact √† trouver (requis pour mid, optionnel pour beg/end)"
                                }
                            },
                            "required": ["section_type", "operation", "new_content"]
                        }
                    },
                    "preview_only": {
                        "type": "boolean",
                        "description": "Si true, g√©n√®re uniquement une pr√©visualisation (d√©faut: false)",
                        "default": False
                    }
                },
                "required": ["context_type", "operations"]
            }
        }
    
    async def update_context(
        self,
        context_type: str,
        operations: List[Dict],
        service_name: str = None,
        preview_only: bool = False,
        require_approval: bool = True  # üÜï Par d√©faut, demander approbation
    ) -> Dict:
        """
        Met √† jour un contexte en utilisant le TextUpdaterAgent.
        
        üÜï WORKFLOW AVEC APPROBATION :
        1. Applique les op√©rations re√ßues via TextUpdaterAgent
        2. Si require_approval=True ‚Üí Demande approbation via carte interactive
        3. Stocke proposition (pour PUBLISH_CONTEXT)
        4. Retourne statut (pending_approval/rejected/approved)
        
        Args:
            context_type: Type de contexte (router/accounting/company)
            operations: Liste d'op√©rations de modification g√©n√©r√©es par l'agent
            service_name: Nom du service (requis si context_type=router)
            preview_only: Si true, pr√©visualisation uniquement
            require_approval: Si True, demande approbation (d√©faut: True)
        
        Returns:
            Dict avec r√©sum√© de la modification et ID de proposition
        """
        try:
            logger.info(
                f"[UPDATE_CONTEXT] Type={context_type}, service={service_name}, "
                f"preview={preview_only}, require_approval={require_approval}"
            )
            
            if not self.mandate_path:
                return {
                    "success": False,
                    "error": "mandate_path non configur√©"
                }
            
            # Validation : service_name requis pour router
            if context_type == "router" and not service_name:
                return {
                    "success": False,
                    "error": "Le param√®tre 'service_name' est requis pour context_type='router'"
                }
            
            # R√©cup√©rer le contexte actuel
            all_contexts = self.firebase_management.get_all_contexts(self.mandate_path)
            
            if not all_contexts:
                return {
                    "success": False,
                    "error": "Impossible de r√©cup√©rer les contextes depuis Firebase"
                }
            
            # Extraire le texte √† modifier selon le type
            original_text = ""
            context_source = ""
            
            if context_type == "router":
                router_context = all_contexts.get("router", {})
                router_prompt_data = router_context.get("router_prompt", {})
                original_text = router_prompt_data.get(service_name, "")
                context_source = f"router_prompt/{service_name}"
                
                # ‚úÖ G√©rer le cas d'un contexte vide (permettre cr√©ation via "add")
                if not original_text:
                    # V√©rifier si toutes les op√©rations sont des "add"
                    all_operations_are_add = all(
                        op.get("operation") == "add" 
                        for op in operations
                    )
                    
                    if not all_operations_are_add:
                        return {
                            "success": False,
                            "error": f"Service '{service_name}' est vide - seules les op√©rations 'add' sont autoris√©es pour cr√©er du contenu"
                        }
                    
                    logger.info(f"[UPDATE_CONTEXT] Service '{service_name}' vide, cr√©ation de contenu via 'add'")
                    original_text = ""  # Travailler sur cha√Æne vide
            
            elif context_type == "accounting":
                accounting_context = all_contexts.get("accounting", {})
                original_text = accounting_context.get("accounting_context_0", "")
                context_source = "accounting_context/data/accounting_context_0"
                
                # ‚úÖ G√©rer le cas d'un contexte vide (permettre cr√©ation via "add")
                if not original_text:
                    # V√©rifier si toutes les op√©rations sont des "add"
                    all_operations_are_add = all(
                        op.get("operation") == "add" 
                        for op in operations
                    )
                    
                    if not all_operations_are_add:
                        return {
                            "success": False,
                            "error": "accounting_context_0 est vide - seules les op√©rations 'add' sont autoris√©es pour cr√©er du contenu"
                        }
                    
                    logger.info("[UPDATE_CONTEXT] accounting_context_0 vide, cr√©ation de contenu via 'add'")
                    original_text = ""  # Travailler sur cha√Æne vide
            
            elif context_type == "bank":
                bank_context = all_contexts.get("bank", {})
                original_text = bank_context.get("bank_context_0", "")
                context_source = "bank_context/data/bank_context_0"
                
                # ‚úÖ G√©rer le cas d'un contexte vide (permettre cr√©ation via "add")
                if not original_text:
                    all_operations_are_add = all(
                        op.get("operation") == "add"
                        for op in operations
                    )
                    if not all_operations_are_add:
                        return {
                            "success": False,
                            "error": "bank_context_0 est vide - seules les op√©rations 'add' sont autoris√©es pour cr√©er du contenu"
                        }
                    logger.info("[UPDATE_CONTEXT] bank_context_0 vide, cr√©ation de contenu via 'add'")
                    original_text = ""

            elif context_type == "company":
                general_context = all_contexts.get("general", {})
                original_text = general_context.get("context_company_profile_report", "")
                context_source = "general_context/context_company_profile_report"
                
                # ‚úÖ G√©rer le cas d'un contexte vide (permettre cr√©ation via "add")
                if not original_text:
                    # V√©rifier si toutes les op√©rations sont des "add"
                    all_operations_are_add = all(
                        op.get("operation") == "add" 
                        for op in operations
                    )
                    
                    if not all_operations_are_add:
                        return {
                            "success": False,
                            "error": "context_company_profile_report est vide - seules les op√©rations 'add' sont autoris√©es pour cr√©er du contenu"
                        }
                    
                    logger.info("[UPDATE_CONTEXT] context_company_profile_report vide, cr√©ation de contenu via 'add'")
                    original_text = ""  # Travailler sur cha√Æne vide
            
            # Initialiser le text_updater
            self._init_text_updater()
            
            # Validation des op√©rations re√ßues
            if not operations or not isinstance(operations, list):
                return {
                    "success": False,
                    "error": "Le param√®tre 'operations' doit √™tre une liste non vide"
                }
            
            # Appliquer les op√©rations avec TextUpdaterAgent
            update_result = self.text_updater.apply_operations(
                text_to_update=original_text,
                operations_list=operations
            )
            
            if not update_result.get("success"):
                return {
                    "success": False,
                    "error": f"√âchec de la mise √† jour: {update_result.get('error')}",
                    "operations_log": update_result.get("operations_log", [])
                }
            
            updated_text = update_result.get("updated_text", "")
            operations_log = update_result.get("operations_log", [])
            
            # G√©n√©rer un ID de proposition
            import uuid
            import hashlib
            proposal_id = f"proposal_{context_type}_{uuid.uuid4().hex[:8]}"
            
            # Calculer hash pour d√©tection de changements
            text_hash = hashlib.sha256(original_text.encode()).hexdigest()[:12]
            
            # ‚ïê‚ïê‚ïê √âTAPE 2 : Stocker proposition (pour le workflow d'approbation) ‚ïê‚ïê‚ïê
            # Utiliser brain.context_proposal pour stocker temporairement
            # (Le brain est accessible via self.brain dans ContextTools)
            self.brain.context_proposal = {
                "proposal_id": proposal_id,
                "context_type": context_type,
                "context_source": context_source,
                "service_name": service_name,
                "original_text": original_text,
                "original_hash": text_hash,
                "updated_text": updated_text,
                "operations_log": operations_log,
                "operations_requested": operations,  # Stocker les op√©rations originales
                "preview_only": preview_only,
                "created_at": datetime.now(timezone.utc).isoformat(),
                "status": "pending_approval" if require_approval else "approved"
            }
            
            logger.info(
                f"[UPDATE_CONTEXT] Proposition cr√©√©e: {proposal_id} "
                f"(status={'pending_approval' if require_approval else 'approved'})"
            )
            
            # ‚ïê‚ïê‚ïê √âTAPE 3 : Demander approbation si requis ‚ïê‚ïê‚ïê
            if require_approval and not preview_only:
                logger.info(
                    f"[UPDATE_CONTEXT] üÉè Demande approbation pour "
                    f"modification {context_type}"
                )
                
                # D√©tecter warnings
                warnings = []
                failed_ops = [op for op in operations_log if not op.get("success")]
                if failed_ops:
                    warnings.append(
                        f"‚ö†Ô∏è {len(failed_ops)} op√©ration(s) ont √©chou√© lors de la mise √† jour"
                    )
                
                # üÜï APPEL AU SYST√àME D'APPROBATION
                from ...llm_service.llm_manager import get_llm_manager
                
                llm_manager = get_llm_manager()
                
                # R√©cup√©rer thread_key depuis brain
                thread_key = self.brain.active_thread_key
                
                if not thread_key:
                    logger.error(
                        "[UPDATE_CONTEXT] ‚ùå active_thread_key non d√©fini dans brain. "
                        "Impossible d'envoyer carte d'approbation."
                    )
                    # Fallback: approuver automatiquement
                    self.brain.context_proposal["status"] = "approved"
                    self.brain.context_proposal["auto_approved_reason"] = "thread_key_missing"
                else:
                    try:
                        approval_result = await llm_manager.request_approval_with_card(
                            user_id=self.firebase_user_id,
                            collection_name=self.collection_name,
                            thread_key=thread_key,
                            card_type="text_modification_approval",
                            card_params={
                                "context_type": context_type,
                                "original_text": original_text,
                                "operations_log": operations_log,
                                "final_text": updated_text,
                                "warnings": warnings
                            },
                            timeout=900  # 15 minutes
                        )
                        
                        # Mettre √† jour le statut de la proposition
                        if approval_result.get("approved"):
                            self.brain.context_proposal["status"] = "approved"
                            self.brain.context_proposal["approved_at"] = datetime.now(timezone.utc).isoformat()
                            self.brain.context_proposal["user_comment"] = approval_result.get("user_message", "")
                            
                            logger.info(f"[UPDATE_CONTEXT] ‚úÖ Modification approuv√©e")
                            
                            # üÜï SAUVEGARDER AUTOMATIQUEMENT DANS FIREBASE
                            logger.info(f"[UPDATE_CONTEXT] üíæ Sauvegarde automatique dans Firebase...")
                            
                            save_result = await self._save_context_to_firebase(
                                context_type=context_type,
                                service_name=service_name,
                                updated_text=updated_text
                            )
                            
                            if save_result.get("success"):
                                # Nettoyer la proposition apr√®s sauvegarde r√©ussie
                                self.brain.context_proposal = None
                                
                                logger.info(
                                    f"[UPDATE_CONTEXT] ‚úÖ Sauvegarde r√©ussie - "
                                    f"path={save_result.get('context_path')}"
                                )
                                
                                return {
                                    "success": True,
                                    "status": "published",  # ‚Üê Nouveau statut !
                                    "message": f"‚úÖ Modification de {context_type} approuv√©e et sauvegard√©e dans Firebase",
                                    "proposal_id": proposal_id,
                                    "operations_count": len(operations_log),
                                    "user_comment": approval_result.get("user_message", ""),
                                    "context_path": save_result.get("context_path"),
                                    "last_refresh": save_result.get("last_refresh")
                                }
                            else:
                                # Sauvegarde a √©chou√© malgr√© l'approbation
                                logger.error(
                                    f"[UPDATE_CONTEXT] ‚ùå √âchec sauvegarde: "
                                    f"{save_result.get('error')}"
                                )
                                return {
                                    "success": False,
                                    "status": "approved_but_save_failed",
                                    "message": f"‚ö†Ô∏è Modification approuv√©e mais √©chec de sauvegarde Firebase",
                                    "proposal_id": proposal_id,
                                    "save_error": save_result.get("error")
                                }
                        else:
                            # Modification refus√©e par l'utilisateur
                            user_comment = approval_result.get("user_message", "")
                            is_timeout = approval_result.get("timeout", False)
                            
                            self.brain.context_proposal["status"] = "rejected"
                            self.brain.context_proposal["rejected_at"] = datetime.now(timezone.utc).isoformat()
                            self.brain.context_proposal["rejection_reason"] = user_comment
                            
                            # Logger le refus avec le commentaire
                            if is_timeout:
                                logger.warning(
                                    f"[UPDATE_CONTEXT] ‚è∞ Timeout - Aucune r√©ponse apr√®s 15 minutes"
                                )
                            else:
                                logger.info(
                                    f"[UPDATE_CONTEXT] ‚ùå Modification refus√©e - "
                                    f"Commentaire: {user_comment if user_comment else 'Aucun'}"
                                )
                            
                            # Nettoyer la proposition (ne pas garder en m√©moire)
                            self.brain.context_proposal = None
                            
                            return {
                                "success": False,
                                "status": "rejected",
                                "message": f"‚ùå Modification de {context_type} refus√©e par l'utilisateur",
                                "proposal_id": proposal_id,
                                "rejection_reason": user_comment,
                                "rejected_at": datetime.now(timezone.utc).isoformat(),
                                "timeout": is_timeout
                            }
                    
                    except Exception as e:
                        logger.error(f"[UPDATE_CONTEXT] Erreur approbation: {e}", exc_info=True)
                        # Fallback: approuver automatiquement en cas d'erreur
                        self.brain.context_proposal["status"] = "approved"
                        self.brain.context_proposal["auto_approved_reason"] = f"approval_error: {str(e)}"
            else:
                # Pas d'approbation requise ou preview_only
                logger.info(
                    f"[UPDATE_CONTEXT] Aucune approbation requise "
                    f"(require_approval={require_approval}, preview_only={preview_only})"
                )
            
            # Retourner seulement un R√âSUM√â (pour ne pas surcharger l'historique)
            return {
                "success": True,
                "proposal_id": proposal_id,
                "context_type": context_type,
                "service_name": service_name if service_name else "N/A",
                "original_hash": text_hash,
                "original_length": len(original_text),
                "original_preview": original_text[:300] + "..." if len(original_text) > 300 else original_text,
                "updated_length": len(updated_text),
                "updated_preview": updated_text[:300] + "..." if len(updated_text) > 300 else updated_text,
                "operations_count": len(operations_log),
                "operations_summary": [
                    f"‚Ä¢ {op.get('args_from_llm', {}).get('operation', '?').upper()} sur {op.get('args_from_llm', {}).get('section_type', '?')}"
                    for op in operations_log[:5]  # Max 5 premi√®res op√©rations
                ],
                "preview_only": preview_only,
                "status": self.brain.context_proposal.get("status", "unknown"),
                "summary": f"‚úèÔ∏è Modification pr√©par√©e: {len(operations_log)} op√©ration(s) sur {context_type}",
                "next_step": "üÉè Carte d'approbation envoy√©e - En attente de validation" if not preview_only else "üëÅÔ∏è Pr√©visualisation uniquement"
            }
        
        except Exception as e:
            logger.error(f"[UPDATE_CONTEXT] Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    # üóëÔ∏è PUBLISH_CONTEXT a √©t√© supprim√© - La sauvegarde se fait automatiquement dans UPDATE_CONTEXT apr√®s approbation
