"""
Pinnokio Brain - Agent Cerveau Principal
Agent orchestrateur intelligent avec capacitÃ© de raisonnement pour gÃ©rer SPT et LPT

â­ Architecture Stateless (Multi-Instance Ready):
L'historique de chat est externalisÃ© dans Redis via ChatHistoryManager.
Cela permet le scaling horizontal : n'importe quelle instance peut reprendre
une conversation crÃ©Ã©e par une autre instance.
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timezone
import json

from ...llm.klk_agents import BaseAIAgent, ModelProvider, ModelSize, NEW_Anthropic_Agent, NEW_OpenAiAgent
from ...llm_service.chat_history_manager import get_chat_history_manager, ChatHistoryManager
from .agent_modes import get_agent_mode_config

logger = logging.getLogger("pinnokio.brain")


class PinnokioBrain:
    """
    Agent cerveau principal (Pinnokio) avec capacitÃ© d'orchestration SPT/LPT
    
    ResponsabilitÃ©s:
    - Comprendre les requÃªtes utilisateur complexes
    - Ã‰laborer des plans d'action structurÃ©s
    - Orchestrer l'exÃ©cution SPT (synchrone) et LPT (asynchrone)
    - Maintenir le contexte pendant l'exÃ©cution
    - Communiquer avec l'utilisateur pendant les LPT
    """
    
    def __init__(self, 
                 collection_name: str,
                 firebase_user_id: str,
                 dms_system: str = "google_drive",
                 dms_mode: str = "prod"):
        """
        Initialise l'agent cerveau Pinnokio
        
        Args:
            collection_name: Nom de la collection (sociÃ©tÃ©)
            firebase_user_id: ID utilisateur Firebase
            dms_system: SystÃ¨me DMS (google_drive, etc.)
            dms_mode: Mode DMS (prod, test)
        """
        self.collection_name = collection_name
        self.firebase_user_id = firebase_user_id
        self.dms_system = dms_system
        self.dms_mode = dms_mode
        
        # â­ NOUVELLE ARCHITECTURE: Agent principal crÃ©Ã© via initialize_agents()
        # Chaque brain a son propre agent principal isolÃ©
        self.pinnokio_agent: Optional[BaseAIAgent] = None
        
        # Configuration du provider (modÃ¨le de raisonnement)
        self.default_provider = ModelProvider.OPENAI
        self.default_size = ModelSize.MEDIUM  # Kimi K2 pour raisonnement + streaming + tools
        
        # â­ NOUVELLE ARCHITECTURE: L'historique est gÃ©rÃ© par self.pinnokio_agent
        # Plus de duplication d'historique au niveau du brain
        
        # Ã‰tat de l'orchestration
        self.active_plans: Dict[str, Dict] = {}  # {thread_key: plan_data}
        self.active_lpt_tasks: Dict[str, List[str]] = {}  # {thread_key: [task_ids]}
        
        # â­ NOUVEAU: Contexte utilisateur (mÃ©tadonnÃ©es sociÃ©tÃ©)
        # Contient: mandate_path, dms_system, communication_mode, etc.
        # Accessible par tous les outils (SPT et LPT)
        self.user_context: Optional[Dict[str, Any]] = None
        
        # â­ NOUVEAU: Agent SPT ContextManager (sera initialisÃ© dans initialize_spt_agents)
        # Chaque agent SPT a son propre BaseAIAgent et chat_history isolÃ©
        self.context_manager = None
        
        # â­ NOUVEAU: Jobs data et mÃ©triques (assignÃ©s depuis LLMSession)
        # Ces donnÃ©es sont chargÃ©es Ã  l'initialisation de la session pour allÃ©ger le contexte
        self.jobs_data: Dict[str, Any] = {}  # DonnÃ©es complÃ¨tes des jobs (pour GET_JOBS)
        self.jobs_metrics: Dict[str, Any] = {}  # MÃ©triques pour le system prompt
        
        # â­ NOUVEAU: Thread actif (pour workflows d'approbation avec cartes)
        self.active_thread_key: Optional[str] = None
        
        # â­ NOUVEAU: Proposition de contexte en attente (pour UPDATE_CONTEXT â†’ PUBLISH_CONTEXT)
        self.context_proposal: Optional[Dict[str, Any]] = None

        # â­ NOUVEAU: DonnÃ©es de la tÃ¢che en cours d'exÃ©cution (si mode task_execution)
        self.active_task_data: Optional[Dict[str, Any]] = None

        # â­ Mode de chat courant (utilisÃ© pour la config prompt/outils)
        self.current_chat_mode: str = "general_chat"

        # â­ DonnÃ©es spÃ©cifiques onboarding (chargÃ©es Ã  la demande, uniquement pour onboarding_chat)
        self.onboarding_data: Optional[Dict[str, Any]] = None
        
        # â­ DonnÃ©es spÃ©cifiques job (chargÃ©es Ã  la demande, pour router_chat, banker_chat, etc.)
        self.job_data: Optional[Dict[str, Any]] = None
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # â­ ARCHITECTURE STATELESS (Multi-Instance Ready)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ChatHistoryManager externalise l'historique dans Redis
        # Approche hybride: cache local (performance) + Redis (durabilitÃ©)
        self._chat_history_manager: ChatHistoryManager = get_chat_history_manager()
        self._redis_sync_enabled: bool = True  # Activer la sync Redis

        logger.info(f"PinnokioBrain initialisÃ© pour user={firebase_user_id}, collection={collection_name}")
    
    async def initialize_agents(self):
        """
        CrÃ©e les agents du brain (principal + outils SPT).
        
        â­ NOUVELLE ARCHITECTURE : Chaque brain a ses propres agents isolÃ©s
        
        CrÃ©ation:
        1. Agent principal (pinnokio_agent) - BaseAIAgent pour interaction utilisateur
        2. Agents SPT (context_manager, etc.) - Pour outils rapides
        
        Cette mÃ©thode doit Ãªtre appelÃ©e immÃ©diatement aprÃ¨s la crÃ©ation du brain,
        avant d'injecter les donnÃ©es de session et d'initialiser le system prompt.
        """
        try:
            logger.info(f"[BRAIN] ðŸ¤– CrÃ©ation agents pour brain (user={self.firebase_user_id}, collection={self.collection_name})")
            
            # â•â•â• 1. CrÃ©er l'agent principal â•â•â•
            self.pinnokio_agent = BaseAIAgent(
                collection_name=self.collection_name,
                dms_system=self.dms_system,
                dms_mode=self.dms_mode,
                firebase_user_id=self.firebase_user_id
            )
            
            # Configurer le provider et la taille par dÃ©faut
            self.pinnokio_agent.default_provider = self.default_provider
            self.pinnokio_agent.default_model_size = self.default_size
            
            # â•â•â• 2. CrÃ©er et enregistrer l'instance du provider â•â•â•
            # CrÃ©er l'instance OpenAI (sans arguments)
            openai_instance = NEW_OpenAiAgent()
            
            # Enregistrer le provider dans BaseAIAgent
            # BaseAIAgent a dÃ©jÃ  collection_name, dms_system, dms_mode, firebase_user_id
            self.pinnokio_agent.register_provider(
                provider=self.default_provider,
                instance=openai_instance,
                default_model_size=self.default_size
            )
            
            logger.info(f"[BRAIN] âœ… Agent principal crÃ©Ã© (provider={self.default_provider.value}, size={self.default_size.value}, model=Kimi K2)")
            
            # â•â•â• 3. CrÃ©er les agents SPT â•â•â•
            
            logger.info(f"[BRAIN] âœ… Agents SPT crÃ©Ã©s")
            
            logger.info(f"[BRAIN] ðŸŽ‰ Tous les agents crÃ©Ã©s avec succÃ¨s")
            
        except Exception as e:
            logger.error(f"[BRAIN] âŒ Erreur crÃ©ation agents: {e}", exc_info=True)
            raise
    
    def initialize_system_prompt(self, chat_mode: str = "general_chat", jobs_metrics: Dict = None):
        """Initialise le system prompt en fonction du mode dÃ©clarÃ©."""

        config = get_agent_mode_config(chat_mode)

        if not self.pinnokio_agent:
            raise RuntimeError("Pinnokio agent non initialisÃ© avant initialize_system_prompt")

        prompt = config.prompt_builder(self, jobs_metrics, chat_mode)
        self.pinnokio_agent.update_system_prompt(prompt)
        self.current_chat_mode = config.name

        logger.info(
            f"System prompt initialisÃ© pour mode={chat_mode} (config={config.name})"
        )
    
    
    def create_workflow_tools(
        self,
        thread_key: str,
        session=None,
        chat_mode: str = "general_chat",
        mode: str = "UI",  # â­ NOUVEAU : Mode UI ou BACKEND pour rechargement Redis
    ) -> Tuple[List[Dict], Dict]:
        """
        Retourne l'ensemble d'outils configurÃ© pour le mode de chat.
        
        Args:
            thread_key: ClÃ© du thread
            session: Session LLM (optionnel)
            chat_mode: Mode de chat (general_chat, router_chat, etc.)
            mode: "UI" (utilisateur connectÃ©, cache Redis Ã  jour) ou "BACKEND" (utilisateur dÃ©connectÃ©)
        """

        config = get_agent_mode_config(chat_mode)
        tool_set, tool_mapping = config.tool_builder(self, thread_key, session, chat_mode, mode=mode)

        logger.info(
            f"Outils initialisÃ©s pour mode={chat_mode} (config={config.name}) : {len(tool_set)} outils"
        )
        return tool_set, tool_mapping


    def _build_general_chat_tools(self, thread_key: str, session=None, mode: str = "UI") -> Tuple[List[Dict], Dict]:
        """
        Construit l'ensemble d'outils standard (mode gÃ©nÃ©ral).
        
        Args:
            thread_key: ClÃ© du thread
            session: Session LLM (optionnel)
            mode: "UI" (utilisateur connectÃ©, cache Redis Ã  jour) ou "BACKEND" (utilisateur dÃ©connectÃ©)
        """
        # â­ Stocker le mode pour les handlers d'outils
        self._current_mode = mode
        
        from ..tools.spt_tools import SPTTools
        from ..tools.lpt_client import LPTClient
        
        
        # CrÃ©er les outils SPT
        # â­ IMPORTANT : Passer le brain pour accÃ¨s au contexte utilisateur
        spt_tools = SPTTools(
            firebase_user_id=self.firebase_user_id,
            collection_name=self.collection_name,
            brain=self
        )
        spt_tools_list = spt_tools.get_tools_definitions()
        spt_tools_mapping = spt_tools.get_tools_mapping()

        # âš ï¸ SPT_CONTEXT_MANAGER DÃ‰SACTIVÃ‰ TEMPORAIREMENT
        # Les outils de contexte sont maintenant intÃ©grÃ©s directement dans l'agent principal
        # via ContextTools (job_tools.py) pour un accÃ¨s plus rapide et direct.
        # Le code SPT est conservÃ© pour usage futur avec d'autres agents SPT.
        #
        # from ..tools.spt_context_manager import create_spt_context_manager_wrapper
        # tool_def, handler = create_spt_context_manager_wrapper(self)
        # spt_tools_list.append(tool_def)
        # spt_tools_mapping["SPT_CONTEXT_MANAGER"] = handler
        
        # CrÃ©er les outils LPT avec session pour cache
        lpt_client = LPTClient()
        lpt_tools_list, lpt_tools_mapping = lpt_client.get_tools_definitions_and_mapping(
            user_id=self.firebase_user_id,
            company_id=self.collection_name,
            thread_key=thread_key,
            session=session,  # â­ Passer la session pour le cache
            brain=self        # â­ IMPORTANT: Passer le brain pour accÃ¨s au contexte utilisateur
        )
        
        # â•â•â• OUTILS JOBS (3 outils sÃ©parÃ©s par dÃ©partement) â•â•â•
        # CrÃ©er les 3 outils jobs avec leurs handlers
        from ..tools.job_tools import APBookkeeperJobTools, RouterJobTools, BankJobTools, ContextTools
        
        # ðŸ” LOGS DE DIAGNOSTIC - VÃ©rifier jobs_data avant crÃ©ation outils
        logger.info(f"[BRAIN] ðŸ” DIAGNOSTIC self.jobs_data avant crÃ©ation outils - "
                   f"ClÃ©s: {list(self.jobs_data.keys()) if self.jobs_data else 'None'}")
        if self.jobs_data and 'ROUTER' in self.jobs_data:
            router_to_process = self.jobs_data['ROUTER'].get('to_process', [])  # âœ… CorrigÃ© : format Reflex utilise 'to_process'
            logger.info(f"[BRAIN] ðŸ” DIAGNOSTIC self.jobs_data['ROUTER']['to_process'] - "
                       f"Longueur: {len(router_to_process) if isinstance(router_to_process, list) else 'N/A'}")
        else:
            logger.warning(f"[BRAIN] âš ï¸ DIAGNOSTIC - Pas de donnÃ©es ROUTER dans self.jobs_data !")
        
        # â­ DÃ©terminer le mode (UI si user_context existe, BACKEND sinon)
        # Le mode UI signifie que l'utilisateur est connectÃ© et que le cache Redis est Ã  jour
        mode = "UI" if self.user_context else "BACKEND"
        
        # 1. APBookkeeper Jobs - â­ Passer paramÃ¨tres pour rechargement Redis
        apbookeeper_tools = APBookkeeperJobTools(
            jobs_data=self.jobs_data,
            user_id=self.firebase_user_id,
            company_id=self.collection_name,
            user_context=self.user_context,
            mode=mode
        )
        get_apbookeeper_jobs_def = apbookeeper_tools.get_tool_definition()
        
        async def handle_get_apbookeeper_jobs(**kwargs):
            return await apbookeeper_tools.search(**kwargs)
        
        # 2. Router Jobs - â­ Passer paramÃ¨tres pour rechargement Redis
        router_tools = RouterJobTools(
            jobs_data=self.jobs_data,
            user_id=self.firebase_user_id,
            company_id=self.collection_name,
            user_context=self.user_context,
            mode=mode
        )
        get_router_jobs_def = router_tools.get_tool_definition()
        
        async def handle_get_router_jobs(**kwargs):
            return await router_tools.search(**kwargs)
        
        # 3. Bank Transactions - â­ Passer paramÃ¨tres pour rechargement Redis
        bank_tools = BankJobTools(
            jobs_data=self.jobs_data,
            user_id=self.firebase_user_id,
            company_id=self.collection_name,
            user_context=self.user_context,
            mode=mode
        )
        get_bank_transactions_def = bank_tools.get_tool_definition()
        
        async def handle_get_bank_transactions(**kwargs):
            return await bank_tools.search(**kwargs)
        
        # â•â•â• OUTILS CONTEXT (5 outils d'accÃ¨s et modification des contextes) â•â•â•
        # CrÃ©er les outils de contexte avec leurs handlers
        from ...firebase_providers import FirebaseManagement
        firebase_management = FirebaseManagement()
        
        context_tools = ContextTools(
            firebase_management=firebase_management,
            firebase_user_id=self.firebase_user_id,
            collection_name=self.collection_name,
            brain=self  # âœ… Passer le brain pour accÃ¨s au user_context
        )
        
        # DÃ©finitions des outils de contexte
        router_prompt_def = context_tools.get_router_prompt_definition()
        apbookeeper_context_def = context_tools.get_apbookeeper_context_definition()
        company_context_def = context_tools.get_company_context_definition()
        update_context_def = context_tools.get_update_context_definition()
        
        # Handlers pour les outils de contexte
        async def handle_router_prompt(**kwargs):
            return await context_tools.get_router_prompt(**kwargs)
        
        async def handle_apbookeeper_context(**kwargs):
            return await context_tools.get_apbookeeper_context(**kwargs)
        
        async def handle_company_context(**kwargs):
            return await context_tools.get_company_context(**kwargs)
        
        async def handle_update_context(**kwargs):
            return await context_tools.update_context(**kwargs)

        # â•â•â• OUTIL VISION DOCUMENT DRIVE â•â•â•
        view_drive_document_def = {
            "name": "VIEW_DRIVE_DOCUMENT",
            "description": "ðŸ–¼ï¸ Visualiser un document Google Drive (PDF, image, facture). Requis: file_id obtenu via GET_APBOOKEEPER_JOBS ou GET_ROUTER_JOBS. GET_TOOL_HELP pour dÃ©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "file_id": {
                        "type": "string",
                        "description": "ID du fichier Google Drive Ã  visionner (ex: '1A2B3C4D5E')"
                    },
                    "question": {
                        "type": "string",
                        "description": "Question spÃ©cifique sur le document (optionnel). Si non fourni, fait une analyse gÃ©nÃ©rale."
                    }
                },
                "required": ["file_id"]
            }
        }
        
        async def handle_view_drive_document(**kwargs):
            """Handler pour visionner un document Google Drive."""
            try:
                file_id = kwargs.get("file_id")
                question = kwargs.get("question", "DÃ©cris le contenu de ce document en dÃ©tail.")
                
                # âœ… VALIDATION : VÃ©rifier que file_id est fourni et non vide
                if not file_id or not isinstance(file_id, str) or len(file_id.strip()) == 0:
                    error_msg = (
                        "âŒ ParamÃ¨tre 'file_id' manquant ou invalide. "
                        "Pour voir un document, tu DOIS d'abord rÃ©cupÃ©rer son drive_file_id "
                        "en utilisant GET_APBOOKEEPER_JOBS, GET_ROUTER_JOBS ou GET_BANK_TRANSACTIONS."
                    )
                    logger.warning(f"[VIEW_DRIVE_DOCUMENT] {error_msg}")
                    return {
                        "type": "error",
                        "message": error_msg
                    }
                
                # VÃ©rifier que le DMS est disponible
                if not self.pinnokio_agent or not self.pinnokio_agent.dms_system:
                    return {
                        "type": "error",
                        "message": "SystÃ¨me DMS non initialisÃ©. Impossible d'accÃ©der aux documents Drive."
                    }
                
                logger.info(f"[VIEW_DRIVE_DOCUMENT] ðŸ–¼ï¸ Vision du document: file_id={file_id}")
                
                # Utiliser process_vision de BaseAIAgent avec Groq (Llama Scout)
                response = await asyncio.to_thread(
                    self.pinnokio_agent.process_vision,
                    text=question,
                    provider=self.default_provider,  # GROQ
                    size=ModelSize.MEDIUM,  # Llama Scout 17B (vision)
                    file_ids=[file_id],  # ðŸ”¥ CORRECTION: paramÃ¨tre renommÃ© drive_file_ids -> file_ids
                    method='batch',
                    max_tokens=2000,
                    final_resume=True
                )
                
                logger.info(f"[VIEW_DRIVE_DOCUMENT] âœ… Analyse terminÃ©e")
                
                return {
                    "type": "success",
                    "file_id": file_id,
                    "analysis": response if isinstance(response, str) else response.get('text_output', str(response))
                }
                
            except ImportError as e:
                # âœ… GÃ©rer spÃ©cifiquement les erreurs d'import de pdf2image
                error_msg = str(e)
                if "pdf2image" in error_msg.lower() or "poppler" in error_msg.lower():
                    detailed_msg = (
                        f"Le module 'pdf2image' n'est pas disponible pour analyser le fichier '{file_id}'. "
                        f"Installez-le avec: pip install pdf2image. "
                        f"Sur Windows, vous devez aussi installer poppler: "
                        f"https://github.com/oschwartz10612/poppler-windows/releases/"
                    )
                else:
                    detailed_msg = f"Erreur d'import: {error_msg}"
                logger.error(f"[VIEW_DRIVE_DOCUMENT] âŒ Erreur d'import: {e}")
                return {
                    "type": "error",
                    "message": detailed_msg,
                    "file_id": file_id
                }
            except FileNotFoundError as e:
                # âœ… GÃ©rer spÃ©cifiquement les erreurs 404 (fichier non trouvÃ©)
                error_msg = f"Le fichier Google Drive '{file_id}' n'a pas Ã©tÃ© trouvÃ©. Il a peut-Ãªtre Ã©tÃ© supprimÃ©, dÃ©placÃ©, ou vous n'avez pas les permissions nÃ©cessaires pour y accÃ©der."
                logger.error(f"[VIEW_DRIVE_DOCUMENT] âŒ Fichier non trouvÃ©: {e}")
                return {
                    "type": "error",
                    "message": error_msg,
                    "file_id": file_id
                }
            except ValueError as e:
                # âœ… GÃ©rer les erreurs de conversion/transformation
                error_msg = str(e)
                if "Aucun contenu d'image" in error_msg or "Aucune image" in error_msg:
                    logger.error(f"[VIEW_DRIVE_DOCUMENT] âŒ Erreur de traitement: {e}")
                    return {
                        "type": "error",
                        "message": f"Impossible de traiter le fichier '{file_id}'. {error_msg}",
                        "file_id": file_id
                    }
                else:
                    logger.error(f"[VIEW_DRIVE_DOCUMENT] âŒ Erreur de validation: {e}")
                    return {
                        "type": "error",
                        "message": error_msg,
                        "file_id": file_id
                    }
            except Exception as e:
                logger.error(f"[VIEW_DRIVE_DOCUMENT] âŒ Erreur: {e}", exc_info=True)
                return {
                    "type": "error",
                    "message": f"Erreur lors de la vision du document: {str(e)}"
                }

        # â•â•â• OUTILS TASK (gestion tÃ¢ches planifiÃ©es) â•â•â•
        from ..tools.task_tools import TaskTools

        task_tools = TaskTools(brain=self)
        create_task_def = task_tools.get_tool_definition()

        async def handle_create_task(**kwargs):
            return await task_tools.create_task(**kwargs)

        # â•â•â• OUTILS WORKFLOW CHECKLIST (pour tÃ¢ches planifiÃ©es) â•â•â•
        create_checklist_tool = {
            "name": "CREATE_CHECKLIST",
            "description": "ðŸ“‹ CrÃ©er la checklist de workflow (mode task_execution). Chaque Ã©tape: id + name. GET_TOOL_HELP pour dÃ©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "steps": {
                        "type": "array",
                        "description": "Liste des Ã©tapes Ã  rÃ©aliser",
                        "items": {
                            "type": "object",
                            "properties": {
                                "id": {
                                    "type": "string",
                                    "description": "ID unique (ex: 'STEP_1_GET_TRANSACTIONS')"
                                },
                                "name": {
                                    "type": "string",
                                    "description": "Nom descriptif de l'Ã©tape"
                                }
                            },
                            "required": ["id", "name"]
                        }
                    }
                },
                "required": ["steps"]
            }
        }

        update_step_tool = {
            "name": "UPDATE_STEP",
            "description": "ðŸ“Š Mettre Ã  jour le statut d'une Ã©tape (in_progress/completed/error). GET_TOOL_HELP pour dÃ©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "step_id": {
                        "type": "string",
                        "description": "ID de l'Ã©tape"
                    },
                    "status": {
                        "type": "string",
                        "enum": ["in_progress", "completed", "error"],
                        "description": "Nouveau statut"
                    },
                    "message": {
                        "type": "string",
                        "description": "Message descriptif"
                    }
                },
                "required": ["step_id", "status", "message"]
            }
        }

        async def handle_create_checklist(**kwargs):
            """CrÃ©e la workflow checklist."""
            try:
                steps = kwargs["steps"]

                # Valider qu'on est en mode tÃ¢che
                if not self.active_task_data:
                    return {"type": "error", "message": "Non disponible (mode normal)"}

                task_id = self.active_task_data["task_id"]
                execution_id = self.active_task_data["execution_id"]
                mandate_path = self.active_task_data["mandate_path"]
                thread_key = self.active_thread_key

                # PrÃ©parer les Ã©tapes
                formatted_steps = []
                for step in steps:
                    formatted_steps.append({
                        "id": step["id"],
                        "name": step["name"],
                        "status": "pending",
                        "timestamp": "",
                        "message": ""
                    })

                checklist_data = {
                    "total_steps": len(formatted_steps),
                    "current_step": 0,
                    "steps": formatted_steps
                }

                # Sauvegarder dans execution
                from ...firebase_providers import get_firebase_management
                fbm = get_firebase_management()

                fbm.update_task_execution(
                    mandate_path, task_id, execution_id,
                    {"workflow_checklist": checklist_data}
                )

                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ENVOI PAR WEBSOCKET + RTDB (comme pour les messages de chat)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                from ...ws_hub import hub
                from ...firebase_providers import get_firebase_realtime
                import uuid
                
                checklist_message_id = str(uuid.uuid4())
                timestamp = datetime.now(timezone.utc).isoformat()
                
                # Construire le message de commande
                user_language = self.user_context.get("user_language", "fr") if self.user_context else "fr"
                
                checklist_command = {
                    "action": "SET_WORKFLOW_CHECKLIST",
                    "params": {
                        "checklist": checklist_data,
                        "user_language": user_language
                    }
                }
                
                # 1. Envoi immÃ©diat par WebSocket
                ws_message = {
                    "type": "WORKFLOW_CHECKLIST",
                    "thread_key": thread_key,
                    "timestamp": timestamp,
                    "message_id": checklist_message_id,
                    "content": json.dumps({
                        "message": {
                            "cmmd": checklist_command
                        }
                    })
                }
                
                ws_channel = f"chat:{self.firebase_user_id}:{self.collection_name}:{thread_key}"
                
                # â­ Broadcast conditionnel selon le mode (UI/BACKEND)
                current_mode = getattr(self, "_current_mode", "UI")
                if current_mode == "UI":
                    await hub.broadcast(self.firebase_user_id, {
                        "type": "WORKFLOW_CHECKLIST",
                        "channel": ws_channel,
                        "payload": ws_message
                    })
                    logger.info(f"[CREATE_CHECKLIST] ðŸ“¡ Checklist envoyÃ©e via WebSocket (mode={current_mode})")
                else:
                    logger.info(f"[CREATE_CHECKLIST] â­ï¸ Broadcast WebSocket ignorÃ© (mode={current_mode})")
                
                # 2. Sauvegarde dans RTDB pour persistence
                rtdb = get_firebase_realtime()
                rtdb_path = f"{self.collection_name}/chats/{thread_key}/messages/{checklist_message_id}"
                
                message_data = {
                    'content': json.dumps({
                        'message': {
                            'cmmd': checklist_command
                        }
                    }),
                    'sender_id': self.firebase_user_id,
                    'timestamp': timestamp,
                    'message_type': 'CMMD',
                    'read': False,
                    'role': 'assistant'
                }
                
                # Utiliser push() pour gÃ©nÃ©rer une clÃ© unique
                thread_path = f"{self.collection_name}/chats/{thread_key}"
                messages_ref = rtdb.db.child(f'{thread_path}/messages')
                messages_ref.push(message_data)
                
                logger.info(f"[CREATE_CHECKLIST] ðŸ’¾ Checklist sauvegardÃ©e dans RTDB")
                logger.info(f"[CREATE_CHECKLIST] âœ… {len(formatted_steps)} Ã©tapes crÃ©Ã©es")

                return {
                    "type": "success",
                    "message": f"Checklist crÃ©Ã©e : {len(formatted_steps)} Ã©tapes",
                    "total_steps": len(formatted_steps)
                }

            except Exception as e:
                logger.error(f"[CREATE_CHECKLIST] Erreur: {e}", exc_info=True)
                return {"type": "error", "message": str(e)}

        async def handle_update_step(**kwargs):
            """Met Ã  jour une Ã©tape de la checklist."""
            try:
                step_id = kwargs["step_id"]
                status = kwargs["status"]
                message = kwargs["message"]

                # Valider mode tÃ¢che
                if not self.active_task_data:
                    return {"type": "error", "message": "Non disponible (mode normal)"}

                task_id = self.active_task_data["task_id"]
                execution_id = self.active_task_data["execution_id"]
                mandate_path = self.active_task_data["mandate_path"]
                thread_key = self.active_thread_key

                # RÃ©cupÃ©rer l'exÃ©cution
                from ...firebase_providers import get_firebase_management
                fbm = get_firebase_management()

                execution = fbm.get_task_execution(mandate_path, task_id, execution_id)

                if not execution:
                    return {"type": "error", "message": "ExÃ©cution non trouvÃ©e"}

                checklist = execution.get("workflow_checklist", {})
                steps = checklist.get("steps", [])

                # Trouver et mettre Ã  jour l'Ã©tape
                step_found = False
                for step in steps:
                    if step["id"] == step_id:
                        step["status"] = status
                        step["timestamp"] = datetime.now(timezone.utc).isoformat()
                        step["message"] = message
                        step_found = True
                        break

                if not step_found:
                    return {"type": "error", "message": f"Ã‰tape {step_id} non trouvÃ©e"}

                # Sauvegarder
                fbm.update_task_execution(
                    mandate_path, task_id, execution_id,
                    {"workflow_checklist.steps": steps}
                )

                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ENVOI PAR WEBSOCKET + RTDB (comme pour les messages de chat)
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                
                from ...ws_hub import hub
                from ...firebase_providers import get_firebase_realtime
                import uuid
                
                update_message_id = str(uuid.uuid4())
                timestamp = datetime.now(timezone.utc).isoformat()
                
                # Construire le message de commande
                update_command = {
                    "action": "UPDATE_STEP_STATUS",
                    "params": {
                        "step_id": step_id,
                        "status": status,
                        "timestamp": timestamp,
                        "message": message
                    }
                }
                
                # 1. Envoi immÃ©diat par WebSocket
                ws_message = {
                    "type": "WORKFLOW_STEP_UPDATE",
                    "thread_key": thread_key,
                    "timestamp": timestamp,
                    "message_id": update_message_id,
                    "content": json.dumps({
                        "message": {
                            "cmmd": update_command
                        }
                    })
                }
                
                ws_channel = f"chat:{self.firebase_user_id}:{self.collection_name}:{thread_key}"
                
                # â­ Broadcast conditionnel selon le mode (UI/BACKEND)
                current_mode = getattr(self, "_current_mode", "UI")
                if current_mode == "UI":
                    await hub.broadcast(self.firebase_user_id, {
                        "type": "WORKFLOW_STEP_UPDATE",
                        "channel": ws_channel,
                        "payload": ws_message
                    })
                    logger.info(f"[UPDATE_STEP] ðŸ“¡ Mise Ã  jour envoyÃ©e via WebSocket (mode={current_mode})")
                else:
                    logger.info(f"[UPDATE_STEP] â­ï¸ Broadcast WebSocket ignorÃ© (mode={current_mode})")
                
                # 2. Sauvegarde dans RTDB pour persistence
                rtdb = get_firebase_realtime()
                
                message_data = {
                    'content': json.dumps({
                        'message': {
                            'cmmd': update_command
                        }
                    }),
                    'sender_id': self.firebase_user_id,
                    'timestamp': timestamp,
                    'message_type': 'CMMD',
                    'read': False,
                    'role': 'assistant'
                }
                
                # Utiliser push() pour gÃ©nÃ©rer une clÃ© unique
                thread_path = f"{self.collection_name}/chats/{thread_key}"
                messages_ref = rtdb.db.child(f'{thread_path}/messages')
                messages_ref.push(message_data)
                
                logger.info(f"[UPDATE_STEP] ðŸ’¾ Mise Ã  jour sauvegardÃ©e dans RTDB")
                logger.info(f"[UPDATE_STEP] âœ… {step_id} â†’ {status}: {message}")

                return {
                    "type": "success",
                    "message": f"Ã‰tape {step_id} mise Ã  jour : {status}"
                }

            except Exception as e:
                logger.error(f"[UPDATE_STEP] Erreur: {e}", exc_info=True)
                return {"type": "error", "message": str(e)}

        # Outil GET_CURRENT_DATETIME
        get_current_datetime_tool = {
            "name": "GET_CURRENT_DATETIME",
            "description": "â° Date/heure actuelles. Optionnel: timezone IANA, format (ISO/READABLE/BOTH). GET_TOOL_HELP pour dÃ©tails.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "timezone": {
                        "type": "string",
                        "description": "Timezone IANA optionnelle (ex: 'Europe/Paris'). Si non fournie, utilise la timezone de la sociÃ©tÃ©."
                    },
                    "format": {
                        "type": "string",
                        "enum": ["ISO", "READABLE", "BOTH"],
                        "description": "Format de sortie souhaitÃ© (dÃ©faut: BOTH)"
                    }
                },
                "required": []
            }
        }
        
        # Handler GET_CURRENT_DATETIME
        def handle_get_current_datetime(timezone: str = None, format: str = "BOTH"):
            return self._get_current_datetime(timezone, format)
        
        # Outil TERMINATE_TASK
        terminate_tool = {
            "name": "TERMINATE_TASK",
            "description": "ðŸŽ¯ Terminer la tÃ¢che quand la mission est accomplie. Utilisez cet outil dÃ¨s que vous avez rÃ©solu la requÃªte de l'utilisateur et fourni une rÃ©ponse complÃ¨te.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "reason": {
                        "type": "string",
                        "description": "Raison de la terminaison (ex: 'Mission accomplie', 'Information fournie', 'TÃ¢che longue lancÃ©e')"
                    },
                    "conclusion": {
                        "type": "string",
                        "description": "Votre rÃ©ponse finale COMPLÃˆTE pour l'utilisateur, rÃ©sumant les actions effectuÃ©es et les rÃ©sultats."
                    }
                },
                "required": ["reason", "conclusion"]
            }
        }
        
        # â•â•â• OUTIL WAIT_ON_LPT â•â•â•
        # CrÃ©er l'outil WAIT_ON_LPT pour mettre en pause le workflow en attente d'un callback LPT
        from ..tools.wait_on_lpt import create_wait_on_lpt_tool
        
        wait_on_lpt_def, wait_on_lpt_mapping = create_wait_on_lpt_tool(
            brain=self,
            thread_key=thread_key,
            mode=mode
        )
        
        async def handle_wait_on_lpt(**kwargs):
            """Handler pour WAIT_ON_LPT."""
            return await wait_on_lpt_mapping["WAIT_ON_LPT"](**kwargs)
        
        # â•â•â• REGISTRE D'AIDE DYNAMIQUE (GET_TOOL_HELP) â•â•â•
        from ..tools.tool_help_registry import ToolHelpRegistry, DETAILED_HELP
        
        help_registry = ToolHelpRegistry()
        
        # Enregistrer la documentation dÃ©taillÃ©e de tous les outils
        help_registry.register_multiple(DETAILED_HELP)
        
        # CrÃ©er l'outil GET_TOOL_HELP dynamiquement
        get_tool_help_def, handle_get_tool_help = help_registry.create_get_tool_help()
        
        # Combiner tous les outils (avec les 3 outils jobs + 4 outils context + VIEW_DRIVE_DOCUMENT + CREATE_TASK + checklist + datetime + WAIT_ON_LPT + GET_TOOL_HELP)
        tool_set = [
            get_apbookeeper_jobs_def,
            get_router_jobs_def,
            get_bank_transactions_def,
            router_prompt_def,
            apbookeeper_context_def,
            company_context_def,
            update_context_def,
            view_drive_document_def,  # â­ Outil de vision Drive
            create_task_def,
            create_checklist_tool,
            update_step_tool,
            get_current_datetime_tool,  # â° Outil date/heure actuelle
            wait_on_lpt_def,  # â³ Outil WAIT_ON_LPT
            get_tool_help_def  # ðŸ“š Outil GET_TOOL_HELP dynamique
        ] + spt_tools_list + lpt_tools_list + [terminate_tool]

        tool_mapping = {
            "GET_APBOOKEEPER_JOBS": handle_get_apbookeeper_jobs,
            "GET_ROUTER_JOBS": handle_get_router_jobs,
            "GET_BANK_TRANSACTIONS": handle_get_bank_transactions,
            "ROUTER_PROMPT": handle_router_prompt,
            "APBOOKEEPER_CONTEXT": handle_apbookeeper_context,
            "COMPANY_CONTEXT": handle_company_context,
            "UPDATE_CONTEXT": handle_update_context,
            "VIEW_DRIVE_DOCUMENT": handle_view_drive_document,  # â­ Handler vision Drive
            "CREATE_TASK": handle_create_task,
            "CREATE_CHECKLIST": handle_create_checklist,
            "UPDATE_STEP": handle_update_step,
            "GET_CURRENT_DATETIME": handle_get_current_datetime,  # â° Handler date/heure
            "WAIT_ON_LPT": handle_wait_on_lpt,  # â³ Handler WAIT_ON_LPT
            "TERMINATE_TASK": self._handle_terminate_task,  # ðŸ Handler terminaison
            "GET_TOOL_HELP": handle_get_tool_help,  # ðŸ“š Handler aide dynamique
            **spt_tools_mapping,
            **lpt_tools_mapping
        }
        
        # â­ RETOURNER LES NOUVEAUX OUTILS (SPT + LPT simplifiÃ©s + GET_TOOL_HELP)
        logger.info(f"Outils crÃ©Ã©s: {len(tool_set)} outils (SPT: {len(spt_tools_list)}, LPT: {len(lpt_tools_list)}, HELP: {len(help_registry.get_available_tools())} outils documentÃ©s)")
        return tool_set, tool_mapping

    async def load_onboarding_data(self) -> Dict[str, Any]:
        """Charge les donnÃ©es d'onboarding spÃ©cifiques Ã  l'utilisateur."""

        if self.onboarding_data is not None:
            return self.onboarding_data

        try:
            from ...firebase_providers import FirebaseManagement

            firebase = FirebaseManagement()
            onboarding_path = f"clients/{self.firebase_user_id}/temp_data/onboarding"
            doc_ref = firebase.db.document(onboarding_path)
            doc = await asyncio.to_thread(doc_ref.get)

            if doc.exists:
                self.onboarding_data = doc.to_dict() or {}
                logger.info(
                    f"[BRAIN_ONBOARDING] DonnÃ©es onboarding chargÃ©es ({list(self.onboarding_data.keys())})"
                )
            else:
                logger.warning(
                    f"[BRAIN_ONBOARDING] Aucun document onboarding trouvÃ© pour path={onboarding_path}"
                )
                self.onboarding_data = {}

        except Exception as e:
            logger.error(f"[BRAIN_ONBOARDING] Erreur chargement donnÃ©es: {e}", exc_info=True)
            self.onboarding_data = {}

        return self.onboarding_data
    
    async def load_job_data(self, job_id: str, force_reload: bool = False) -> Dict[str, Any]:
        """
        Charge les donnÃ©es de job depuis notifications/{job_id}.
        
        Args:
            job_id: ID du job Ã  charger
            force_reload: Si True, force le rechargement depuis Firestore mÃªme si dÃ©jÃ  en cache
        """
        
        if not force_reload and self.job_data is not None and self.job_data.get("job_id") == job_id:
            return self.job_data
        
        try:
            from ...firebase_providers import FirebaseManagement
            
            firebase = FirebaseManagement()
            job_path = f"clients/{self.firebase_user_id}/notifications/{job_id}"
            doc_ref = firebase.db.document(job_path)
            doc = await asyncio.to_thread(doc_ref.get)
            
            if doc.exists:
                doc_data = doc.to_dict() or {}
                # Extraire les champs requis : instructions, job_id, file_id, status
                self.job_data = {
                    "instructions": doc_data.get("instructions", ""),
                    "job_id": doc_data.get("job_id", job_id),
                    "file_id": doc_data.get("file_id", ""),
                    "status": doc_data.get("status", ""),
                    # Conserver les autres champs au cas oÃ¹
                    **{k: v for k, v in doc_data.items() if k not in ["instructions", "job_id", "file_id", "status"]}
                }
                
                # â•â•â• EXTRACTION DES TRANSACTIONS POUR BANKER_CHAT â•â•â•
                # Extraire et formater les transactions depuis le champ 'transactions'
                transactions_raw = doc_data.get("transactions", {})
                formatted_transactions = []
                
                if transactions_raw:
                    # Cas 1: transactions est un dictionnaire avec des clÃ©s numÃ©riques (0, 1, 2, ...)
                    if isinstance(transactions_raw, dict):
                        # Trier les clÃ©s numÃ©riquement pour maintenir l'ordre
                        for key in sorted(transactions_raw.keys(), key=lambda x: int(x) if str(x).isdigit() else 999):
                            transaction = transactions_raw[key]
                            if isinstance(transaction, dict):
                                # Extraire uniquement les champs importants
                                formatted_transaction = {
                                    "amount": transaction.get("amount"),
                                    "currency_name": transaction.get("currency_name", ""),
                                    "date": transaction.get("date", ""),
                                    "payment_ref": transaction.get("payment_ref", ""),
                                    "status": transaction.get("status", ""),
                                    "transaction_id": transaction.get("transaction_id", "")
                                }
                                formatted_transactions.append(formatted_transaction)
                    # Cas 2: transactions est une liste
                    elif isinstance(transactions_raw, list):
                        for transaction in transactions_raw:
                            if isinstance(transaction, dict):
                                # Extraire uniquement les champs importants
                                formatted_transaction = {
                                    "amount": transaction.get("amount"),
                                    "currency_name": transaction.get("currency_name", ""),
                                    "date": transaction.get("date", ""),
                                    "payment_ref": transaction.get("payment_ref", ""),
                                    "status": transaction.get("status", ""),
                                    "transaction_id": transaction.get("transaction_id", "")
                                }
                                formatted_transactions.append(formatted_transaction)
                    
                    if formatted_transactions:
                        self.job_data["formatted_transactions"] = formatted_transactions
                        logger.info(
                            f"[BRAIN_JOB_DATA] {len(formatted_transactions)} transactions formatÃ©es "
                            f"pour job_id={job_id}"
                        )
                
                logger.info(
                    f"[BRAIN_JOB_DATA] DonnÃ©es job chargÃ©es pour job_id={job_id} "
                    f"(instructions={bool(self.job_data.get('instructions'))}, "
                    f"file_id={self.job_data.get('file_id')}, "
                    f"status={self.job_data.get('status')}, "
                    f"transactions={len(self.job_data.get('formatted_transactions', []))})"
                )
            else:
                # C'est normal si le document n'existe pas encore (job pas encore lancÃ©)
                # On initialise avec des valeurs par dÃ©faut
                self.job_data = {
                    "instructions": "",
                    "job_id": job_id,
                    "file_id": "",
                    "status": "pending"
                }
                logger.debug(
                    f"[BRAIN_JOB_DATA] Document job non trouvÃ© pour path={job_path} "
                    f"(job_id={job_id}) - Initialisation avec valeurs par dÃ©faut. "
                    f"C'est normal si le job n'a pas encore Ã©tÃ© lancÃ©."
                )
        
        except Exception as e:
            logger.error(f"[BRAIN_JOB_DATA] Erreur chargement donnÃ©es: {e}", exc_info=True)
            self.job_data = {
                "instructions": "",
                "job_id": job_id,
                "file_id": "",
                "status": ""
            }
        
        return self.job_data
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰THODES SPT (synchrones)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _spt_read_firebase(self, collection_path: str, document_id: str) -> Dict:
        """SPT: Lecture Firebase"""
        try:
            from ...firebase_client import get_firestore
            db = get_firestore()
            doc = db.collection(f"{self.collection_name}/{collection_path}").document(document_id).get()
            
            if doc.exists:
                return {
                    'type': 'success',
                    'data': doc.to_dict(),
                    'document_id': document_id
                }
            else:
                return {
                    'type': 'not_found',
                    'message': f"Document {document_id} non trouvÃ©"
                }
        except Exception as e:
            logger.error(f"Erreur lecture Firebase: {e}")
            return {'type': 'error', 'message': str(e)}
    
    def _spt_search_chromadb(self, query: str, n_results: int = 5) -> Dict:
        """SPT: Recherche ChromaDB"""
        try:
            from ...chroma_vector_service import get_chroma_vector_service
            chroma = get_chroma_vector_service()
            
            results = chroma.query_collection(
                user_id=self.firebase_user_id,
                collection_name=self.collection_name,
                query_texts=[query],
                n_results=n_results
            )
            
            return {
                'type': 'success',
                'results': results,
                'count': len(results.get('documents', [[]])[0]) if results else 0
            }
        except Exception as e:
            logger.error(f"Erreur recherche ChromaDB: {e}")
            return {'type': 'error', 'message': str(e)}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰THODES LPT (asynchrones via HTTP)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _lpt_file_manager(self, thread_key: str, action: str, params: Dict, task_title: str) -> Dict:
        """
        LPT: Appel Ã  l'Agent File Manager (HTTP)
        
        Cette mÃ©thode dÃ©clenche une tÃ¢che asynchrone et retourne immÃ©diatement.
        Le rÃ©sultat arrivera plus tard via callback.
        """
        try:
            from .task_tracker import TaskTracker
            tracker = TaskTracker(self.firebase_user_id, self.collection_name)
            
            # CrÃ©er une tÃ¢che LPT
            task_id = tracker.create_lpt_task(
                thread_key=thread_key,
                agent_type="file_manager",
                action=action,
                params=params,
                task_title=task_title
            )
            
            # Enregistrer la tÃ¢che active
            if thread_key not in self.active_lpt_tasks:
                self.active_lpt_tasks[thread_key] = []
            self.active_lpt_tasks[thread_key].append(task_id)
            
            logger.info(f"TÃ¢che LPT crÃ©Ã©e: {task_id} pour File Manager")
            
            return {
                'type': 'lpt_started',
                'task_id': task_id,
                'agent': 'file_manager',
                'estimated_duration': '2-3 minutes',
                'message': f"âœ… TÃ¢che '{task_title}' envoyÃ©e Ã  l'Agent File Manager. Traitement en cours..."
            }
            
        except Exception as e:
            logger.error(f"Erreur dÃ©marrage LPT File Manager: {e}")
            return {'type': 'error', 'message': str(e)}
    
    def _lpt_accounting(self, thread_key: str, action: str, params: Dict, task_title: str) -> Dict:
        """
        LPT: Appel Ã  l'Agent Comptable (HTTP)
        
        Cette mÃ©thode dÃ©clenche une tÃ¢che asynchrone et retourne immÃ©diatement.
        Le rÃ©sultat arrivera plus tard via callback.
        """
        try:
            from .task_tracker import TaskTracker
            tracker = TaskTracker(self.firebase_user_id, self.collection_name)
            
            # CrÃ©er une tÃ¢che LPT
            task_id = tracker.create_lpt_task(
                thread_key=thread_key,
                agent_type="accounting",
                action=action,
                params=params,
                task_title=task_title
            )
            
            # Enregistrer la tÃ¢che active
            if thread_key not in self.active_lpt_tasks:
                self.active_lpt_tasks[thread_key] = []
            self.active_lpt_tasks[thread_key].append(task_id)
            
            logger.info(f"TÃ¢che LPT crÃ©Ã©e: {task_id} pour Accounting")
            
            return {
                'type': 'lpt_started',
                'task_id': task_id,
                'agent': 'accounting',
                'estimated_duration': '5-10 minutes',
                'message': f"âœ… TÃ¢che '{task_title}' envoyÃ©e Ã  l'Agent Comptable. Traitement en cours..."
            }
            
        except Exception as e:
            logger.error(f"Erreur dÃ©marrage LPT Accounting: {e}")
            return {'type': 'error', 'message': str(e)}
    
    async def _handle_terminate_task(
        self, 
        reason: str, 
        conclusion: str, 
        **kwargs
    ) -> Dict:
        """
        Handler pour l'outil TERMINATE_TASK.
        
        Cette mÃ©thode est appelÃ©e automatiquement par le workflow pour gÃ©nÃ©rer
        un rÃ©sultat d'outil (tool_result) qui sera ajoutÃ© au chat_history.
        
        âš ï¸ VALIDATION : En mode execution (tÃ¢che planifiÃ©e), vÃ©rifie que toutes
        les Ã©tapes de la checklist sont "completed" avant d'autoriser la terminaison.
        
        Args:
            reason: Raison de la terminaison
            conclusion: Rapport final complet
            **kwargs: ParamÃ¨tres additionnels ignorÃ©s
            
        Returns:
            Dict avec le rÃ©sultat de la terminaison (succÃ¨s ou erreur avec dÃ©tails)
        """
        logger.info(f"[TERMINATE_TASK] ðŸ Terminaison demandÃ©e - raison: {reason}")
        
        # â­ VALIDATION : VÃ©rifier que toutes les Ã©tapes sont "completed" en mode execution
        from ..tools.terminate_task_validator import validate_terminate_task
        
        is_valid, validation_result = validate_terminate_task(
            brain=self,
            reason=reason,
            conclusion=conclusion
        )
        
        if not is_valid:
            # âŒ Validation Ã©chouÃ©e â†’ retourner l'erreur dÃ©taillÃ©e
            logger.warning(
                f"[TERMINATE_TASK] âŒ Terminaison refusÃ©e: "
                f"{len(validation_result.get('incomplete_steps', []))} Ã©tapes incomplÃ¨tes"
            )
            return validation_result
        
        # âœ… Validation OK â†’ terminaison autorisÃ©e
        logger.info("[TERMINATE_TASK] âœ… Validation OK, terminaison autorisÃ©e")
        return {
            "success": True,
            "reason": reason,
            "conclusion": conclusion,
            "status": "terminated",
            "message": "Task terminated successfully",
            "validation": validation_result
        }
    
    def _get_current_datetime(self, timezone: str = None, format: str = "BOTH") -> Dict:
        """
        Obtient la date et l'heure actuelles dans un fuseau horaire spÃ©cifique.
        
        Args:
            timezone: Timezone IANA optionnelle (ex: 'Europe/Paris').
                     Si None, utilise la timezone configurÃ©e pour la sociÃ©tÃ©.
            format: Format de sortie ("ISO", "READABLE", ou "BOTH")
            
        Returns:
            Dict contenant la date/heure dans le format demandÃ©
        """
        from datetime import datetime
        import pytz
        
        try:
            # Utiliser la timezone du mandat si non fournie
            if not timezone:
                timezone = self.user_context.get("timezone", "UTC") if self.user_context else "UTC"
            
            logger.info(f"[GET_CURRENT_DATETIME] Timezone: {timezone}, Format: {format}")
            
            # Obtenir l'heure actuelle dans la timezone
            tz = pytz.timezone(timezone)
            now = datetime.now(tz)
            
            result = {
                "success": True,
                "timezone": timezone
            }
            
            # Format ISO
            if format in ["ISO", "BOTH"]:
                result["iso_format"] = now.isoformat()
                result["date_iso"] = now.date().isoformat()
                result["time_iso"] = now.time().isoformat()
            
            # Format lisible
            if format in ["READABLE", "BOTH"]:
                # Noms des jours et mois en franÃ§ais
                days_fr = ["lundi", "mardi", "mercredi", "jeudi", "vendredi", "samedi", "dimanche"]
                months_fr = ["janvier", "fÃ©vrier", "mars", "avril", "mai", "juin", 
                            "juillet", "aoÃ»t", "septembre", "octobre", "novembre", "dÃ©cembre"]
                
                day_name = days_fr[now.weekday()]
                month_name = months_fr[now.month - 1]
                
                result["readable_date"] = f"{day_name} {now.day} {month_name} {now.year}"
                result["readable_time"] = now.strftime("%H:%M:%S")
                result["readable_full"] = f"{day_name} {now.day} {month_name} {now.year} Ã  {now.strftime('%H:%M:%S')}"
            
            # Informations additionnelles utiles
            result["day_of_week"] = now.weekday() + 1  # 1 = lundi, 7 = dimanche
            result["day_of_month"] = now.day
            result["month"] = now.month
            result["year"] = now.year
            result["hour"] = now.hour
            result["minute"] = now.minute
            
            logger.info(f"[GET_CURRENT_DATETIME] âœ… RÃ©sultat: {result.get('readable_full', result.get('iso_format'))}")
            
            return result
            
        except Exception as e:
            logger.error(f"[GET_CURRENT_DATETIME] âŒ Erreur: {e}", exc_info=True)
            return {
                "success": False,
                "error": f"Erreur lors de l'obtention de la date/heure: {str(e)}",
                "timezone": timezone or "UTC"
            }
    
    def has_active_lpt_tasks(self, thread_key: str) -> bool:
        """VÃ©rifie si des tÃ¢ches LPT sont en cours pour ce thread"""
        return thread_key in self.active_lpt_tasks and len(self.active_lpt_tasks[thread_key]) > 0
    
    def get_active_lpt_count(self, thread_key: str) -> int:
        """Retourne le nombre de tÃ¢ches LPT actives"""
        return len(self.active_lpt_tasks.get(thread_key, []))
    
    def reset_context_with_summary(self, summary: str) -> int:
        """
        RÃ©initialise le contexte avec un rÃ©sumÃ© intÃ©grÃ© au system prompt.
        
        Cette mÃ©thode :
        1. Ajoute le rÃ©sumÃ© au system prompt de base
        2. Vide l'historique du chat
        3. Calcule et retourne le nombre de tokens du nouveau contexte
        
        Args:
            summary: RÃ©sumÃ© de la conversation Ã  intÃ©grer
        
        Returns:
            Nombre de tokens du nouveau contexte (system prompt + rÃ©sumÃ©)
        """
        logger.info("[RESET] RÃ©initialisation du contexte avec rÃ©sumÃ©")
        
        # RÃ©cupÃ©rer l'instance provider
        provider_instance = self.pinnokio_agent.get_provider_instance(self.default_provider)
        
        # Sauvegarder le system prompt de base (si pas dÃ©jÃ  sauvegardÃ©)
        if not hasattr(self, '_base_system_prompt'):
            self._base_system_prompt = provider_instance.system_prompt if hasattr(provider_instance, 'system_prompt') else ""
        
        # CrÃ©er le nouveau system prompt avec rÃ©sumÃ© intÃ©grÃ©
        new_system_prompt = f"""{self._base_system_prompt}

                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                ðŸ“‹ CONTEXTE DE LA CONVERSATION PRÃ‰CÃ‰DENTE :

                {summary}

                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                Continue la conversation en tenant compte de ce contexte historique.
                """
        
        # Mettre Ã  jour le system prompt
        if hasattr(provider_instance, 'update_system_prompt'):
            provider_instance.update_system_prompt(new_system_prompt)
        elif hasattr(provider_instance, 'system_prompt'):
            provider_instance.system_prompt = new_system_prompt
        
        # â­ NOUVEAU: Vider l'historique du brain (isolÃ© par thread)
        self.clear_chat_history()
        
        # Calculer les tokens du nouveau contexte
        # â­ get_history_token_count() compte maintenant automatiquement :
        # - L'historique du chat (vide aprÃ¨s clear)
        # - Le system prompt complet (avec rÃ©sumÃ© intÃ©grÃ©)
        tokens_after_reset = self.get_history_token_count()
        
        logger.info(
            f"[RESET] Contexte rÃ©initialisÃ© - "
            f"Nouveau contexte: {tokens_after_reset:,} tokens "
            f"(system prompt avec rÃ©sumÃ© + historique vide)"
        )
        
        return tokens_after_reset
    
    def generate_conversation_summary(self, thread_key: str, total_tokens_used: int) -> str:
        """
        GÃ©nÃ¨re un rÃ©sumÃ© compressÃ© de la conversation actuelle
        pour rÃ©initialiser le contexte tout en gardant l'essentiel.
        
        Cette mÃ©thode est appelÃ©e quand le budget de tokens est atteint (80K)
        pour compresser l'historique et permettre de continuer la conversation.
        
        Args:
            thread_key: ClÃ© du thread de conversation
            total_tokens_used: Nombre total de tokens utilisÃ©s dans la session
        
        Returns:
            RÃ©sumÃ© compressÃ© de la conversation (max 500 tokens)
        """
        logger.info(f"[SUMMARY] GÃ©nÃ©ration rÃ©sumÃ© - thread={thread_key}, tokens={total_tokens_used}")
        
        summary_prompt = f"""RÃ©sume cette conversation en gardant UNIQUEMENT les informations critiques:

                **Instructions de RÃ©sumÃ©** :
                1. **Contexte initial**: Quelle Ã©tait la demande originale de l'utilisateur ?
                2. **Actions effectuÃ©es**: Quels outils ont Ã©tÃ© utilisÃ©s (SPT/LPT) et pourquoi ?
                3. **RÃ©sultats clÃ©s**: Qu'avons-nous dÃ©couvert ou accompli ?
                4. **Ã‰tat actuel**: OÃ¹ en sommes-nous maintenant ? Que reste-t-il Ã  faire ?
                5. **TÃ¢ches LPT en cours**: Y a-t-il des tÃ¢ches longues en cours d'exÃ©cution ?

                **Contraintes** :
                - Maximum 500 tokens
                - Format concis et structurÃ©
                - Garde uniquement l'essentiel pour continuer efficacement

                Tokens utilisÃ©s dans cette session: {total_tokens_used:,}
                """
        
        try:
            # Utiliser l'agent pour gÃ©nÃ©rer le rÃ©sumÃ© (sans outils)
            summary_response = self.pinnokio_agent.process_tool_use(
                content=summary_prompt,
                tools=[],  # Pas d'outils pour le rÃ©sumÃ©
                tool_mapping={},
                provider=self.default_provider,
                size=ModelSize.SMALL,  # ModÃ¨le rapide suffit pour un rÃ©sumÃ©
                max_tokens=600,
                raw_output=True
            )
            
            # Extraire le texte du rÃ©sumÃ©
            summary_text = self._extract_text_from_summary_response(summary_response)
            
            logger.info(f"[SUMMARY] RÃ©sumÃ© gÃ©nÃ©rÃ© - longueur={len(summary_text)} caractÃ¨res")
            
            return summary_text
            
        except Exception as e:
            logger.error(f"[SUMMARY] Erreur gÃ©nÃ©ration rÃ©sumÃ©: {e}", exc_info=True)
            
            # RÃ©sumÃ© de fallback en cas d'erreur
            return f"""RÃ©sumÃ© automatique de la session:
            - Tokens utilisÃ©s: {total_tokens_used:,}
            - Thread: {thread_key}
            - TÃ¢ches LPT actives: {self.get_active_lpt_count(thread_key)}
            - Budget tokens atteint, contexte rÃ©initialisÃ©.
            """
    
    def _extract_text_from_summary_response(self, response: Any) -> str:
        """
        Extrait le texte d'une rÃ©ponse de rÃ©sumÃ©.
        Helper method pour extract le texte peu importe le format de rÃ©ponse.
        """
        if not response:
            return "Aucun rÃ©sumÃ© gÃ©nÃ©rÃ©."
        
        # Si c'est une liste de rÃ©ponses
        if isinstance(response, list):
            for item in response:
                if isinstance(item, dict):
                    # Chercher text_output
                    if "text_output" in item:
                        text_block = item["text_output"]
                        if isinstance(text_block, dict) and "content" in text_block:
                            return str(text_block["content"])
                        elif isinstance(text_block, str):
                            return text_block
        
        # Si c'est directement un dict
        if isinstance(response, dict):
            if "text_output" in response:
                text_block = response["text_output"]
                if isinstance(text_block, dict) and "content" in text_block:
                    return str(text_block["content"])
                elif isinstance(text_block, str):
                    return text_block
        
        # Fallback: convertir en string
        return str(response)[:1000]  # Limiter Ã  1000 chars par sÃ©curitÃ©

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GESTION HISTORIQUE CHAT (ISOLÃ‰ PAR THREAD)
    # â­ Multi-Instance Ready: Synchronisation Redis
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def add_user_message(self, content):
        """
        Ajoute un message utilisateur Ã  l'historique du chat.
        
        â­ Multi-Instance: Synchronise avec Redis aprÃ¨s ajout.
        
        Args:
            content: Contenu du message utilisateur (str ou list pour tool_results)
        """
        if self.pinnokio_agent:
            self.pinnokio_agent.add_user_message(content, provider=self.default_provider)
            content_len = len(content) if isinstance(content, (str, list)) else 0
            logger.debug(f"[CHAT_HISTORY] Message utilisateur ajoutÃ© via agent (type={type(content).__name__}, len={content_len})")
            
            # â­ Sync Redis (multi-instance)
            self._sync_history_to_redis()
        else:
            logger.warning(f"[CHAT_HISTORY] Agent non initialisÃ©, message non ajoutÃ©")
    
    def add_assistant_message(self, content: Any):
        """
        Ajoute un message assistant Ã  l'historique du chat.
        
        â­ Multi-Instance: Synchronise avec Redis aprÃ¨s ajout.
        
        Args:
            content: Contenu du message assistant (str, list ou dict)
                     - str: texte simple
                     - list: blocs Anthropic (text, tool_use, etc.)
                     - dict: ancien format (sera prÃ©servÃ©)
        """
        if self.pinnokio_agent:
            self.pinnokio_agent.add_ai_message(content, provider=self.default_provider)
            content_type = type(content).__name__
            content_len = len(content) if isinstance(content, (str, list)) else 1
            logger.debug(f"[CHAT_HISTORY] Message assistant ajoutÃ© via agent (type={content_type}, len={content_len})")
            
            # â­ Sync Redis (multi-instance)
            self._sync_history_to_redis()
        else:
            logger.warning(f"[CHAT_HISTORY] Agent non initialisÃ©, message non ajoutÃ©")
    
    def get_chat_history(self) -> List[Dict[str, Any]]:
        """
        Retourne l'historique complet du chat.
        
        â­ Multi-Instance: Utilise le cache local (performance).
        Pour cross-instance, utiliser get_chat_history_from_redis().
        
        Returns:
            Liste des messages du chat
        """
        if self.pinnokio_agent:
            return self.pinnokio_agent.chat_history.get(self.default_provider.value, []).copy()
        return []
    
    def get_chat_history_from_redis(self) -> List[Dict[str, Any]]:
        """
        RÃ©cupÃ¨re l'historique depuis Redis (pour reprise cross-instance).
        
        â­ Multi-Instance: Lecture directe depuis Redis.
        
        Returns:
            Liste des messages depuis Redis, ou liste vide
        """
        if not self.active_thread_key:
            logger.warning("[CHAT_HISTORY] Pas de thread_key actif pour lecture Redis")
            return []
        
        return self._chat_history_manager.get_messages(
            self.firebase_user_id,
            self.collection_name,
            self.active_thread_key
        )
    
    def restore_history_from_redis(self) -> bool:
        """
        Restaure l'historique depuis Redis dans l'agent local.
        
        â­ Multi-Instance: AppelÃ© au dÃ©marrage du brain pour reprise.
        
        Returns:
            True si restauration rÃ©ussie
        """
        if not self.active_thread_key:
            logger.debug("[CHAT_HISTORY] Pas de thread_key actif pour restauration")
            return False
        
        try:
            history = self._chat_history_manager.load_chat_history(
                self.firebase_user_id,
                self.collection_name,
                self.active_thread_key
            )
            
            if history and self.pinnokio_agent:
                messages = history.get("messages", [])
                system_prompt = history.get("system_prompt", "")
                
                # Restaurer le system prompt
                if system_prompt:
                    self.pinnokio_agent.update_system_prompt(system_prompt)
                
                # Restaurer les messages
                # Note: On remplace directement le chat_history
                self.pinnokio_agent.chat_history[self.default_provider.value] = messages
                
                logger.info(
                    f"[CHAT_HISTORY] âœ… Historique restaurÃ© depuis Redis: "
                    f"{len(messages)} messages, thread={self.active_thread_key}"
                )
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"[CHAT_HISTORY] âš ï¸ Erreur restauration Redis: {e}")
            return False
    
    def clear_chat_history(self):
        """
        Vide l'historique du chat pour ce thread.
        
        â­ Multi-Instance: Synchronise avec Redis aprÃ¨s vidage.
        """
        if self.pinnokio_agent:
            current_history = self.get_chat_history()
            message_count = len(current_history)
            self.pinnokio_agent.clear_chat_history()
            
            # â­ Sync Redis (vider aussi dans Redis)
            if self._redis_sync_enabled and self.active_thread_key:
                self._chat_history_manager.clear_messages(
                    self.firebase_user_id,
                    self.collection_name,
                    self.active_thread_key,
                    keep_system_prompt=True
                )
            
            logger.info(f"[CHAT_HISTORY] Historique vidÃ© via agent ({message_count} messages supprimÃ©s)")
        else:
            logger.warning(f"[CHAT_HISTORY] Agent non initialisÃ©, rien Ã  vider")
    
    def _sync_history_to_redis(self):
        """
        Synchronise l'historique local vers Redis (non-bloquant).
        
        â­ Multi-Instance: AppelÃ© aprÃ¨s chaque modification pour durabilitÃ©.
        """
        if not self._redis_sync_enabled:
            return
        
        if not self.active_thread_key:
            logger.debug("[CHAT_HISTORY] Pas de thread_key actif pour sync Redis")
            return
        
        try:
            messages = self.get_chat_history()
            system_prompt = ""
            
            # RÃ©cupÃ©rer le system prompt si disponible
            if self.pinnokio_agent:
                provider_instance = self.pinnokio_agent.get_provider_instance(self.default_provider)
                if provider_instance and hasattr(provider_instance, 'system_prompt'):
                    system_prompt = provider_instance.system_prompt or ""
            
            self._chat_history_manager.save_chat_history(
                user_id=self.firebase_user_id,
                company_id=self.collection_name,
                thread_key=self.active_thread_key,
                messages=messages,
                system_prompt=system_prompt,
                metadata={
                    "chat_mode": self.current_chat_mode,
                    "provider": self.default_provider.value
                },
                status="active"
            )
            
            logger.debug(
                f"[CHAT_HISTORY] ðŸ’¾ Sync Redis: {len(messages)} messages, "
                f"thread={self.active_thread_key}"
            )
            
        except Exception as e:
            logger.warning(f"[CHAT_HISTORY] âš ï¸ Erreur sync Redis: {e}")
    
    async def load_user_context(self, mode: str = "UI") -> Dict[str, Any]:
        """
        Charge le contexte utilisateur (mÃ©tadonnÃ©es sociÃ©tÃ©) dans le brain SESSION.
        
        â­ NOUVEAU : Support dual-mode (UI/BACKEND)
        
        Mode UI (utilisateur connectÃ©) :
        1. Tenter cache Redis (TTL 1h)
        2. Si CACHE MISS â†’ Fallback Firebase
        3. Mettre en cache pour prochains appels
        
        Mode BACKEND (utilisateur dÃ©connectÃ©) :
        1. AccÃ¨s direct Firebase (source de vÃ©ritÃ©)
        2. Pas de cache
        
        Ce contexte contient toutes les mÃ©tadonnÃ©es importantes :
        - mandate_path, client_uuid, company_name
        - dms_system, drive_space_parent_id
        - communication_mode, log_communication_mode
        - bank_erp (odoo_url, odoo_db, etc.)
        
        â­ IMPORTANT : AppelÃ© lors de initialize_agent() (pas besoin de thread_key)
        
        Args:
            mode: "UI" (cache prioritaire) ou "BACKEND" (Firebase direct)
        
        Returns:
            Dict contenant le contexte utilisateur
        """
        try:
            logger.info(f"[BRAIN_CONTEXT] Chargement contexte utilisateur - Mode: {mode}")
            
            import json
            from ...redis_client import get_redis
            
            context = None
            
            # â•â•â• MODE UI : Cache Redis â†’ Fallback Firebase â•â•â•
            if mode == "UI":
                try:
                    redis_client = get_redis()
                    cache_key = f"context:{self.firebase_user_id}:{self.collection_name}"
                    
                    logger.info(f"[BRAIN_CONTEXT] ðŸ” DEBUG - Tentative lecture cache: {cache_key}")
                    cached_data = redis_client.get(cache_key)
                    logger.info(f"[BRAIN_CONTEXT] ðŸ” DEBUG - cached_data type: {type(cached_data)}, value: {cached_data[:100] if cached_data else None}")
                    
                    if cached_data:
                        context = json.loads(cached_data)
                        logger.info(f"[BRAIN_CONTEXT] âœ… CACHE HIT: {cache_key}")
                    else:
                        logger.info(f"[BRAIN_CONTEXT] âŒ CACHE MISS: {cache_key} - Fallback Firebase")
                
                except Exception as e:
                    logger.warning(f"[BRAIN_CONTEXT] Erreur accÃ¨s cache: {e} - Fallback Firebase")
            
            # â•â•â• Si pas de cache OU mode BACKEND : Firebase direct â•â•â•
            if context is None:
                logger.info(f"[BRAIN_CONTEXT] RÃ©cupÃ©ration depuis Firebase...")
                
                from ..tools.lpt_client import LPTClient
                
                lpt_client = LPTClient()
                
                # RÃ©cupÃ©rer depuis Firebase (sans cache)
                context = await lpt_client._reconstruct_full_company_profile(
                    self.firebase_user_id,
                    self.collection_name
                )
                
                # Si mode UI, mettre en cache
                if mode == "UI" and context:
                    try:
                        redis_client = get_redis()
                        cache_key = f"context:{self.firebase_user_id}:{self.collection_name}"
                        
                        # Ajouter timestamp
                        context["cached_at"] = datetime.now().isoformat()
                        
                        redis_client.setex(
                            cache_key,
                            3600,  # TTL 1 heure
                            json.dumps(context)
                        )
                        
                        logger.info(f"[BRAIN_CONTEXT] âœ… Contexte mis en cache: {cache_key}")
                    
                    except Exception as e:
                        logger.warning(f"[BRAIN_CONTEXT] Erreur mise en cache: {e}")
            
            # â•â•â• Stocker dans le brain â•â•â•
            if context:
                self.user_context = context
                
                logger.info(
                    f"[BRAIN_CONTEXT] âœ… Contexte chargÃ©: mandate_path={context.get('mandate_path')}, "
                    f"dms_system={context.get('dms_system')}, "
                    f"client_uuid={context.get('client_uuid')}, "
                    f"mode={mode}"
                )
                
                # ðŸ” DEBUG : Afficher les champs critiques pour Router et Bank
                logger.info(
                    f"[BRAIN_CONTEXT] ðŸ” DEBUG - Champs Drive: "
                    f"drive_space_parent_id={context.get('drive_space_parent_id')}, "
                    f"input_drive_doc_id={context.get('input_drive_doc_id')}"
                )
                logger.info(
                    f"[BRAIN_CONTEXT] ðŸ” DEBUG - Champs ERP Bank: "
                    f"mandate_bank_erp={context.get('mandate_bank_erp')}, "
                    f"erp_odoo_url={context.get('erp_odoo_url')}, "
                    f"erp_erp_type={context.get('erp_erp_type')}"
                )
                logger.info(
                    f"[BRAIN_CONTEXT] ðŸ” DEBUG - Toutes les clÃ©s: {list(context.keys())}"
                )
                
                return context
            
            else:
                raise ValueError("Contexte vide depuis Firebase")
        
        except Exception as e:
            logger.error(f"[BRAIN_CONTEXT] âŒ Erreur chargement contexte: {e}", exc_info=True)
            
            # Retourner un contexte minimal pour ne pas bloquer
            self.user_context = {
                "mandate_path": self.collection_name,
                "dms_system": "google_drive",
                "communication_mode": "webhook",
                "log_communication_mode": "firebase",
                "user_language": "fr",
                "mode": mode
            }
            
            return self.user_context
    
    def get_user_context(self) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re le contexte utilisateur stockÃ© dans le brain.
        
        Returns:
            Dict contenant le contexte utilisateur, ou dict vide si non chargÃ©
        """
        if self.user_context is None:
            logger.warning(
                f"[BRAIN_CONTEXT] âš ï¸ Contexte non chargÃ©. "
                f"Appelez load_user_context() aprÃ¨s crÃ©ation du brain."
            )
            return {}
        
        return self.user_context
    
    def set_active_thread(self, thread_key: str):
        """
        DÃ©finit le thread actif pour les workflows d'approbation.
        
        Cette mÃ©thode doit Ãªtre appelÃ©e au dÃ©but du traitement d'un message
        pour que les outils sachent sur quel thread envoyer les cartes d'approbation.
        
        Args:
            thread_key: ClÃ© du thread de conversation actif
        """
        self.active_thread_key = thread_key
        logger.info(f"[BRAIN] Thread actif dÃ©fini: {thread_key}")
    
    def get_history_token_count(self) -> int:
        """
        Estime le nombre de tokens dans le contexte actuel complet.
        
        â­ PROXY vers BaseAIAgent.get_total_context_tokens()
        
        Calcule automatiquement :
        - Chat history (messages utilisateur + assistant + tool_results)
        - System prompt (avec rÃ©sumÃ©s Ã©ventuels)
        
        Returns:
            Nombre approximatif de tokens dans le contexte complet
        """
        if not self.pinnokio_agent:
            return 0
        
        # DÃ©lÃ©guer le calcul Ã  BaseAIAgent (Ã©vite duplication de code)
        return self.pinnokio_agent.get_total_context_tokens(self.default_provider)

