# Architecture de communication Firebase Microservice â†” Reflex

## Vue d'ensemble de l'architecture

Cette documentation dÃ©crit l'architecture complÃ¨te de communication entre l'application Reflex et le microservice Firebase, incluant les patterns de communication, les protocoles utilisÃ©s et les mÃ©canismes d'extensibilitÃ© pour de nouveaux services.

### Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    RPC HTTP     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Firebase API    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
â”‚  Application    â”‚                 â”‚  Microservice   â”‚                    â”‚   Firebase      â”‚
â”‚     Reflex      â”‚                 â”‚   Firebase      â”‚                    â”‚  (Firestore +   â”‚
â”‚                 â”‚                 â”‚                 â”‚                    â”‚   Realtime DB)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                                   â”‚
         â”‚ WebSocket/Redis                   â”‚ Redis Pub/Sub
         â”‚ (Ã©vÃ©nements temps rÃ©el)           â–¼
         â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     Redis       â”‚
                                    â”‚  (Event Bus)    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Modes de fonctionnement

Le systÃ¨me supporte trois modes de dÃ©ploiement pour permettre une transition progressive et un dÃ©veloppement sÃ©curisÃ©.

### 1) Mode ACTUEL (ne rien casser)
- Source: mÃ©canisme en place aujourdâ€™hui (queue process interne / listeners intÃ©grÃ©s au State Reflex).
- Action: ne changez rien. Ce mode reste par dÃ©faut tant que les tests local et prod ne sont pas validÃ©s.

### 2) Mode LOCAL (tests dÃ©veloppeur)
- Source: Redis local (Docker) publiÃ© par `listeners-service` en local.
- PrÃ©-requis cÃ´tÃ© dev:
  - DÃ©marrer Redis local: `docker run -d --name redis-local -p 6379:6379 redis:alpine`
  - DÃ©marrer le microservice listeners: `USE_LOCAL_REDIS=true uvicorn app.main:app --host 0.0.0.0 --port 8080`
  - VÃ©rifier `GET http://localhost:8080/debug` â†’ `redis: ok`
- ParamÃ©trage cÃ´tÃ© backend Reflex (variables dâ€™environnement):
  - `LISTENERS_REDIS_HOST=127.0.0.1`
  - `LISTENERS_REDIS_PORT=6379`
  - `LISTENERS_REDIS_PASSWORD=` (vide)
  - `LISTENERS_REDIS_TLS=false`
  - `LISTENERS_REDIS_DB=0`
  - `LISTENERS_CHANNEL_PREFIX=user:` (assurez-vous quâ€™il corresponde Ã  celui du microservice)
- RÃ©sultat attendu: le backend Reflex sâ€™abonne Ã  `user:{uid}` sur le Redis local et reÃ§oit les messages `notif.*`.

### 3) Mode PROD (ECS Fargate + ALB + ElastiCache Valkey)
- Source: Valkey Serverless (compatible Redis) dans AWS.
- ParamÃ©trage cÃ´tÃ© backend Reflex (env prod):
  - `LISTENERS_REDIS_HOST=pinnokio-cache-7uum2j.serverless.use1.cache.amazonaws.com`
  - `LISTENERS_REDIS_PORT=6379`
  - `LISTENERS_REDIS_PASSWORD=` (vide, sÃ©curitÃ© rÃ©seau via SG/VPC)
  - `LISTENERS_REDIS_TLS=true`
  - `LISTENERS_REDIS_DB=0`
  - `LISTENERS_CHANNEL_PREFIX=user:`
- RÃ©seau: Le backend Reflex doit Ãªtre dans le mÃªme VPC/subnets et Security Group autorisant le port 6379 vers Valkey.
- VÃ©rification: une fois dÃ©ployÃ©, `GET https://<ALB>/healthz` du microservice doit Ãªtre `ok`, et le backend Reflex doit recevoir les Ã©vÃ©nements sur `user:{uid}`.

### 4) Commutation progressive des modes
- Ã‰tapes recommandÃ©es:
  1) Conserver le mode ACTUEL en production (aucun changement).
  2) Tester le mode LOCAL cÃ´tÃ© dev (Redis Docker + microservice local). Valider que lâ€™UI reÃ§oit `notif.*` via le backend Reflex.
  3) DÃ©ployer le microservice en PROD (ECS/ALB) et configurer le backend Reflex en mode PROD (Valkey). Tester sur un sous-ensemble dâ€™utilisateurs.
  4) AprÃ¨s validation, retirer le mode ACTUEL et basculer dÃ©finitivement sur Redis/Valkey.

### 5) RÃ©fÃ©rences et points de contrÃ´le
- PrÃ©fixe de canal: `LISTENERS_CHANNEL_PREFIX` doit Ãªtre identique cÃ´tÃ© microservice et backend Reflex.
- Aucun replay: Redis/Valkey diffuse seulement. Sur reconnexion, relire Firestore si besoin.
- SantÃ© du microservice: `GET /healthz` et `GET /debug` (ALB en prod ou localhost en local).
- SÃ©curitÃ© (prod): accÃ¨s Valkey par SG/VPC, TLS activÃ©, pas de mot de passe.

---

## Protocoles de communication dÃ©taillÃ©s

### 1. Communication RPC HTTP (Reflex â†’ Microservice)

#### Architecture RPC
- **Endpoint**: `POST /rpc`
- **Authentification**: Bearer token via `Authorization: Bearer <LISTENERS_SERVICE_TOKEN>`
- **Idempotence**: ClÃ© SHA256 basÃ©e sur mÃ©thode, arguments et paramÃ¨tres
- **Timeout**: Configurable par requÃªte (dÃ©faut: 120s)

#### Format des requÃªtes RPC
```json
{
  "method": "FIREBASE_MANAGEMENT.add_or_update_job_by_job_id",
  "args": ["clients/user123/notifications", {"job_id": "abc123", ...}],
  "kwargs": {},
  "user_id": "user123",
  "session_id": "session456",
  "idempotency_key": "sha256_hash",
  "timeout_ms": 30000,
  "trace_id": "uuid4",
  "reply_to": "redis:reply:session456"
}
```

#### Format des rÃ©ponses RPC
```json
// SuccÃ¨s
{
  "ok": true,
  "data": "result_or_object"
}

// Erreur
{
  "ok": false,
  "error": {
    "code": "INVALID_ARGS|INTERNAL|METHOD_NOT_FOUND",
    "message": "Description de l'erreur",
    "retry_after_ms": 5000  // optionnel
  }
}
```

#### Mapping des mÃ©thodes
Le microservice route automatiquement les appels RPC vers les bonnes implÃ©mentations :

- `FIREBASE_MANAGEMENT.*` â†’ Classe `FirebaseManagement` (Firestore + Stripe)
- `FIREBASE_REALTIME.*` â†’ Classe `FirebaseRealtimeChat` (Realtime Database)
- `CHROMA_VECTOR.*` â†’ Classe `ChromaVectorService` (Base de donnÃ©es vectorielle ChromaDB)
- `REGISTRY.*` â†’ SystÃ¨me de gestion des sessions utilisateur

#### Proxy cÃ´tÃ© Reflex
L'application Reflex utilise un systÃ¨me de proxy transparent :

```python
# En mode LOCAL/PROD, tous les appels Firebase sont automatiquement routÃ©s via RPC
firebase_service = FireBaseManagement()  # Proxy RPC automatique
firebase_service.add_or_update_job_by_job_id(path, data)  # â†’ RPC call

# ChromaDB utilise le mÃªme pattern de proxy
chroma_proxy = get_chroma_vector_proxy()  # Proxy RPC automatique
chroma_instance = chroma_proxy.create_chroma_instance(collection_name)  # â†’ Instance ou proxy selon le mode
```

### 2. Communication temps rÃ©el (Microservice â†’ Reflex)

#### Architecture Event Bus
Le microservice publie les Ã©vÃ©nements sur Redis, l'application Reflex les consomme via WebSocket et/ou Redis.

#### Canaux Redis
- **Notifications**: `user:{user_id}` (ex: `user:123abc`)
- **Messages directs**: `msg:{user_id}`
- **Chat**: `chat:{user_id}:{space_code}:{thread_key}`

#### Format des Ã©vÃ©nements
```json
{
  "type": "notif.job_updated|notif.sync|msg.new|chat.message",
  "uid": "user_id",
  "timestamp": "2025-09-20T11:44:00.000Z",
  "payload": {
    "job_id": "abc123",
    "status": "completed",
    "collection_path": "clients/user123/notifications",
    // ... donnÃ©es spÃ©cifiques Ã  l'Ã©vÃ©nement
  }
}
```

#### Types d'Ã©vÃ©nements
- `notif.job_updated`: Notification de job mise Ã  jour
- `notif.sync`: Synchronisation complÃ¨te des notifications
- `msg.new`: Nouveau message direct
- `msg.sync`: Synchronisation des messages
- `chat.message`: Message de chat
- `chat.sync`: Synchronisation du chat
- `workflow.invoice_update`: Mise Ã  jour des donnÃ©es de facture
- `workflow.step_update`: Mise Ã  jour des Ã©tapes de workflow APBookeeper

#### Ã‰vÃ©nements Workflow dÃ©taillÃ©s

**Ã‰vÃ©nement `workflow.invoice_update`** :
```json
{
  "type": "workflow.invoice_update",
  "uid": "user123",
  "job_id": "job456",
  "timestamp": "2025-09-20T12:30:00.000Z",
  "payload": {
    "invoice_changes": {
      "invoiceReference": "INV-2025-001",
      "totalAmountDueVATExcluded": 1250.00,
      "currency": "EUR"
    }
  }
}
```

**Ã‰vÃ©nement `workflow.step_update`** :
```json
{
  "type": "workflow.step_update",
  "uid": "user123",
  "job_id": "job456",
  "timestamp": "2025-09-20T12:30:00.000Z",
  "payload": {
    "step_changes": {
      "APBookeeper_step_status": {
        "step_extract_data": 3,
        "step_validate_data": 1
      }
    }
  }
}
```

### 3. Surveillance des workflows (WorkflowListener)

#### Architecture du WorkflowListener
Le microservice surveille automatiquement les documents dans `clients/{user_id}/task_manager/` pour dÃ©tecter :
- **Changements de donnÃ©es de facture** : Modifications dans `document.initial_data`
- **Progression des Ã©tapes** : Ã‰volution des compteurs dans `APBookeeper_step_status`

#### Champs de facture surveillÃ©s
- Informations principales : `invoiceReference`, `recipient`, `invoiceDescription`
- Montants : `totalAmountDueVATExcluded`, `totalAmountDueVATIncluded`, `VATAmount`
- DÃ©tails : `recipientAddress`, `dueDate`, `sender`, `invoiceDate`, `currency`
- MÃ©tadonnÃ©es : `VATPercentages`, `sender_country`, `account_number`, `account_name`

#### Logique de dÃ©tection des Ã©tapes
- Chaque Ã©tape APBookeeper a un compteur numÃ©rique qui s'incrÃ©mente
- Le microservice compare les valeurs actuelles avec le cache prÃ©cÃ©dent
- Seules les Ã©tapes modifiÃ©es sont publiÃ©es dans l'Ã©vÃ©nement

#### Configuration
```bash
# Variable d'environnement pour activer/dÃ©sactiver
WORKFLOW_LISTENER_ENABLED=true
```

### 4. Gestion des sessions et registre utilisateur

#### Enregistrement de session
```python
# Au login Reflex
registry_register_user(user_id, session_id, backend_route)
```

#### DÃ©senregistrement
```python
# Au logout Reflex
registry_unregister_session(session_id)
```

#### Heartbeat et prÃ©sence
- Heartbeat automatique via WebSocket
- Mise Ã  jour du statut utilisateur (`online`/`offline`)
- TTL de 90 secondes pour la prÃ©sence

---

## ExtensibilitÃ© et intÃ©gration de nouveaux services

### Pattern d'extension pour services externes

#### 1. Services synchrones (bases de donnÃ©es vectorielles, API externes)

Pour intÃ©grer un nouveau service synchrone (ex: Pinecone, Weaviate, API REST) :

```python
# 1. CrÃ©er une nouvelle classe de service
class VectorDatabaseService:
    def search_vectors(self, query_vector, top_k=10):
        # ImplÃ©mentation de recherche vectorielle
        pass

    def upsert_vectors(self, vectors):
        # ImplÃ©mentation d'insertion
        pass

# 2. Enregistrer dans le dispatcher RPC (main.py)
def _resolve_method(method: str) -> Tuple[Callable[..., Any], str]:
    if method.startswith("VECTOR_DB."):
        name = method.split(".", 1)[1]
        target = getattr(get_vector_db_service(), name, None)
        if callable(target):
            return target, "VECTOR_DB"
    # ... autres services
```

#### 2. Services asynchrones (Ã©vÃ©nements temps rÃ©el)

Pour un service gÃ©nÃ©rant des Ã©vÃ©nements :

```python
# 1. Publier des Ã©vÃ©nements via le systÃ¨me existant
def _publish_vector_event(self, user_id, event_data):
    payload = {
        "type": "vector.search_complete",
        "uid": user_id,
        "timestamp": datetime.now().isoformat(),
        "payload": event_data
    }

    # Utiliser le listeners_manager existant
    from app.main import listeners_manager
    if listeners_manager:
        listeners_manager.publish(user_id, payload)

# 2. Ajouter de nouveaux canaux si nÃ©cessaire
# Format: service:{user_id}:{specific_channel}
```

#### 3. Services de stockage alternatifs

Pour intÃ©grer une base de donnÃ©es alternative :

```python
# 1. CrÃ©er l'interface de service
class PostgreSQLService:
    def execute_query(self, query, params=None):
        # ImplÃ©mentation PostgreSQL
        pass

# 2. Ajouter au mapping RPC
# POSTGRESQL.execute_query â†’ PostgreSQLService.execute_query

# 3. Configurer cÃ´tÃ© Reflex
# Le proxy RPC fonctionnera automatiquement
```

### Configuration pour nouveaux services

#### Variables d'environnement
```bash
# Service vectoriel
VECTOR_DB_URL=https://api.pinecone.io
VECTOR_DB_API_KEY=xxx

# Service PostgreSQL
POSTGRES_URL=postgresql://user:pass@host:5432/db

# Redis pour nouveaux canaux
VECTOR_CHANNEL_PREFIX=vector:
POSTGRES_CHANNEL_PREFIX=postgres:
```

#### Authentification et sÃ©curitÃ©
- RÃ©utiliser le systÃ¨me Bearer token existant
- Ajouter des clÃ©s d'API spÃ©cifiques dans les variables d'environnement
- Utiliser le mÃªme systÃ¨me d'idempotence pour Ã©viter les doublons

### Patterns de communication recommandÃ©s

#### 1. Pour opÃ©rations CRUD simples
```python
# Utiliser le pattern RPC synchrone
result = rpc_call("NEW_SERVICE.create_record", args=[data])
```

#### 2. Pour opÃ©rations longues/asynchrones
```python
# 1. DÃ©clencher via RPC
job_id = rpc_call("NEW_SERVICE.start_long_operation", args=[params])

# 2. Publier progression via Ã©vÃ©nements
def publish_progress(user_id, job_id, progress):
    payload = {
        "type": "service.progress_update",
        "uid": user_id,
        "payload": {"job_id": job_id, "progress": progress}
    }
    listeners_manager.publish(user_id, payload)
```

#### 3. Pour intÃ©grations temps rÃ©el
```python
# Stream d'Ã©vÃ©nements continu
def stream_realtime_data(user_id):
    for event in realtime_source:
        payload = {
            "type": "stream.data_update",
            "uid": user_id,
            "payload": event
        }
        listeners_manager.publish(user_id, payload)
```

---

## Monitoring et observabilitÃ©

### Logs structurÃ©s
- `rpc_call`: Appels RPC entrants
- `rpc_ok/rpc_error`: RÃ©sultats des appels
- `publish`: Ã‰vÃ©nements publiÃ©s sur Redis
- `ws_connect/ws_disconnect`: Connexions WebSocket

### MÃ©triques recommandÃ©es
- Latence des appels RPC par mÃ©thode
- Taux d'erreur par service
- Nombre d'Ã©vÃ©nements publiÃ©s par canal
- Connexions WebSocket actives

### Endpoints de santÃ©
- `GET /healthz`: SantÃ© globale du microservice + compteurs workflow listeners
- `GET /debug`: Ã‰tat dÃ©taillÃ© (Redis, Firebase, workflow listeners, services externes)

### Monitoring spÃ©cifique aux workflow listeners

#### Endpoint /healthz
```json
{
  "status": "ok",
  "version": "1.0.0",
  "listeners_count": 5,
  "workflow_listeners_count": 3,
  "redis": "ok",
  "uptime_s": 3600
}
```

#### Endpoint /debug
```json
{
  "redis": {"status": "ok"},
  "firestore": {"status": "ok"},
  "workflow_listeners": {
    "status": "ok",
    "enabled": true,
    "active_count": 3,
    "users": ["user123", "user456", "user789"],
    "cache_entries": 12
  }
}
```

#### Logs de workflow
- `workflow_listener_start`: DÃ©marrage du listener pour un utilisateur
- `workflow_listener_attached`: Listener attachÃ© avec succÃ¨s
- `workflow_invoice_changes`: Changements dÃ©tectÃ©s dans les donnÃ©es de facture
- `workflow_step_changes`: Changements dÃ©tectÃ©s dans les Ã©tapes APBookeeper
- `workflow_listener_error`: Erreurs du workflow listener

Cette architecture permet une extension facile vers de nouveaux services tout en maintenant la cohÃ©rence des patterns de communication et la fiabilitÃ© du systÃ¨me existant.

---

## IntÃ©gration ChromaDB (Base de DonnÃ©es Vectorielle)

### Vue d'ensemble de l'intÃ©gration ChromaDB

L'intÃ©gration ChromaDB suit le mÃªme pattern que les autres services du microservice, avec le support des trois modes de fonctionnement (ACTUEL, LOCAL, PROD) pour assurer une transition progressive.

### Architecture ChromaDB

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    RPC HTTP     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    ChromaDB API    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
â”‚  Application    â”‚                 â”‚  Microservice   â”‚                    â”‚    ChromaDB     â”‚
â”‚     Reflex      â”‚                 â”‚ChromaVectorSvc  â”‚                    â”‚    Server       â”‚
â”‚                 â”‚                 â”‚                 â”‚                    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                                   â”‚
         â”‚ WebSocket/Redis                   â”‚ Redis Registry
         â”‚ (Ã©vÃ©nements heartbeat)            â–¼
         â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     Redis       â”‚
                                    â”‚ (Collection     â”‚
                                    â”‚  Registry)      â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Modes de fonctionnement ChromaDB

#### 1) Mode ACTUEL (ne rien casser)
- Source: instances directes CHROMA_KLK et ChromaAnalyzer comme aujourd'hui
- Action: aucun changement dans le comportement existant
- Les instances sont crÃ©Ã©es directement dans l'application Reflex

#### 2) Mode LOCAL (tests dÃ©veloppeur)
- Source: ChromaVectorService dans le microservice local
- PrÃ©-requis cÃ´tÃ© dev:
  - Microservice local en cours d'exÃ©cution avec ChromaDB configurÃ©
  - Variables d'environnement ChromaDB configurÃ©es
- ParamÃ©trage cÃ´tÃ© backend Reflex:
  - `LISTENERS_MODE=LOCAL`
  - Autres variables RPC standard
- RÃ©sultat: toutes les opÃ©rations ChromaDB passent par le microservice via RPC

#### 3) Mode PROD (ECS Fargate + ChromaDB distant)
- Source: ChromaVectorService dans le microservice de production
- ParamÃ©trage cÃ´tÃ© backend Reflex:
  - `LISTENERS_MODE=PROD`
  - Variables RPC de production
- ChromaDB: serveur distant configurÃ© via les variables d'environnement du microservice

### Configuration ChromaDB

#### Variables d'environnement du microservice
```bash
# Configuration ChromaDB
CHROMA_HOST=localhost                    # Ou l'adresse du serveur ChromaDB
CHROMA_PORT=8000                        # Port du serveur ChromaDB
CHROMA_SSL=False                        # True pour HTTPS
CHROMA_HEADERS=                         # Headers HTTP personnalisÃ©s
CHROMA_SETTINGS=                        # RÃ©glages ChromaDB personnalisÃ©s
CHROMA_TENANT=default                   # Tenant ChromaDB
CHROMA_DATABASE=default                 # Base de donnÃ©es ChromaDB

# ClÃ© API pour les embeddings OpenAI
OPENAI_PINNOKIO_SECRET=openai_pinnokio  # Nom du secret dans Google Secret Manager
```

### SystÃ¨me de registre pour collections

ChromaDB utilise un systÃ¨me de registre par collection pour optimiser les performances :

#### Enregistrement de collection
```python
# Au dÃ©marrage de l'application (AuthState.initialize_background_services)
chroma_proxy.register_collection_user(
    user_id=firebase_user_id,
    collection_name=companies_search_id,
    session_id=session_id
)
```

#### Heartbeat de collection
```python
# Maintien automatique de la connexion (TTL de 90 secondes)
chroma_proxy.heartbeat_collection(
    user_id=firebase_user_id,
    collection_name=companies_search_id
)
```

#### DÃ©senregistrement
```python
# Au changement de sociÃ©tÃ© ou dÃ©connexion
chroma_proxy.unregister_collection_user(
    user_id=firebase_user_id,
    collection_name=old_collection_name
)
```

### MÃ©thodes RPC ChromaDB disponibles

#### Gestion des documents
- `CHROMA_VECTOR.add_documents` : Ajoute des documents Ã  une collection
- `CHROMA_VECTOR.query_documents` : Recherche de documents avec similaritÃ© vectorielle
- `CHROMA_VECTOR.delete_documents` : Suppression de documents par critÃ¨res
- `CHROMA_VECTOR.get_collection_info` : Informations sur une collection

#### Analyse de collection
- `CHROMA_VECTOR.analyze_collection` : Analyse complÃ¨te d'une collection (taille, mÃ©triques)

#### Gestion du registre
- `CHROMA_VECTOR.register_collection_user` : Enregistre un utilisateur pour une collection
- `CHROMA_VECTOR.heartbeat_collection` : Met Ã  jour le heartbeat
- `CHROMA_VECTOR.unregister_collection_user` : DÃ©senregistre un utilisateur

### Exemple d'utilisation dans Reflex

```python
# Dans l'application Reflex (mode LOCAL/PROD)
from ..code.tools.chroma_vector_proxy import get_chroma_vector_proxy

# Obtenir le proxy (automatiquement en mode RPC si LOCAL/PROD)
chroma_proxy = get_chroma_vector_proxy()

# CrÃ©er une instance ChromaDB (proxy ou directe selon le mode)
chroma_instance = chroma_proxy.create_chroma_instance(collection_name)

# CrÃ©er un analyseur (proxy ou direct selon le mode)
analyzer = chroma_proxy.create_analyzer_instance(collection_name)

# Utilisation transparente (mÃªme API qu'avant)
chroma_instance.add_documents(documents, metadatas)
results = chroma_instance.query_documents(query_texts)
analysis = analyzer.get_collection_size()
```

### IntÃ©gration avec l'authentification

L'enregistrement ChromaDB est automatiquement gÃ©rÃ© lors des Ã©vÃ©nements d'authentification :

1. **Connexion utilisateur** : Enregistrement automatique dans `initialize_background_services`
2. **Changement de sociÃ©tÃ©** : Mise Ã  jour automatique dans `handle_company_select`
3. **DÃ©connexion** : DÃ©senregistrement automatique (gestion via TTL Redis)

### Optimisations de performance

#### Instance unique par collection
- Le microservice maintient une instance ChromaDB unique par collection
- Ã‰vite les crÃ©ations multiples d'instances coÃ»teuses
- Cache des collections avec thread-safety

#### Registre Redis avec TTL
- Suivi des collections actives par utilisateur
- TTL de 90 secondes pour nettoyer automatiquement les sessions inactives
- Heartbeat automatique pour maintenir les connexions actives

### Migration progressive

#### Ã‰tapes recommandÃ©es :
1. **Phase 1** : Conserver le mode ACTUEL en production
2. **Phase 2** : Tester en mode LOCAL avec le microservice local
3. **Phase 3** : Valider en mode PROD avec un sous-ensemble d'utilisateurs
4. **Phase 4** : Basculer dÃ©finitivement vers le mode PROD

#### Rollback sÃ©curisÃ©
En cas de problÃ¨me, il suffit de modifier `LISTENERS_MODE=ACTUEL` pour revenir au comportement original sans redÃ©ploiement.

### Monitoring ChromaDB

#### MÃ©triques spÃ©cifiques
- Nombre de collections actives par utilisateur
- Taille des collections et utilisation mÃ©moire
- Latence des opÃ©rations vectorielles
- Taux de succÃ¨s des enregistrements de collection

#### Logs structurÃ©s
- `chroma_register`: Enregistrement de collection utilisateur
- `chroma_heartbeat`: Mise Ã  jour du heartbeat
- `chroma_operation`: OpÃ©rations CRUD sur les collections
- `chroma_error`: Erreurs dans les opÃ©rations ChromaDB

Cette intÃ©gration ChromaDB s'inscrit parfaitement dans l'architecture existante du microservice tout en apportant les optimisations de performance nÃ©cessaires pour la gestion des bases de donnÃ©es vectorielles.

---

## Statut de l'IntÃ©gration ChromaDB

### âœ… **MICROSERVICE - TERMINÃ‰**

#### MÃ©thodes RPC implÃ©mentÃ©es et fonctionnelles :
- `CHROMA_VECTOR.register_collection_user` âœ…
- `CHROMA_VECTOR.heartbeat_collection` âœ…
- `CHROMA_VECTOR.unregister_collection_user` âœ…
- `CHROMA_VECTOR.create_chroma_instance` âœ…
- `CHROMA_VECTOR.create_analyzer_instance` âœ…
- `CHROMA_VECTOR.add_documents` âœ…
- `CHROMA_VECTOR.query_documents` âœ…
- `CHROMA_VECTOR.delete_documents` âœ…
- `CHROMA_VECTOR.get_collection_info` âœ…
- `CHROMA_VECTOR.analyze_collection` âœ…

#### Configuration validÃ©e :
- ChromaDB v0.4.14 âœ…
- OpenAI v0.28 âœ…
- Connexion ChromaDB: `35.180.247.70:8000` âœ…
- SystÃ¨me de registre avec heartbeat âœ…

### âš ï¸ **APPLICATION REFLEX - Ã€ VÃ‰RIFIER**

#### ProblÃ¨mes identifiÃ©s dans l'interface utilisateur :

1. **Section "Vector Database Storage"** :
   - âŒ Affiche "Error during storage analysis"
   - âŒ Pourcentage Ã  "0%"
   - âŒ DonnÃ©es ChromaAnalyzer non affichÃ©es

#### Points de vÃ©rification requis cÃ´tÃ© application Reflex :

##### **1. VÃ©rification du proxy ChromaAnalyzer**

**Fichier:** `pinnokio_app/code/tools/chroma_vector_proxy.py`

```python
# MÃ©thode Ã  vÃ©rifier dans ChromaAnalyzerProxy
def get_collection_size(self) -> dict:
    """Analyse la taille de la collection"""
    result = self.vector_proxy.analyze_collection(self.collection_name)
    if result.get("success"):
        return result["analysis"]  # âš ï¸ VÃ‰RIFIER CE RETOUR
    else:
        raise Exception(f"Erreur lors de l'analyse: {result.get('error', 'Erreur inconnue')}")
```

**PROBLÃˆME POTENTIEL:** L'ancien ChromaAnalyzer retournait peut-Ãªtre un format diffÃ©rent que `result["analysis"]`.

##### **2. VÃ©rification du format de rÃ©ponse attendu**

**Le microservice retourne:**
```json
{
    "success": true,
    "collection_name": "klk_space_id_002e0b",
    "analysis": {
        "total_size": 1234567,
        "embeddings_size": 987654,
        "documents_size": 234567,
        "metadata_size": 12346,
        "document_count": 150
    }
}
```

**L'application Reflex attend probablement:**
```python
{
    "total_size": 1234567,
    "embeddings_size": 987654,
    "documents_size": 234567,
    "metadata_size": 12346,
    "document_count": 150
}
```

##### **3. VÃ©rification de la mÃ©thode analyze_storage dans base_state.py**

**Fichier:** `pinnokio_app/state/base_state.py` (ligne ~5502)

```python
async def analyze_storage(self):
    """Analyser l'espace de stockage utilisÃ© par la base vectorielle."""
    async with self:
        try:
            # âš ï¸ VÃ‰RIFIER CETTE PARTIE
            from ..code.tools.chroma_vector_proxy import get_chroma_vector_proxy
            chroma_proxy = get_chroma_vector_proxy()
            chroma_instance = chroma_proxy.create_chroma_instance(self.companies_search_id)
            analyzer = chroma_proxy.create_analyzer_instance(self.companies_search_id)

            # âš ï¸ PROBLÃˆME PROBABLE ICI
            report = analyzer.generate_report()  # Cette mÃ©thode existe-t-elle ?
            stats = analyzer.analyze_collection()  # Ou celle-ci ?

            # âš ï¸ VÃ‰RIFIER LE FORMAT ATTENDU
            self.storage_report = report
            self.storage_stats = stats
```

##### **4. Actions de correction recommandÃ©es**

**A. Corriger ChromaAnalyzerProxy.get_collection_size()**
```python
def get_collection_size(self) -> dict:
    """Analyse la taille de la collection"""
    result = self.vector_proxy.analyze_collection(self.collection_name)
    if result.get("success"):
        # Retourner directement l'analysis, pas le result complet
        return result["analysis"]
    else:
        # Logger l'erreur pour debug
        print(f"âŒ Erreur ChromaDB analysis: {result.get('error')}")
        raise Exception(f"Erreur lors de l'analyse: {result.get('error', 'Erreur inconnue')}")
```

**B. Adapter la mÃ©thode analyze_storage dans base_state.py**
```python
async def analyze_storage(self):
    """Analyser l'espace de stockage utilisÃ© par la base vectorielle."""
    async with self:
        try:
            from ..code.tools.chroma_vector_proxy import get_chroma_vector_proxy
            chroma_proxy = get_chroma_vector_proxy()

            # Utiliser directement analyze_collection via le proxy
            analyzer = chroma_proxy.create_analyzer_instance(self.companies_search_id)

            # Appeler get_collection_size qui fait l'appel RPC
            stats = analyzer.get_collection_size()

            # Adapter au format attendu par l'UI
            self.storage_stats = stats

        except Exception as e:
            print(f"âŒ Erreur analyze_storage: {e}")
            # GÃ©rer l'erreur proprement pour l'UI
            self.storage_stats = {"error": str(e)}
```

**C. VÃ©rifier les mÃ©thodes manquantes**

Si l'application attend `generate_report()` ou `analyze_collection()` sur l'analyzer :

```python
# Dans ChromaAnalyzerProxy, ajouter ces mÃ©thodes si elles manquent
def generate_report(self) -> dict:
    """GÃ©nÃ¨re un rapport d'analyse"""
    return self.get_collection_size()

def analyze_collection(self) -> dict:
    """Analyse la collection"""
    return self.get_collection_size()
```

##### **5. Debug recommandÃ©**

**Ajouter des logs dans base_state.py pour tracer le problÃ¨me:**
```python
async def analyze_storage(self):
    async with self:
        try:
            print(f"ğŸ” analyze_storage: collection_name = {self.companies_search_id}")

            # ... code existant ...

            print(f"ğŸ” analyzer result: {stats}")

        except Exception as e:
            print(f"âŒ analyze_storage erreur complÃ¨te: {e}")
            import traceback
            traceback.print_exc()
```

### ğŸ¯ **Prochaines Ã©tapes pour l'agent Reflex**

1. **Examiner** le fichier `base_state.py` mÃ©thode `analyze_storage`
2. **VÃ©rifier** le format de retour dans `ChromaAnalyzerProxy.get_collection_size()`
3. **Tester** l'appel RPC avec des logs dÃ©taillÃ©s
4. **Adapter** le format de rÃ©ponse du microservice si nÃ©cessaire
5. **Valider** que l'UI affiche correctement les donnÃ©es ChromaDB

Le microservice fonctionne parfaitement. Le problÃ¨me est dans l'adaptation des donnÃ©es entre le microservice et l'interface utilisateur Reflex.
