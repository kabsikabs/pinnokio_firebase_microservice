# ğŸ—ï¸ Architecture Redis CohÃ©rente - Frontend & Backend
## StratÃ©gie de ScalabilitÃ© Horizontale

---

## âœ… IMPLÃ‰MENTATION RÃ‰ALISÃ‰E (DÃ©cembre 2024)

### Modules CrÃ©Ã©s

| Module | Fichier | Description |
|--------|---------|-------------|
| **SessionStateManager** | `app/llm_service/session_state_manager.py` | Externalise l'Ã©tat LLMSession dans Redis (session:*) |
| **ChatHistoryManager** | `app/llm_service/chat_history_manager.py` | Externalise l'historique chat dans Redis (chat:*:history) |
| **DistributedLock** | `app/cron_scheduler.py` | Lock Redis distribuÃ© pour CronScheduler (lock:cron:*) |
| **RedisNamespaces** | `app/llm_service/redis_namespaces.py` | Constantes et helpers pour les clÃ©s Redis |

### Modifications EffectuÃ©es

| Fichier | Modification |
|---------|--------------|
| `app/llm_service/llm_manager.py` | LLMSession utilise SessionStateManager pour Ã©tat hybride (RAM + Redis) |
| `app/pinnokio_agentic_workflow/orchestrator/pinnokio_brain.py` | PinnokioBrain utilise ChatHistoryManager pour sync historique |
| `app/cron_scheduler.py` | CronScheduler utilise DistributedLock pour Ã©viter exÃ©cutions en double |
| `app/llm_service/__init__.py` | Export des nouveaux modules |

### Architecture RÃ©sultante

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARCHITECTURE MULTI-INSTANCE READY                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Instance 1    â”‚     â”‚   Instance 2    â”‚     â”‚   Instance N    â”‚     â”‚
â”‚  â”‚  (ECS Fargate)  â”‚     â”‚  (ECS Fargate)  â”‚     â”‚  (ECS Fargate)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                       â”‚                       â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                   â”‚                                       â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                         â”‚   REDIS CLOUD     â”‚                             â”‚
â”‚                         â”‚                   â”‚                             â”‚
â”‚                         â”‚ session:* (2h)    â”‚  â† Ã‰tat session             â”‚
â”‚                         â”‚ chat:*:history    â”‚  â† Historique chat          â”‚
â”‚                         â”‚ lock:cron:* (5m)  â”‚  â† Locks distribuÃ©s         â”‚
â”‚                         â”‚ context:* (1h)    â”‚  â† Contexte utilisateur     â”‚
â”‚                         â”‚ cache:* (1h)      â”‚  â† Cache donnÃ©es            â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fonctionnement Hybride (Performance + DurabilitÃ©)

1. **Lecture**: Cache local d'abord, puis Redis
2. **Ã‰criture**: Local + Redis en parallÃ¨le
3. **Reprise**: Restauration automatique depuis Redis si session existe
4. **Lock**: Acquisition atomique avec SET NX EX

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Ã‰tat Actuel de l'Architecture](#Ã©tat-actuel-de-larchitecture)
2. [ProblÃ¨mes de ScalabilitÃ© IdentifiÃ©s](#problÃ¨mes-de-scalabilitÃ©-identifiÃ©s)
3. [Architecture Redis CohÃ©rente ProposÃ©e](#architecture-redis-cohÃ©rente-proposÃ©e)
4. [StratÃ©gie de Migration](#stratÃ©gie-de-migration)
5. [Plan de ScalabilitÃ© Horizontale](#plan-de-scalabilitÃ©-horizontale)
6. [Recommandations OpÃ©rationnelles](#recommandations-opÃ©rationnelles)

---

## Ã‰tat Actuel de l'Architecture

### ğŸ—‚ï¸ Namespace Redis Actuels (PartagÃ©s Frontend/Backend)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REDIS CLOUD (Valkey Serverless)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚ ğŸ“¦ NAMESPACE 1: cache:* (DonnÃ©es mÃ©tiers - Frontend)                   â”‚
â”‚    cache:{user_id}:{company_id}:bank:transactions         [TTL: 60min]â”‚
â”‚    cache:{user_id}:{company_id}:drive:documents           [TTL: 30min]â”‚
â”‚    cache:{user_id}:{company_id}:apbookeeper:documents     [TTL: 40min]â”‚
â”‚    cache:{user_id}:{company_id}:expenses:details          [TTL: 40min]â”‚
â”‚                                                                         â”‚
â”‚ ğŸ§  NAMESPACE 2: context:* (Contexte LLM - Backend)                     â”‚
â”‚    context:{user_id}:{collection_name}                    [TTL: 24h] â”‚
â”‚    â””â”€ Contient: mandate_path, client_uuid, dms_system, etc.          â”‚
â”‚                                                                         â”‚
â”‚ ğŸ“Š NAMESPACE 3: jobs:* (MÃ©triques jobs - Backend)                      â”‚
â”‚    jobs:{user_id}:{collection_name}:APBOOKEEPER          [TTL: 30min]â”‚
â”‚    jobs:{user_id}:{collection_name}:ROUTER               [TTL: 30min]â”‚
â”‚    jobs:{user_id}:{collection_name}:BANK                 [TTL: 30min]â”‚
â”‚                                                                         â”‚
â”‚ ğŸ” NAMESPACE 4: registry:* (Registre unifiÃ© - Backend)                 â”‚
â”‚    registry:unified:{user_id}                            [TTL: 24h] â”‚
â”‚    registry:task:{task_id}                               [TTL: var] â”‚
â”‚    registry:company:{company_id}                         [TTL: 24h] â”‚
â”‚                                                                         â”‚
â”‚ ğŸ¯ NAMESPACE 5: idemp:* (Idempotence RPC - Backend)                    â”‚
â”‚    idemp:{idempotency_key}                               [TTL: 15min]â”‚
â”‚                                                                         â”‚
â”‚ ğŸ“¡ NAMESPACE 6: user:{uid} (Pub/Sub Listeners - Backend)               â”‚
â”‚    user:{user_id}                                        [Pub/Sub]   â”‚
â”‚    â””â”€ UtilisÃ© pour: notifications, messages, chat temps rÃ©el         â”‚
â”‚                                                                         â”‚
â”‚ ğŸ”„ NAMESPACE 7: llm_init:* (Initialisation sessions LLM - Backend)     â”‚
â”‚    llm_init:{user_id}:{collection_name}                  [TTL: 5min] â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š Mapping Usage par Application

| Namespace | UtilisÃ© par | AccÃ¨s | Nature | ScalabilitÃ© |
|-----------|-------------|-------|--------|-------------|
| `cache:*` | **Frontend Reflex** | R/W | DonnÃ©es mÃ©tiers | âœ… Stateless |
| `context:*` | **Backend LLM** | R/W | Contexte utilisateur | âš ï¸ Partiel |
| `jobs:*` | **Backend JobLoader** | R/W | MÃ©triques jobs | âœ… Stateless |
| `registry:*` | **Backend Registre** | R/W | Ã‰tat sessions | âš ï¸ Critique |
| `idemp:*` | **Backend RPC** | R/W | DÃ©duplication | âœ… Stateless |
| `user:{uid}` | **Backend Pub/Sub** | Pub/Sub | Ã‰vÃ©nements temps rÃ©el | âŒ **Bloquant** |
| `llm_init:*` | **Backend LLMManager** | R/W | Locks initialisation | âš ï¸ Critique |

---

## ProblÃ¨mes de ScalabilitÃ© IdentifiÃ©s

### ğŸ”´ **ProblÃ¨me #1 : Ã‰tat en MÃ©moire (LLMSession + PinnokioBrain)**

**Fichier** : `app/llm_service/llm_manager.py`

```python
class LLMSession:
    def __init__(self, session_key: str, context: LLMContext):
        self.session_key = session_key
        
        # âš ï¸ PROBLÃˆME : Ã‰tat en mÃ©moire RAM
        self.user_context: Optional[Dict] = None
        self.jobs_data: Optional[Dict] = None
        self.jobs_metrics: Optional[Dict] = None
        
        # âš ï¸ PROBLÃˆME : Brains actifs en RAM (1 brain = 1 chat)
        self.active_brains: Dict[str, Any] = {}  # {thread_key: PinnokioBrain}
        
        # âš ï¸ PROBLÃˆME : Historique chat en RAM
        # Chaque PinnokioBrain a son propre chat_history
```

**Impact ScalabilitÃ©** :
- âŒ **Impossible de distribuer sur plusieurs instances**
- âŒ **Perte de l'Ã©tat si instance tombe**
- âŒ **AffinitÃ© session obligatoire (Sticky Sessions)**

### ğŸ”´ **ProblÃ¨me #2 : Pub/Sub Redis Blocking Architecture**

**Fichier** : `app/listeners_manager.py`

```python
class ListenersManager:
    def start(self):
        # âš ï¸ PROBLÃˆME : Chaque instance Ã©coute TOUS les channels user:{uid}
        # Si 10 instances â†’ 10x listeners pour le mÃªme user
        
        # âš ï¸ PROBLÃˆME : Pas de partitionnement par user
        # Une instance ne peut pas dÃ©lÃ©guer Ã  une autre
```

**Impact ScalabilitÃ©** :
- âš ï¸ **Broadcasting redondant** (chaque instance reÃ§oit tous les messages)
- âš ï¸ **Pas de load balancing** intelligent par user
- âš ï¸ **WebSocket tied Ã  une instance** (pas de failover)

### ğŸŸ¡ **ProblÃ¨me #3 : Duplication des DonnÃ©es (Frontend/Backend)**

**Situation Actuelle** :

```
FRONTEND (Reflex)                    BACKEND (Microservice)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cache:{uid}:{cid}:  â”‚              â”‚ jobs:{uid}:{cid}:   â”‚
â”‚   apbookeeper       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   APBOOKEEPER       â”‚
â”‚   documents         â”‚   DOUBLON?   â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Questions** :
- â“ Les donnÃ©es `cache:*` (frontend) et `jobs:*` (backend) sont-elles redondantes ?
- â“ Le backend devrait-il lire `cache:*` ou maintenir `jobs:*` ?
- â“ Qui est la source de vÃ©ritÃ© ?

### ğŸŸ¡ **ProblÃ¨me #4 : TTL IncohÃ©rents**

| Namespace | TTL | Justification |
|-----------|-----|---------------|
| `cache:*:bank:transactions` | 60 min | Frontend - DonnÃ©es ERP stables |
| `cache:*:drive:documents` | 30 min | Frontend - Drive volatile |
| `context:*` | 24h | Backend - MÃ©tadonnÃ©es company |
| `jobs:*` | 30 min | Backend - MÃ©triques jobs |

**ProblÃ¨me** : Pas de stratÃ©gie cohÃ©rente de rafraÃ®chissement entre frontend/backend.

---

## Architecture Redis CohÃ©rente ProposÃ©e

### ğŸ¯ Objectifs

1. **ScalabilitÃ© Horizontale** : Permettre 2-10 instances backend sans affinitÃ©
2. **Ã‰tat ExternalisÃ©** : Aucun Ã©tat critique en RAM
3. **RÃ©duction Duplication** : Unifier les namespaces frontend/backend
4. **StratÃ©gie TTL CohÃ©rente** : DÃ©finir des rÃ¨gles claires de rafraÃ®chissement

### ğŸ“ Nouvelle Structure Redis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REDIS CLOUD (Source de VÃ©ritÃ© Unique)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚ ğŸ—‚ï¸ TIER 1: SESSION STATE (Ã‰tat utilisateur externalisÃ©)                â”‚
â”‚    session:{user_id}:{company_id}:state                  [TTL: 2h]    â”‚
â”‚    â”œâ”€ user_context (mandate_path, client_uuid, dms_system)            â”‚
â”‚    â”œâ”€ jobs_data (factures, documents, transactions)                   â”‚
â”‚    â”œâ”€ jobs_metrics (compteurs pour system prompt)                     â”‚
â”‚    â””â”€ active_threads (threads de chat actifs)                         â”‚
â”‚                                                                         â”‚
â”‚ ğŸ’¬ TIER 2: CHAT HISTORY (Conversations LLM externalisÃ©es)              â”‚
â”‚    chat:{user_id}:{company_id}:{thread_key}:history      [TTL: 24h]  â”‚
â”‚    â”œâ”€ messages (utilisateur + assistant + tool_results)               â”‚
â”‚    â”œâ”€ system_prompt (avec rÃ©sumÃ©s Ã©ventuels)                          â”‚
â”‚    â”œâ”€ metadata (created_at, last_activity, mode)                      â”‚
â”‚    â””â”€ status (active, idle, terminated)                               â”‚
â”‚                                                                         â”‚
â”‚ ğŸ“¦ TIER 3: BUSINESS DATA CACHE (DonnÃ©es mÃ©tiers - PartagÃ©)            â”‚
â”‚    data:{user_id}:{company_id}:bank:transactions        [TTL: 60min] â”‚
â”‚    data:{user_id}:{company_id}:drive:documents          [TTL: 30min] â”‚
â”‚    data:{user_id}:{company_id}:apbookeeper:documents    [TTL: 40min] â”‚
â”‚    data:{user_id}:{company_id}:expenses:details         [TTL: 40min] â”‚
â”‚    â””â”€ âœ… UtilisÃ© par Frontend ET Backend (source unique)              â”‚
â”‚                                                                         â”‚
â”‚ ğŸ” TIER 4: INFRASTRUCTURE (Registres et coordination)                  â”‚
â”‚    registry:user:{user_id}                               [TTL: 24h]  â”‚
â”‚    registry:task:{task_id}                               [TTL: var]  â”‚
â”‚    idemp:{key}                                          [TTL: 15min] â”‚
â”‚    llm_init:{user_id}:{company_id}                      [TTL: 5min]  â”‚
â”‚                                                                         â”‚
â”‚ ğŸ“¡ TIER 5: REAL-TIME EVENTS (Pub/Sub avec routing)                     â”‚
â”‚    events:{user_id}                                     [Pub/Sub]    â”‚
â”‚    â”œâ”€ notifications (jobs terminÃ©s, erreurs)                          â”‚
â”‚    â”œâ”€ chat_updates (nouveaux messages)                                â”‚
â”‚    â””â”€ state_sync (synchronisation multi-onglets)                      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Mapping Migration

| Ancien Namespace | Nouveau Namespace | Changement |
|------------------|-------------------|------------|
| `cache:{uid}:{cid}:*` | `data:{uid}:{cid}:*` | Renommage (+ partagÃ© backend) |
| `context:{uid}:{cid}` | `session:{uid}:{cid}:state` | IntÃ©gration session |
| `jobs:{uid}:{cid}:*` | **SUPPRIMÃ‰** | Utilise `data:*` directement |
| `user:{uid}` (Pub/Sub) | `events:{uid}` | Renommage (routing amÃ©liorÃ©) |
| **NOUVEAU** | `chat:{uid}:{cid}:{thread}:history` | Externalisation chat history |

---

## StratÃ©gie de Migration

### ğŸ“… Phase 1 : Externalisation Ã‰tat Session (Semaine 1-2)

**Objectif** : Permettre scaling horizontal basique avec sticky sessions

#### 1.1 CrÃ©er `SessionStateManager`

**Nouveau fichier** : `app/state_manager.py`

```python
class SessionStateManager:
    """Gestionnaire d'Ã©tat session externalisÃ© dans Redis."""
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def save_session_state(
        self, 
        user_id: str, 
        company_id: str,
        state: Dict
    ):
        """Sauvegarde l'Ã©tat complet d'une session."""
        key = f"session:{user_id}:{company_id}:state"
        
        payload = {
            "user_context": state.get("user_context"),
            "jobs_data": state.get("jobs_data"),
            "jobs_metrics": state.get("jobs_metrics"),
            "active_threads": state.get("active_threads", []),
            "updated_at": datetime.now(timezone.utc).isoformat()
        }
        
        await self.redis.setex(
            key,
            7200,  # TTL 2h
            json.dumps(payload)
        )
    
    async def load_session_state(
        self, 
        user_id: str, 
        company_id: str
    ) -> Optional[Dict]:
        """Charge l'Ã©tat session depuis Redis."""
        key = f"session:{user_id}:{company_id}:state"
        data = await self.redis.get(key)
        
        if data:
            return json.loads(data)
        return None
    
    async def update_heartbeat(
        self, 
        user_id: str, 
        company_id: str
    ):
        """Met Ã  jour le heartbeat session (prolonge TTL)."""
        key = f"session:{user_id}:{company_id}:state"
        await self.redis.expire(key, 7200)
```

#### 1.2 Modifier `LLMSession` pour Utiliser Redis

**Fichier** : `app/llm_service/llm_manager.py`

```python
class LLMSession:
    def __init__(self, session_key: str, context: LLMContext):
        self.session_key = session_key
        self.context = context
        
        # âœ… NOUVEAU : Gestionnaire d'Ã©tat externalisÃ©
        self.state_manager = SessionStateManager(get_redis())
        
        # âŒ SUPPRIMÃ‰ : Ã‰tat en mÃ©moire
        # self.user_context: Optional[Dict] = None
        # self.jobs_data: Optional[Dict] = None
        # self.jobs_metrics: Optional[Dict] = None
        
        # âš ï¸ CONSERVÃ‰ TEMPORAIREMENT : Brains (Phase 2)
        self.active_brains: Dict[str, Any] = {}
    
    async def get_user_context(self) -> Dict:
        """Charge user_context depuis Redis."""
        state = await self.state_manager.load_session_state(
            self.context.user_id,
            self.context.collection_name
        )
        return state.get("user_context") if state else {}
    
    async def update_jobs_data(self, jobs_data: Dict):
        """Met Ã  jour jobs_data dans Redis."""
        state = await self.state_manager.load_session_state(
            self.context.user_id,
            self.context.collection_name
        ) or {}
        
        state["jobs_data"] = jobs_data
        
        await self.state_manager.save_session_state(
            self.context.user_id,
            self.context.collection_name,
            state
        )
```

**Impact** :
- âœ… Ã‰tat session persiste entre instances
- âœ… Perte d'instance = rÃ©cupÃ©ration automatique
- âš ï¸ Latence additionnelle : ~10-20ms par accÃ¨s Redis

---

### ğŸ“… Phase 2 : Externalisation Chat History (Semaine 3-4)

**Objectif** : Permettre rotation d'instance pendant conversation active

#### 2.1 CrÃ©er `ChatHistoryManager`

**Nouveau fichier** : `app/chat_history_manager.py`

```python
class ChatHistoryManager:
    """Gestionnaire d'historique chat externalisÃ© dans Redis."""
    
    async def save_chat_history(
        self,
        user_id: str,
        company_id: str,
        thread_key: str,
        messages: List[Dict],
        system_prompt: str,
        metadata: Dict
    ):
        """Sauvegarde l'historique complet d'un thread."""
        key = f"chat:{user_id}:{company_id}:{thread_key}:history"
        
        payload = {
            "messages": messages,
            "system_prompt": system_prompt,
            "metadata": metadata,
            "updated_at": datetime.now(timezone.utc).isoformat()
        }
        
        await self.redis.setex(
            key,
            86400,  # TTL 24h
            json.dumps(payload)
        )
    
    async def load_chat_history(
        self,
        user_id: str,
        company_id: str,
        thread_key: str
    ) -> Optional[Dict]:
        """Charge l'historique d'un thread depuis Redis."""
        key = f"chat:{user_id}:{company_id}:{thread_key}:history"
        data = await self.redis.get(key)
        
        if data:
            return json.loads(data)
        return None
    
    async def append_message(
        self,
        user_id: str,
        company_id: str,
        thread_key: str,
        message: Dict
    ):
        """Ajoute un message Ã  l'historique (atomique)."""
        history = await self.load_chat_history(user_id, company_id, thread_key) or {
            "messages": [],
            "metadata": {}
        }
        
        history["messages"].append(message)
        history["updated_at"] = datetime.now(timezone.utc).isoformat()
        
        await self.save_chat_history(
            user_id, company_id, thread_key,
            history["messages"],
            history.get("system_prompt", ""),
            history.get("metadata", {})
        )
```

#### 2.2 Modifier `PinnokioBrain` pour Utiliser Redis

**Fichier** : `app/pinnokio_agentic_workflow/orchestrator/pinnokio_brain.py`

```python
class PinnokioBrain:
    def __init__(self, collection_name: str, firebase_user_id: str, ...):
        self.collection_name = collection_name
        self.firebase_user_id = firebase_user_id
        
        # âœ… NOUVEAU : Gestionnaire d'historique externalisÃ©
        self.chat_history_manager = ChatHistoryManager(get_redis())
        
        # âŒ SUPPRIMÃ‰ : Historique en mÃ©moire
        # self.pinnokio_agent.chat_history = {...}
    
    async def add_user_message(self, content: str, thread_key: str):
        """Ajoute un message utilisateur (sauvegarde Redis)."""
        message = {
            "role": "user",
            "content": content,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        await self.chat_history_manager.append_message(
            self.firebase_user_id,
            self.collection_name,
            thread_key,
            message
        )
    
    async def get_chat_history(self, thread_key: str) -> List[Dict]:
        """RÃ©cupÃ¨re l'historique depuis Redis."""
        history = await self.chat_history_manager.load_chat_history(
            self.firebase_user_id,
            self.collection_name,
            thread_key
        )
        return history.get("messages", []) if history else []
```

**Impact** :
- âœ… Conversation persiste entre instances
- âœ… Scaling horizontal complet (sans sticky sessions)
- âš ï¸ Latence additionnelle : ~15-30ms par message

---

### ğŸ“… Phase 3 : Unification Namespace Data (Semaine 5)

**Objectif** : Ã‰liminer la duplication `cache:*` vs `jobs:*`

#### 3.1 Renommer `cache:*` â†’ `data:*`

**Frontend** : `pinnokio_app/code/tools/redis_cache_manager.py`

```python
class PinnokioCacheManager:
    def _build_cache_key(self, user_id, company_id, data_type, sub_type=None):
        # âœ… NOUVEAU : Namespace unifiÃ©
        key = f"data:{user_id}:{company_id}:{data_type}"
        if sub_type:
            key += f":{sub_type}"
        return key
```

#### 3.2 Backend Lit `data:*` Directement

**Fichier** : `app/pinnokio_agentic_workflow/tools/job_loader.py`

```python
class JobLoader:
    async def _get_from_cache(self, department):
        """Lit depuis le cache UNIFIÃ‰ (data:*)."""
        mapping = {
            "APBOOKEEPER": "apbookeeper:documents",
            "ROUTER": "drive:documents",
            "BANK": "bank:transactions"
        }
        
        data_type = mapping.get(department)
        # âœ… Utilise le mÃªme namespace que le frontend
        cache_key = f"data:{self.user_id}:{self.company_id}:{data_type}"
        
        cached_data = await self.redis.get(cache_key)
        if cached_data:
            return json.loads(cached_data)
        return None
```

**Impact** :
- âœ… Ã‰limination duplication `cache:*` / `jobs:*`
- âœ… Frontend et Backend partagent la mÃªme source
- âœ… RÃ©duction mÃ©moire Redis (~30-40%)

---

### ğŸ“… Phase 4 : AmÃ©lioration Pub/Sub (Semaine 6)

**Objectif** : Router intelligent pour Ã©vÃ©nements temps rÃ©el

#### 4.1 Nouveau Pattern : `events:{user_id}` avec Routing

**Backend** : `app/listeners_manager.py`

```python
class ListenersManager:
    async def publish_event(
        self, 
        user_id: str, 
        event_type: str, 
        payload: Dict
    ):
        """Publie un Ã©vÃ©nement avec routing intelligent."""
        channel = f"events:{user_id}"
        
        message = {
            "type": event_type,  # "notification", "chat_update", "state_sync"
            "payload": payload,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        await self.redis.publish(channel, json.dumps(message))
    
    async def subscribe_user_events(self, user_id: str):
        """Ã‰coute UNIQUEMENT les Ã©vÃ©nements d'un user."""
        channel = f"events:{user_id}"
        pubsub = self.redis.pubsub()
        await pubsub.subscribe(channel)
        
        async for message in pubsub.listen():
            if message["type"] == "message":
                event = json.loads(message["data"])
                await self._handle_event(user_id, event)
```

**Impact** :
- âœ… Routing Ã©vÃ©nements par type
- âœ… Pas de broadcasting redondant
- âœ… PrÃ©paration multi-instance (chaque instance Ã©coute ses users)

---

## Plan de ScalabilitÃ© Horizontale

### ğŸ¯ Architecture Cible

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ALB (Round Robin)                           â”‚
â”‚               Session Affinity: OPTIONNEL                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ firebase_microservice â”‚  â”‚ firebase_microservice  â”‚
    â”‚      Instance 1       â”‚  â”‚      Instance 2        â”‚
    â”‚      (Stateless)      â”‚  â”‚      (Stateless)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      Redis (ElastiCache)       â”‚
              â”‚  - session:* (Ã©tat session)    â”‚
              â”‚  - chat:* (historique)         â”‚
              â”‚  - data:* (business cache)     â”‚
              â”‚  - events:* (pub/sub routing)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š Modes de DÃ©ploiement

#### **Mode 1 : Sticky Sessions (Phase 1-2)**

**Configuration ALB** :
```yaml
stickiness:
  enabled: true
  type: lb_cookie
  duration: 7200  # 2 heures
```

**Avantages** :
- âœ… Migration progressive
- âœ… Performances (moins d'accÃ¨s Redis)
- âœ… CompatibilitÃ© avec code existant

**InconvÃ©nients** :
- âš ï¸ Distribution non optimale
- âš ï¸ Perte de session si instance tombe

#### **Mode 2 : Round Robin Complet (Phase 3-4)**

**Configuration ALB** :
```yaml
stickiness:
  enabled: false
routing:
  algorithm: round_robin
```

**Avantages** :
- âœ… Distribution parfaite
- âœ… RÃ©silience complÃ¨te
- âœ… Scaling horizontal illimitÃ©

**InconvÃ©nients** :
- âš ï¸ Latence Redis Ã  chaque requÃªte
- âš ï¸ CoÃ»t Redis plus Ã©levÃ©

---

## Recommandations OpÃ©rationnelles

### ğŸ”§ Configuration Redis Optimale

**Fichier** : `.env` / AWS Parameter Store

```bash
# Redis Configuration
REDIS_HOST=your-elasticache-endpoint.use1.cache.amazonaws.com
REDIS_PORT=6379
REDIS_PASSWORD=your-strong-password
REDIS_TLS=true
REDIS_DB=0

# Performance Tuning
REDIS_POOL_SIZE=50              # Pool de connexions
REDIS_SOCKET_TIMEOUT=5          # Timeout socket
REDIS_SOCKET_CONNECT_TIMEOUT=5  # Timeout connexion
REDIS_RETRY_ON_TIMEOUT=true     # Retry automatique

# Cache Strategy
SESSION_STATE_TTL=7200          # 2h pour Ã©tat session
CHAT_HISTORY_TTL=86400          # 24h pour historique chat
DATA_CACHE_TTL_BANK=3600        # 1h pour transactions bancaires
DATA_CACHE_TTL_DRIVE=1800       # 30min pour documents Drive
DATA_CACHE_TTL_AP=2400          # 40min pour factures AP
```

### ğŸ“Š Monitoring Redis

**MÃ©triques Critiques** :

```python
# app/monitoring/redis_metrics.py

class RedisMetrics:
    """SystÃ¨me de monitoring Redis."""
    
    async def get_key_distribution(self) -> Dict:
        """Distribution des clÃ©s par namespace."""
        patterns = [
            "session:*",
            "chat:*",
            "data:*",
            "events:*",
            "registry:*"
        ]
        
        distribution = {}
        for pattern in patterns:
            cursor = 0
            count = 0
            
            while True:
                cursor, keys = await self.redis.scan(
                    cursor=cursor,
                    match=pattern,
                    count=1000
                )
                count += len(keys)
                if cursor == 0:
                    break
            
            namespace = pattern.split(":")[0]
            distribution[namespace] = count
        
        return distribution
    
    async def get_memory_usage(self) -> Dict:
        """Utilisation mÃ©moire par namespace."""
        info = await self.redis.info("memory")
        
        return {
            "used_memory_human": info["used_memory_human"],
            "used_memory_peak_human": info["used_memory_peak_human"],
            "maxmemory_human": info.get("maxmemory_human", "unlimited"),
            "mem_fragmentation_ratio": info["mem_fragmentation_ratio"]
        }
    
    async def get_hit_ratio(self) -> float:
        """Ratio cache hit/miss."""
        info = await self.redis.info("stats")
        
        hits = int(info.get("keyspace_hits", 0))
        misses = int(info.get("keyspace_misses", 0))
        
        if hits + misses == 0:
            return 0.0
        
        return hits / (hits + misses)
```

### ğŸš¨ Alertes CloudWatch

**MÃ©triques Ã  Surveiller** :

| MÃ©trique | Seuil | Action |
|----------|-------|--------|
| `CPUUtilization` | > 70% | Scale up |
| `DatabaseMemoryUsagePercentage` | > 80% | Augmenter cache size |
| `CacheHitRate` | < 70% | Revoir stratÃ©gie TTL |
| `EngineCPUUtilization` | > 90% | Critique - intervention |
| `NetworkBytesIn/Out` | Anomalie | VÃ©rifier pub/sub |

### ğŸ§ª Tests de Charge

**ScÃ©narios Ã  Tester** :

```python
# tests/load_testing/redis_load_test.py

async def test_concurrent_sessions():
    """Test 100 sessions utilisateur concurrentes."""
    tasks = []
    
    for i in range(100):
        user_id = f"user_{i}"
        company_id = f"company_{i % 10}"  # 10 sociÃ©tÃ©s
        
        task = simulate_user_session(user_id, company_id)
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    
    # VÃ©rifier :
    # - Temps de rÃ©ponse < 100ms
    # - Aucune perte de donnÃ©es
    # - Hit ratio > 70%

async def test_failover():
    """Test basculement entre instances."""
    # 1. CrÃ©er session sur instance 1
    session = await create_session_instance_1()
    
    # 2. Simuler crash instance 1
    await shutdown_instance_1()
    
    # 3. Reprendre session sur instance 2
    session_recovered = await resume_session_instance_2()
    
    # VÃ©rifier :
    # - Ã‰tat session identique
    # - Historique chat prÃ©servÃ©
    # - Aucune perte de donnÃ©es
```

---

## ğŸ“š Checklist de Migration

### âœ… Phase 1 : Externalisation Session (Semaines 1-2)

- [ ] CrÃ©er `SessionStateManager` (`app/state_manager.py`)
- [ ] Modifier `LLMSession` pour utiliser Redis
- [ ] Tests unitaires Ã©tat session
- [ ] Tests intÃ©gration frontend/backend
- [ ] DÃ©ploiement staging avec sticky sessions
- [ ] Validation performance (< 20ms overhead)
- [ ] Monitoring mÃ©triques Redis

### âœ… Phase 2 : Externalisation Chat History (Semaines 3-4)

- [ ] CrÃ©er `ChatHistoryManager` (`app/chat_history_manager.py`)
- [ ] Modifier `PinnokioBrain` pour utiliser Redis
- [ ] Tests conversation multi-instance
- [ ] Migration donnÃ©es RTDB â†’ Redis (historique)
- [ ] Tests failover instance
- [ ] Validation latence messages (< 30ms)

### âœ… Phase 3 : Unification Namespace (Semaine 5)

- [ ] Renommer `cache:*` â†’ `data:*` (frontend)
- [ ] Modifier backend pour lire `data:*`
- [ ] Supprimer namespace `jobs:*` (legacy)
- [ ] Tests compatibilitÃ© frontend/backend
- [ ] Migration donnÃ©es Redis
- [ ] Validation rÃ©duction mÃ©moire

### âœ… Phase 4 : AmÃ©lioration Pub/Sub (Semaine 6)

- [ ] CrÃ©er routing `events:{user_id}`
- [ ] Migrer `user:{uid}` â†’ `events:{uid}`
- [ ] Tests multi-instance pub/sub
- [ ] Monitoring Ã©vÃ©nements temps rÃ©el
- [ ] Validation latence notifications

### âœ… Phase 5 : Production (Semaine 7)

- [ ] Configuration ALB round-robin
- [ ] Auto-scaling backend (2-10 instances)
- [ ] Monitoring complet Redis
- [ ] Tests de charge 100+ users
- [ ] Documentation opÃ©rationnelle
- [ ] Runbook incidents

---

## ğŸ¯ RÃ©sumÃ©

### Ã‰tat Actuel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ Ã‰tat en mÃ©moire (LLMSession, PinnokioBrain)       â”‚
â”‚ âŒ Scaling horizontal impossible                      â”‚
â”‚ âš ï¸ Duplication donnÃ©es (cache:* vs jobs:*)          â”‚
â”‚ âš ï¸ Pub/Sub broadcasting redondant                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Cible

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Ã‰tat externalisÃ© dans Redis                       â”‚
â”‚ âœ… Scaling horizontal 2-10 instances                 â”‚
â”‚ âœ… Namespace unifiÃ© (data:*)                         â”‚
â”‚ âœ… Pub/Sub avec routing intelligent                  â”‚
â”‚ âœ… RÃ©silience complÃ¨te (failover automatique)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ROI Attendu

| MÃ©trique | Avant | AprÃ¨s | AmÃ©lioration |
|----------|-------|-------|--------------|
| **Scaling** | Vertical uniquement | Horizontal 2-10x | **10x capacitÃ©** |
| **RÃ©silience** | âŒ Perte Ã©tat si crash | âœ… RÃ©cupÃ©ration auto | **100%** |
| **Latence** | ~50ms (local) | ~80ms (Redis) | **+60% acceptable** |
| **CoÃ»t Redis** | $50/mois | $150/mois | **+200% justifiÃ©** |
| **CoÃ»t ECS** | 1 instance (2 vCPU, 4GB) | 2-10 instances (auto-scale) | **Variable selon charge** |

---

**ğŸ¯ Conclusion : L'architecture Redis actuelle nÃ©cessite une refonte significative pour permettre un vrai scaling horizontal. La migration proposÃ©e en 5 phases permet une transition progressive tout en prÃ©servant la stabilitÃ© du service.**

