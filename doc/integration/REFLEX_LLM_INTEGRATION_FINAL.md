# ğŸ¤– IntÃ©gration LLM Reflex - Plan d'implÃ©mentation FINAL

## ğŸ“‹ Vue d'ensemble

Ce document dÃ©crit l'intÃ©gration complÃ¨te du service LLM microservice dans l'application Reflex, avec une architecture indÃ©pendante et une gestion intelligente des changements de sociÃ©tÃ©.

## ğŸ¯ Architecture proposÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REFLEX APPLICATION                        â”‚
â”‚                                                             â”‚
â”‚  AuthState (authentification)                               â”‚
â”‚  â”œâ”€ user_id: str                                           â”‚
â”‚  â”œâ”€ authorized_companies: List[str]                        â”‚
â”‚  â”œâ”€ current_company_id: str                                â”‚
â”‚  â””â”€ on_auth_success() â†’ initialize_llm_state()            â”‚
â”‚                                                             â”‚
â”‚  LLMState (NOUVEAU - indÃ©pendant)                           â”‚
â”‚  â”œâ”€ _llm_session_id: Optional[str]                          â”‚
â”‚  â”œâ”€ _llm_connected: bool                                   â”‚
â”‚  â”œâ”€ _llm_collection_name: str                              â”‚
â”‚  â”œâ”€ initialize_session() â†’ RPC LLM.initialize_session     â”‚
â”‚  â”œâ”€ update_company() â†’ RPC LLM.update_context             â”‚
â”‚  â””â”€ send_message() â†’ RPC LLM.send_message                 â”‚
â”‚                                                             â”‚
â”‚  ChatState (MODIFIÃ‰)                                       â”‚
â”‚  â”œâ”€ question: str                                          â”‚
â”‚  â”œâ”€ processing: bool                                       â”‚
â”‚  â”œâ”€ chats: Dict[str, List[QA]]                             â”‚
â”‚  â”œâ”€ send_message() â†’ LLMState.send_message()              â”‚
â”‚  â””â”€ _handle_chat_message() (INCHANGÃ‰ - listener RTDB)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ ImplÃ©mentation dÃ©taillÃ©e

### **1. CrÃ©er LLMState indÃ©pendant**

**Fichier :** `pinnokio_app/state/llm_state.py` (NOUVEAU)

```python
import reflex as rx
from typing import Optional
from .manager import get_manager  # RPC manager existant

class LLMState(rx.State):
    """Ã‰tat indÃ©pendant pour la gestion LLM via microservice."""
    
    # Variables d'Ã©tat
    _llm_session_id: Optional[str] = None
    _llm_connected: bool = False
    _llm_collection_name: str = ""
    _llm_user_id: str = ""
    _llm_dms_system: str = "google_drive"
    _llm_dms_mode: str = "prod"
    _llm_chat_mode: str = "general_chat"
    
    # Ã‰tat de connexion
    _llm_init_inflight: bool = False
    _llm_error: Optional[str] = None
    
    async def initialize_llm_session(
        self, 
        user_id: str, 
        collection_name: str,
        dms_system: str = "google_drive",
        dms_mode: str = "prod",
        chat_mode: str = "general_chat"
    ) -> bool:
        """Initialise une session LLM via le microservice."""
        try:
            if self._llm_init_inflight:
                return False
                
            self._llm_init_inflight = True
            self._llm_error = None
            yield
            
            # Appel RPC au microservice
            result = await get_manager().rpc_call(
                method="LLM.initialize_session",
                args={
                    "user_id": user_id,
                    "collection_name": collection_name,
                    "dms_system": dms_system,
                    "dms_mode": dms_mode,
                    "chat_mode": chat_mode
                },
                user_id=user_id,
                timeout_ms=30000
            )
            
            if result and result.get("success"):
                self._llm_session_id = result.get("session_id")
                self._llm_connected = True
                self._llm_collection_name = collection_name
                self._llm_user_id = user_id
                self._llm_dms_system = dms_system
                self._llm_dms_mode = dms_mode
                self._llm_chat_mode = chat_mode
                
                print(f"âœ… LLM initialisÃ©: {self._llm_session_id}")
                return True
            else:
                error_msg = result.get("error", "Unknown error") if result else "No response"
                self._llm_error = error_msg
                print(f"âŒ Erreur initialisation LLM: {error_msg}")
                return False
                
        except Exception as e:
            self._llm_error = str(e)
            print(f"âŒ Exception initialisation LLM: {e}")
            return False
        finally:
            self._llm_init_inflight = False
            yield
    
    async def update_company_context(self, new_collection_name: str) -> bool:
        """Met Ã  jour le contexte LLM lors du changement de sociÃ©tÃ©."""
        try:
            if not self._llm_connected or not self._llm_session_id:
                # RÃ©initialiser avec la nouvelle sociÃ©tÃ©
                return await self.initialize_llm_session(
                    user_id=self._llm_user_id,
                    collection_name=new_collection_name,
                    dms_system=self._llm_dms_system,
                    dms_mode=self._llm_dms_mode,
                    chat_mode=self._llm_chat_mode
                )
            
            # Mettre Ã  jour le contexte existant
            self._llm_collection_name = new_collection_name
            
            # Note: Le microservice gÃ¨re automatiquement le changement de contexte
            # via la session existante
            print(f"âœ… Contexte LLM mis Ã  jour pour sociÃ©tÃ©: {new_collection_name}")
            return True
            
        except Exception as e:
            print(f"âŒ Erreur mise Ã  jour contexte LLM: {e}")
            return False
    
    async def send_message(
        self,
        space_code: str,
        chat_thread: str,
        message: str,
        system_prompt: str = None
    ) -> dict:
        """Envoie un message via le microservice."""
        try:
            if not self._llm_connected:
                return {"success": False, "error": "LLM non connectÃ©"}
            
            # Appel RPC au microservice
            result = await get_manager().rpc_call(
                method="LLM.send_message",
                args={
                    "user_id": self._llm_user_id,
                    "collection_name": self._llm_collection_name,
                    "space_code": space_code,
                    "chat_thread": chat_thread,
                    "message": message,
                    "chat_mode": self._llm_chat_mode,
                    "system_prompt": system_prompt
                },
                user_id=self._llm_user_id,
                timeout_ms=5000
            )
            
            return result if result else {"success": False, "error": "No response"}
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_llm_status(self) -> dict:
        """Retourne le statut de la connexion LLM."""
        return {
            "connected": self._llm_connected,
            "session_id": self._llm_session_id,
            "collection_name": self._llm_collection_name,
            "error": self._llm_error,
            "init_inflight": self._llm_init_inflight
        }
```

### **2. Modifier AuthState pour initialiser LLMState**

**Fichier :** `pinnokio_app/state/auth_state.py` (MODIFIÃ‰)

```python
# Ajouter dans AuthState aprÃ¨s authentification rÃ©ussie
from .llm_state import LLMState

class AuthState(rx.State):
    # ... variables existantes ...
    
    async def on_auth_success(self, user_id: str, authorized_companies: list, current_company: str):
        """AppelÃ© aprÃ¨s authentification rÃ©ussie."""
        # ... logique existante ...
        
        # ğŸ†• NOUVEAU: Initialiser LLMState
        await self.initialize_llm_for_user(user_id, current_company)
    
    async def initialize_llm_for_user(self, user_id: str, collection_name: str):
        """Initialise le service LLM pour l'utilisateur authentifiÃ©."""
        try:
            # AccÃ©der Ã  LLMState depuis l'instance globale
            llm_state = LLMState()
            success = await llm_state.initialize_llm_session(
                user_id=user_id,
                collection_name=collection_name,
                dms_system="google_drive",  # Ã€ rÃ©cupÃ©rer depuis user_info
                dms_mode="prod",
                chat_mode="general_chat"
            )
            
            if success:
                print(f"âœ… LLM initialisÃ© pour {user_id} dans sociÃ©tÃ© {collection_name}")
            else:
                print(f"âŒ Ã‰chec initialisation LLM pour {user_id}")
                
        except Exception as e:
            print(f"âŒ Erreur initialisation LLM: {e}")
    
    async def switch_company(self, new_company_id: str):
        """Change de sociÃ©tÃ© et met Ã  jour le contexte LLM."""
        # ... logique existante de changement de sociÃ©tÃ© ...
        
        # ğŸ†• NOUVEAU: Mettre Ã  jour LLMState
        await self.update_llm_company_context(new_company_id)
    
    async def update_llm_company_context(self, new_collection_name: str):
        """Met Ã  jour le contexte LLM lors du changement de sociÃ©tÃ©."""
        try:
            llm_state = LLMState()
            success = await llm_state.update_company_context(new_collection_name)
            
            if success:
                print(f"âœ… Contexte LLM mis Ã  jour pour sociÃ©tÃ©: {new_collection_name}")
            else:
                print(f"âŒ Ã‰chec mise Ã  jour contexte LLM")
                
        except Exception as e:
            print(f"âŒ Erreur mise Ã  jour contexte LLM: {e}")
```

### **3. Modifier ChatState pour utiliser LLMState**

**Fichier :** `pinnokio_app/state/base_state.py` (MODIFIÃ‰)

```python
from .llm_state import LLMState

class ChatState(rx.State):
    # ... variables existantes INCHANGÃ‰ES ...
    
    # ğŸ†• NOUVEAU: RÃ©fÃ©rence Ã  LLMState
    _llm_state: Optional[LLMState] = None
    
    def __init__(self):
        super().__init__()
        self._llm_state = LLMState()
    
    @rx.event(background=True)
    async def initialize_llm_agent(self):
        """âœ… MODIFIÃ‰: Utilise LLMState au lieu de l'ancien systÃ¨me."""
        try:
            # VÃ©rifier si LLMState est dÃ©jÃ  connectÃ©
            if self._llm_state._llm_connected:
                print("âœ… LLM dÃ©jÃ  connectÃ© via LLMState")
                return True
            
            # RÃ©cupÃ©rer les infos utilisateur depuis AuthState
            user_id = getattr(self, 'firebase_user_id', None)
            collection_name = getattr(self, 'base_collection_id', None)
            
            if not user_id or not collection_name:
                print("âŒ Infos utilisateur manquantes pour LLM")
                return False
            
            # Initialiser via LLMState
            success = await self._llm_state.initialize_llm_session(
                user_id=user_id,
                collection_name=collection_name,
                dms_system=getattr(self, 'dms_type_extracted', 'google_drive'),
                dms_mode="prod",
                chat_mode=getattr(self, 'chat_mode', 'general_chat')
            )
            
            return success
            
        except Exception as e:
            print(f"âŒ Erreur initialisation LLM: {e}")
            return False
    
    @rx.event(background=True)
    async def send_message(self):
        """âœ… MODIFIÃ‰: Utilise LLMState pour envoyer via microservice."""
        if not self.question.strip():
            return
        
        try:
            # VÃ©rifier que LLMState est connectÃ©
            if not self._llm_state._llm_connected:
                print("âš ï¸ LLM non connectÃ©, initialisation...")
                success = await self.initialize_llm_agent()
                if not success:
                    yield rx.toast.error("Impossible de se connecter Ã  l'assistant")
                    return
            
            question = self.question
            self.question = ""
            self.processing = True
            current_chat_key = self.current_chat
            
            yield
            
            # RÃ©cupÃ©rer le system prompt selon le mode
            system_prompt = self._get_system_prompt_by_mode()
            
            # âœ… Envoi via LLMState (qui appelle le microservice)
            result = await self._llm_state.send_message(
                space_code=self.base_collection_id,  # collection_name = space_code
                chat_thread=current_chat_key,
                message=question,
                system_prompt=system_prompt
            )
            
            if not result.get("success"):
                error_msg = result.get("error", "Unknown error")
                print(f"âŒ Erreur envoi message: {error_msg}")
                self.processing = False
                yield rx.toast.error(f"Erreur: {error_msg}")
                return
            
            # âœ… C'EST TOUT ! Le listener RTDB va gÃ©rer le reste automatiquement
            print(f"âœ… Message envoyÃ© au microservice: {result.get('assistant_message_id')}")
            
        except Exception as e:
            print(f"âŒ Exception send_message: {e}")
            self.processing = False
            yield rx.toast.error(f"Erreur: {str(e)}")
    
    def _get_system_prompt_by_mode(self) -> str:
        """Retourne le prompt systÃ¨me selon le chat_mode."""
        # ... logique existante inchangÃ©e ...
        pass
    
    # âœ… _handle_chat_message() reste INCHANGÃ‰
    # Le listener RTDB continue de fonctionner exactement comme avant
```

## ğŸ”„ Flux de communication complet

```
1. AuthState.on_auth_success()
   â†“
2. AuthState.initialize_llm_for_user()
   â†“
3. LLMState.initialize_llm_session() â†’ RPC LLM.initialize_session
   â†“
4. ChatState.send_message()
   â†“
5. LLMState.send_message() â†’ RPC LLM.send_message
   â†“
6. Microservice Ã©crit dans Firebase RTDB
   â†“
7. ChatState._handle_chat_message() (listener RTDB)
   â†“
8. UI mise Ã  jour automatiquement
```

## ğŸ¯ Avantages de cette architecture

1. **âœ… SÃ©paration claire** : LLMState indÃ©pendant d'AuthState et ChatState
2. **âœ… Gestion sociÃ©tÃ©** : Changement automatique du contexte LLM
3. **âœ… RÃ©utilisation** : LLMState peut Ãªtre utilisÃ© par d'autres composants
4. **âœ… CompatibilitÃ©** : ChatState garde la mÃªme interface
5. **âœ… Ã‰volutivitÃ©** : Facile d'ajouter de nouvelles fonctionnalitÃ©s LLM

## ğŸ“‹ Checklist d'implÃ©mentation

- [ ] CrÃ©er `pinnokio_app/state/llm_state.py`
- [ ] Modifier `AuthState` pour initialiser LLMState
- [ ] Modifier `ChatState` pour utiliser LLMState
- [ ] Tester initialisation aprÃ¨s authentification
- [ ] Tester changement de sociÃ©tÃ©
- [ ] Tester conversation complÃ¨te end-to-end

## ğŸš€ DÃ©ploiement

### Ã‰tape 1: CrÃ©er les fichiers
1. CrÃ©er `pinnokio_app/state/llm_state.py`
2. Modifier `pinnokio_app/state/auth_state.py`
3. Modifier `pinnokio_app/state/base_state.py`

### Ã‰tape 2: Tests
1. Tester authentification â†’ initialisation LLM
2. Tester changement de sociÃ©tÃ© â†’ mise Ã  jour contexte
3. Tester conversation complÃ¨te

### Ã‰tape 3: Production
1. DÃ©ployer microservice avec service LLM
2. DÃ©ployer Reflex avec nouvelles modifications
3. VÃ©rifier fonctionnement end-to-end

## ğŸ” Points d'attention

1. **Gestion d'erreurs** : Fallback si microservice indisponible
2. **Performance** : Cache des sessions LLM
3. **SÃ©curitÃ©** : Validation des paramÃ¨tres utilisateur
4. **Monitoring** : Logs et mÃ©triques de performance

---

**Cette architecture garantit une intÃ©gration propre et Ã©volutive du service LLM dans Reflex !** ğŸš€

