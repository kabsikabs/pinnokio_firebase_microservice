# ğŸ“š HR Redis Cache - Backend Documentation

> **Date de CrÃ©ation**: 16 Janvier 2026  
> **Auteur**: Integration Redis HR Module  
> **Version**: 1.0.0  
> **Backend**: firebase_microservice

---

## ğŸ“‹ Vue d'Ensemble

Cette documentation dÃ©crit l'intÃ©gration du cache Redis dans le module HR du backend `firebase_microservice`. Le cache amÃ©liore considÃ©rablement les performances en rÃ©duisant les appels Ã  PostgreSQL Neon.

### Objectifs

- **Performance**: RÃ©duction des temps de rÃ©ponse de 80-90% pour les lectures
- **ScalabilitÃ©**: Diminution de la charge sur PostgreSQL
- **ExpÃ©rience Utilisateur**: Chargement instantanÃ© des donnÃ©es frÃ©quemment consultÃ©es

---

## ğŸ—ï¸ Architecture

### Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚
â”‚  (Reflex)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ RPC Call
       â”‚ + firebase_user_id
       â”‚ + company_id
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (firebase_microservice) â”‚
â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ hr_rpc_handlers  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                      â”‚
â”‚           â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ hr_cache_manager â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚      â”‚                   â”‚
â”‚     HITâ”‚    â”‚MISS                â”‚
â”‚       â”‚      â”‚                   â”‚
â”‚       â–¼      â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚Redis â”‚ â”‚neon_hr_mgr â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                  â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ PostgreSQL  â”‚
            â”‚    Neon     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern Cache-First

**Lecture (GET):**
1. âœ… Tentative de lecture depuis Redis (cache)
2. âŒ Si MISS â†’ Lecture depuis PostgreSQL
3. ğŸ’¾ Stockage dans Redis pour les prochains accÃ¨s
4. â†©ï¸ Retour des donnÃ©es + indicateur source (`cache` ou `database`)

**Ã‰criture (CREATE/UPDATE/DELETE):**
1. âœï¸ Ã‰criture dans PostgreSQL (source de vÃ©ritÃ©)
2. ğŸ—‘ï¸ Invalidation du cache Redis concernÃ©
3. âœ… Confirmation de l'opÃ©ration
4. ğŸ”„ Prochain GET â†’ Rechargement depuis PostgreSQL + mise en cache

---

## ğŸ”‘ Structure des ClÃ©s Redis

### Format Standard

```
cache:{user_id}:{company_id}:hr:{data_type}[:{sub_type}]
```

### ClÃ©s UtilisÃ©es

| ClÃ© | Description | TTL | Exemple |
|-----|-------------|-----|---------|
| `cache:{uid}:{cid}:hr:employees` | Liste des employÃ©s | 1h | Tous les employÃ©s d'une sociÃ©tÃ© |
| `cache:{uid}:{cid}:hr:employee:{emp_id}` | DÃ©tail d'un employÃ© | 1h | Informations complÃ¨tes employÃ© |
| `cache:{uid}:{cid}:hr:contracts:{emp_id}` | Contrats d'un employÃ© | 1h | Liste des contrats |
| `cache:{uid}:{cid}:hr:active_contract:{emp_id}` | Contrat actif | 1h | Contrat en cours |
| `cache:{uid}:{cid}:hr:clusters[:country]` | Clusters/CCT | 24h | Liste des cantons CH |
| `cache:{uid}:{cid}:hr:references:{country}:{lang}` | DonnÃ©es de rÃ©fÃ©rence | 24h | Types contrats, statuts, etc. |

**Exemple concret:**
```
cache:uid_xyz123:comp_uuid456:hr:employees
cache:uid_xyz123:comp_uuid456:hr:contracts:emp_uuid789
cache:uid_xyz123:comp_uuid456:hr:references:CH:fr
```

---

## â±ï¸ TTLs (Time To Live)

### Valeurs ConfigurÃ©es

Les TTLs sont dÃ©finis dans [`app/llm_service/redis_namespaces.py`](../llm_service/redis_namespaces.py):

```python
class RedisTTL:
    HR_EMPLOYEES = 3600      # 1 heure
    HR_CONTRACTS = 3600      # 1 heure
    HR_REFERENCES = 86400    # 24 heures
    HR_CLUSTERS = 86400      # 24 heures
```

### Justifications

| Type de DonnÃ©es | TTL | Justification |
|-----------------|-----|---------------|
| **Employees** | 1h | ModifiÃ©es occasionnellement, Ã©quilibre fraÃ®cheur/performance |
| **Contracts** | 1h | DonnÃ©es stables, changements peu frÃ©quents |
| **References** | 24h | Statiques, rarement modifiÃ©es (types contrat, statuts) |
| **Clusters** | 24h | Configuration systÃ¨me, quasi-immuable |

---

## ğŸ› ï¸ Fichiers ModifiÃ©s/CrÃ©Ã©s

### Fichiers CrÃ©Ã©s

#### 1. [`app/tools/hr_cache_manager.py`](../tools/hr_cache_manager.py)

Gestionnaire de cache Redis asynchrone dÃ©diÃ© au module HR.

**Classe principale:** `HRCacheManager`

**MÃ©thodes publiques:**
- `get_cached_data(user_id, company_id, data_type, sub_type, ttl_seconds)` â†’ Lecture cache
- `set_cached_data(user_id, company_id, data_type, sub_type, data, ttl_seconds)` â†’ Ã‰criture cache
- `invalidate_cache(user_id, company_id, data_type, sub_type)` â†’ Invalidation ciblÃ©e
- `invalidate_company_hr_cache(user_id, company_id)` â†’ Invalidation complÃ¨te HR
- `get_cache_stats(user_id, company_id)` â†’ Statistiques cache

**Singleton:**
```python
from app.tools.hr_cache_manager import get_hr_cache_manager

cache = get_hr_cache_manager()
cached = await cache.get_cached_data(user_id, company_id, "hr", "employees")
```

#### 2. [`app/docs/HR_REDIS_CACHE_BACKEND.md`](HR_REDIS_CACHE_BACKEND.md)

Cette documentation.

### Fichiers ModifiÃ©s

#### 1. [`app/hr_rpc_handlers.py`](../hr_rpc_handlers.py)

**Modifications:**
- Import du cache manager et des TTLs
- Ajout paramÃ¨tre `firebase_user_id` (optionnel) aux mÃ©thodes de lecture
- IntÃ©gration du pattern cache-first dans les mÃ©thodes GET
- Invalidation du cache dans les mÃ©thodes CREATE/UPDATE/DELETE
- Retour de la source des donnÃ©es (`cache` ou `database`)

**MÃ©thodes avec cache (lecture):**
- `list_employees(company_id, firebase_user_id=None)`
- `get_employee(company_id, employee_id, firebase_user_id=None)`
- `list_contracts(company_id, employee_id, firebase_user_id=None)`
- `get_active_contract(company_id, employee_id, firebase_user_id=None)`
- `list_clusters(country_code, firebase_user_id=None, company_id=None)`
- `get_all_references(country_code, lang, firebase_user_id=None, company_id=None)`

**MÃ©thodes avec invalidation (Ã©criture):**
- `create_employee(..., firebase_user_id=None)`
- `update_employee(..., firebase_user_id=None)`
- `delete_employee(..., firebase_user_id=None)`
- `create_contract(..., firebase_user_id=None)`

#### 2. [`app/llm_service/redis_namespaces.py`](../llm_service/redis_namespaces.py)

**Ajout:**
```python
class RedisTTL:
    # ... existant ...
    
    # HR Module
    HR_EMPLOYEES = 3600      # 1 heure
    HR_CONTRACTS = 3600      # 1 heure
    HR_REFERENCES = 86400    # 24 heures
    HR_CLUSTERS = 86400      # 24 heures
```

---

## ğŸ’» Exemples d'Utilisation

### Exemple 1: Liste des EmployÃ©s avec Cache

**Frontend (Reflex):**
```python
# Appel RPC avec firebase_user_id pour bÃ©nÃ©ficier du cache
result = await rpc_call(
    "HR.list_employees",
    company_id=self.hr_company_id,
    firebase_user_id=self.firebase_user_id  # âœ… Active le cache
)

employees = result.get("employees", [])
source = result.get("source")  # "cache" ou "database"
print(f"ğŸ“Š Loaded {len(employees)} employees from {source}")
```

**Backend (Handler):**
```python
async def list_employees(self, company_id: str, firebase_user_id: str = None):
    # 1. Tentative cache
    if firebase_user_id:
        cache = get_hr_cache_manager()
        cached = await cache.get_cached_data(
            firebase_user_id, company_id, "hr", "employees", 
            ttl_seconds=RedisTTL.HR_EMPLOYEES
        )
        if cached:
            return {"employees": cached["data"], "source": "cache"}
    
    # 2. Fallback PostgreSQL
    manager = get_neon_hr_manager()
    employees = await manager.list_employees(UUID(company_id))
    serialized = [_serialize_employee(emp) for emp in employees]
    
    # 3. Mise en cache
    if firebase_user_id and serialized:
        await cache.set_cached_data(
            firebase_user_id, company_id, "hr", "employees", 
            serialized, ttl_seconds=RedisTTL.HR_EMPLOYEES
        )
    
    return {"employees": serialized, "source": "database"}
```

### Exemple 2: CrÃ©ation d'EmployÃ© avec Invalidation

**Frontend:**
```python
# CrÃ©ation d'un nouvel employÃ©
result = await rpc_call(
    "HR.create_employee",
    company_id=self.hr_company_id,
    firebase_user_id=self.firebase_user_id,  # âœ… Active invalidation
    identifier="EMP001",
    first_name="Jean",
    last_name="Dupont",
    birth_date="1990-01-15",
    cluster_code="CH-GE",
    hire_date="2024-01-01"
)

# Le cache "employees" est automatiquement invalidÃ©
# Prochain appel list_employees â†’ rechargement depuis PostgreSQL
```

**Backend (Handler):**
```python
async def create_employee(self, company_id, firebase_user_id=None, ...):
    # 1. Ã‰criture PostgreSQL
    manager = get_neon_hr_manager()
    employee_id = await manager.create_employee(...)
    
    # 2. Invalidation cache
    if firebase_user_id:
        cache = get_hr_cache_manager()
        await cache.invalidate_cache(
            firebase_user_id, company_id, "hr", "employees"
        )
    
    return {"employee_id": str(employee_id)}
```

### Exemple 3: Sans Cache (RÃ©trocompatibilitÃ©)

**Frontend (ancien code):**
```python
# Appel RPC sans firebase_user_id â†’ pas de cache
result = await rpc_call(
    "HR.list_employees",
    company_id=self.hr_company_id
    # Pas de firebase_user_id â†’ lecture directe PostgreSQL
)
```

âœ… **Le systÃ¨me continue de fonctionner** sans le cache si `firebase_user_id` n'est pas fourni.

---

## ğŸ” Monitoring et Debugging

### Logs

Les logs du cache utilisent le prÃ©fixe `[HR_CACHE]`:

```
âœ… [HR_CACHE] HIT: cache:uid123:comp456:hr:employees | Cached: 2026-01-16T10:30:00 | Items: 25
âŒ [HR_CACHE] MISS: cache:uid123:comp456:hr:employees
ğŸ’¾ [HR_CACHE] Stockage rÃ©ussi: cache:uid123:comp456:hr:employees | TTL: 3600s | Taille: 15234
ğŸ—‘ï¸ [HR_CACHE] Invalidation demandÃ©e: cache:uid123:comp456:hr:employees
```

### Statistiques Cache

Obtenir les statistiques du cache pour un utilisateur/sociÃ©tÃ©:

```python
cache = get_hr_cache_manager()
stats = await cache.get_cache_stats(user_id, company_id)

print(f"Total keys: {stats['total_keys']}")
print(f"Data types: {stats['data_types']}")
print(f"Total size: {stats['total_size_bytes']} bytes")
print(f"Oldest entry: {stats['oldest_entry']}")
print(f"Newest entry: {stats['newest_entry']}")
```

**Exemple de sortie:**
```python
{
    "total_keys": 5,
    "data_types": {
        "employees": 1,
        "contracts": 2,
        "references": 1,
        "clusters": 1
    },
    "total_size_bytes": 45678,
    "oldest_entry": "2026-01-16T08:15:00",
    "newest_entry": "2026-01-16T10:45:00"
}
```

### VÃ©rification Redis (CLI)

```bash
# Connexion Redis
redis-cli -h <host> -p <port> -a <password>

# Lister toutes les clÃ©s HR d'un utilisateur
SCAN 0 MATCH cache:uid_xyz123:*:hr:* COUNT 100

# Afficher une clÃ© spÃ©cifique
GET cache:uid_xyz123:comp_uuid456:hr:employees

# VÃ©rifier le TTL restant
TTL cache:uid_xyz123:comp_uuid456:hr:employees

# Supprimer manuellement une clÃ© (debugging)
DEL cache:uid_xyz123:comp_uuid456:hr:employees
```

---

## âš ï¸ Points d'Attention

### 1. CohÃ©rence des DonnÃ©es

**ProblÃ¨me:** DonnÃ©es en cache obsolÃ¨tes si modification externe (admin DB, autre systÃ¨me).

**Solution:** 
- TTLs courts (1h) pour donnÃ©es volatiles
- Invalidation manuelle si nÃ©cessaire
- Fonction de refresh forcÃ© dans l'UI

### 2. Fallback Gracieux

Le systÃ¨me continue de fonctionner mÃªme si Redis est indisponible:

```python
try:
    redis_client = await self._get_redis_client()
    cached_data = await redis_client.get(cache_key)
    # ...
except Exception as e:
    logger.error(f"Redis error: {e}")
    return None  # â†’ Fallback PostgreSQL
```

### 3. Taille des DonnÃ©es en Cache

**Limite Redis:** Ã‰viter de stocker des objets > 10MB par clÃ©.

**Recommandation:**
- Ne pas mettre en cache les donnÃ©es volumineuses (PDFs, exports)
- Paginer les listes trÃ¨s longues (> 1000 employÃ©s)

### 4. Invalidation Multi-Utilisateurs

**ScÃ©nario:** User A modifie un employÃ©, User B consulte la liste.

**Comportement actuel:** 
- User A â†’ Cache invalidÃ© â†’ Prochain GET = fresh data
- User B â†’ Cache non invalidÃ© â†’ DonnÃ©es potentiellement obsolÃ¨tes jusqu'Ã  expiration TTL

**Solution envisagÃ©e (future):**
- Broadcaster l'invalidation via Pub/Sub Redis
- Invalider le cache pour tous les utilisateurs de la mÃªme sociÃ©tÃ©

---

## ğŸš€ Performances Attendues

### Comparaison Avant/AprÃ¨s Cache

| OpÃ©ration | Sans Cache | Avec Cache (HIT) | Gain |
|-----------|------------|------------------|------|
| list_employees (25 emp) | 150-200ms | 10-15ms | **93%** |
| get_employee | 80-100ms | 5-8ms | **94%** |
| list_contracts | 60-80ms | 5-8ms | **92%** |
| get_all_references | 300-400ms | 8-12ms | **97%** |

### Taux de Cache Hit EspÃ©rÃ©

- **Consultation normale:** 80-90% HIT
- **PremiÃ¨re visite:** 0% HIT (normal)
- **AprÃ¨s modifications:** 0% HIT sur donnÃ©es modifiÃ©es (invalidation)

---

## ğŸ“ Checklist d'IntÃ©gration Frontend

Pour bÃ©nÃ©ficier du cache, mettre Ã  jour le frontend:

- [ ] Passer `firebase_user_id` dans tous les appels RPC HR de lecture
- [ ] Passer `firebase_user_id` dans tous les appels RPC HR d'Ã©criture
- [ ] Afficher l'indicateur de source (`cache` vs `database`) dans l'UI (optionnel)
- [ ] Ajouter un bouton "RafraÃ®chir" qui force le rechargement PostgreSQL
- [ ] Tester le comportement en cas d'indisponibilitÃ© Redis

**Exemple de mise Ã  jour:**

```python
# âŒ AVANT (sans cache)
result = await rpc_call("HR.list_employees", company_id=self.hr_company_id)

# âœ… APRÃˆS (avec cache)
result = await rpc_call(
    "HR.list_employees", 
    company_id=self.hr_company_id,
    firebase_user_id=self.firebase_user_id
)
```

---

## ğŸ”§ Configuration

### Variables d'Environnement

Le cache utilise la mÃªme configuration Redis que le reste du backend:

```bash
# Redis Connection
LISTENERS_REDIS_HOST=your-redis-host.amazonaws.com
LISTENERS_REDIS_PORT=6379
LISTENERS_REDIS_PASSWORD=your-redis-password
LISTENERS_REDIS_TLS=true
LISTENERS_REDIS_DB=0

# Local Development
USE_LOCAL_REDIS=true  # Force localhost:6379
```

### DÃ©sactivation du Cache (Debug)

Pour dÃ©sactiver temporairement le cache sans modifier le code:

**Option 1:** Ne pas passer `firebase_user_id` dans les appels RPC.

**Option 2:** Modifier temporairement les TTLs Ã  0 dans `redis_namespaces.py`:

```python
class RedisTTL:
    HR_EMPLOYEES = 0  # Cache dÃ©sactivÃ©
```

---

## ğŸ“ RÃ©fÃ©rences

### Fichiers Principaux

- [`app/tools/hr_cache_manager.py`](../tools/hr_cache_manager.py) - Cache manager
- [`app/hr_rpc_handlers.py`](../hr_rpc_handlers.py) - Handlers RPC avec cache
- [`app/llm_service/redis_namespaces.py`](../llm_service/redis_namespaces.py) - Constantes TTL
- [`app/tools/neon_hr_manager.py`](../tools/neon_hr_manager.py) - Manager PostgreSQL

### Documentation Connexe

- [HR Module Integration (Frontend)](../../../../pinnokio_app/docs/hr/HR_MODULE_INTEGRATION.md)
- [Redis Cache Implementation (Frontend)](../../../../pinnokio_app/docs/architecture_devops/REDIS_CACHE_IMPLEMENTATION_FINAL.md)
- Backend Integration HR (firebase_microservice)

---

## ğŸ“ˆ Ã‰volutions Futures

### PrÃ©vues

1. **Invalidation Multi-Utilisateurs**: Broadcaster via Redis Pub/Sub
2. **MÃ©triques Prometheus**: Exposer HIT/MISS rate, latences
3. **Cache Warming**: PrÃ©-charger le cache au login
4. **Cache Partiel**: StratÃ©gies de pagination pour grandes listes

### Ã€ ConsidÃ©rer

- **Cache HiÃ©rarchique**: Redis (L1) + PostgreSQL Read Replica (L2)
- **Compression**: Compresser les donnÃ©es en cache si > 1MB
- **Versioning**: Invalider automatiquement en cas de changement de schÃ©ma

---

*Documentation mise Ã  jour le 16 Janvier 2026 - IntÃ©gration Redis Cache HR Backend v1.0*
