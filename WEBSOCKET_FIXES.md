# ğŸ”§ Correctifs WebSocket - DÃ©connexions et Race Conditions

## ğŸ“‹ RÃ©sumÃ© du ProblÃ¨me

Le service ECS tombait en panne avec `ServiceSchedulerInitiated` Ã  cause de health checks ELB Ã©chouÃ©s. L'analyse a rÃ©vÃ©lÃ© :

1. **DÃ©connexions brutales** (code 1006 - ABNORMAL_CLOSURE)
2. **Race conditions** entre dÃ©connexion et reconnexion rapide
3. **Blocage du backend** pendant le cleanup des listeners
4. **Health checks Ã©chouÃ©s** â†’ Task ECS tuÃ© par AWS

## âœ… Solutions ImplÃ©mentÃ©es

### 1. ğŸ” Logs AmÃ©liorÃ©s (`app/main.py`)

**Avant :**
```python
logger.info("ws_disconnect uid=%s", uid)
```

**AprÃ¨s :**
```python
logger.warning("ğŸ”´ ws_disconnect uid=%s code=%s reason=%s type=%s", uid, code, reason, disconnect_reason)
```

**BÃ©nÃ©fices :**
- Identification du type de dÃ©connexion (normal, abnormal, timeout, etc.)
- Logs visuels avec emojis pour repÃ©rage rapide
- Logs structurÃ©s pour analyse

### 2. ğŸ“Š MÃ©triques WebSocket (`app/ws_metrics.py`)

Nouveau module pour tracer :
- Nombre de dÃ©connexions par utilisateur
- Raisons de dÃ©connexion (1000, 1006, timeout, etc.)
- Horodatage de la derniÃ¨re dÃ©connexion
- DÃ©tection des dÃ©connexions frÃ©quentes

**Endpoint :** `GET /ws-metrics`

**Exemple de rÃ©ponse :**
```json
{
  "status": "ok",
  "metrics": {
    "total_users_tracked": 5,
    "top_disconnects": [
      ["user123", 3],
      ["user456", 2]
    ],
    "all_reasons": {
      "user123": {
        "abnormal_closure": 2,
        "normal_closure": 1
      }
    }
  }
}
```

### 3. â° DÃ©lai avec Annulation (`app/listeners_manager.py`)

**ProblÃ¨me :**
```
T+0s  : DÃ©connexion
T+0s  : Backend lance cleanup
T+0.5s: Frontend reconnecte
T+0.5s: Backend attache de nouveaux listeners
â†’ CONFLIT : Cleanup et attachment simultanÃ©s
â†’ DEADLOCK â†’ Health checks Ã©chouent
```

**Solution :**
```python
def _do_detach():
    # â° Attendre 5 secondes avant le cleanup
    time.sleep(5)
    
    # ğŸ” VÃ©rifier si reconnexion pendant le dÃ©lai
    with self._lock:
        if uid in self._user_unsubs:
            logger.info("âœ… Cleanup annulÃ© (reconnexion)")
            return
    
    # ğŸ§¹ ProcÃ©der au cleanup seulement si pas de reconnexion
    # ... cleanup code ...
```

**BÃ©nÃ©fices :**
- Ã‰vite le cleanup inutile en cas de reconnexion rapide
- Ã‰limine la race condition
- RÃ©duit la charge CPU/rÃ©seau

### 4. ğŸ”¬ Diagnostic Timeout (`pinnokio_app/listeners/bus_consumer.py`)

**Avant :**
```python
websockets.connect(ws_full, ping_interval=20, ping_timeout=20)
```

**AprÃ¨s :**
```python
websockets.connect(ws_full, ping_interval=20, ping_timeout=60)
```

**Objectif :**
- **ping_interval=20** : Envoie un PING toutes les 20 secondes
- **ping_timeout=60** : Attend jusqu'Ã  60 secondes pour le PONG (au lieu de 20s)

**Diagnostic :**
- Si dÃ©connexions **persistent** avec 60s â†’ ProblÃ¨me rÃ©seau ou fermeture explicite
- Si dÃ©connexions **disparaissent** â†’ C'Ã©tait un timeout dÃ» au blocage backend

## ğŸ“Š Monitoring et Diagnostic

### Consulter les mÃ©triques

```bash
curl https://your-service.com/ws-metrics
```

### Logs Ã  surveiller

| Emoji | Message | Signification |
|-------|---------|---------------|
| ğŸ”´ | `ws_disconnect` | DÃ©connexion WebSocket |
| â° | `user_detach_delay_start` | DÃ©but du dÃ©lai de 5s |
| âœ… | `user_detach_cancelled` | Cleanup annulÃ© (reconnexion) |
| ğŸ§¹ | `user_detach_executing` | Cleanup en cours |
| ğŸ”µ | `REGISTRY_CLEANUP_START` | Nettoyage registre Firestore |
| ğŸŸ¢ | `REGISTRY_CLEANUP_SUCCESS` | Nettoyage rÃ©ussi |
| ğŸ”´ | `REGISTRY_CLEANUP_ERROR` | Erreur nettoyage |
| ğŸŸ¡ | `ws_cleanup_complete` | Nettoyage WebSocket terminÃ© |

### Codes de dÃ©connexion WebSocket

| Code | Nom | Cause |
|------|-----|-------|
| 1000 | Normal Closure | Fermeture propre (logout, navigation) |
| 1001 | Going Away | Fermeture page/onglet |
| 1006 | Abnormal Closure | **Timeout ping/pong, crash backend, coupure rÃ©seau** |
| 1011 | Server Error | Exception non gÃ©rÃ©e cÃ´tÃ© serveur |

## ğŸ§ª Tests RecommandÃ©s

### Test 1 : Reconnexion Rapide
1. Se connecter Ã  l'application
2. Fermer/rouvrir l'onglet rapidement (< 5s)
3. **Attendu :** Log `user_detach_cancelled`

### Test 2 : DÃ©connexion Longue
1. Se connecter Ã  l'application
2. Fermer l'onglet et attendre 10 secondes
3. **Attendu :** Logs `user_detach_executing` â†’ `REGISTRY_CLEANUP_SUCCESS`

### Test 3 : StabilitÃ© ECS
1. DÃ©ployer les changements
2. Surveiller les health checks ELB pendant 30 minutes
3. **Attendu :** Aucun Ã©chec de health check

### Test 4 : Timeout Diagnostic
1. Analyser les logs avec `ping_timeout=60`
2. Si `code=1006` persiste â†’ ProblÃ¨me rÃ©seau/frontend
3. Si `code=1006` disparaÃ®t â†’ C'Ã©tait un blocage backend (rÃ©solu)

## ğŸš€ DÃ©ploiement

### Backend (firebase_microservice)

```bash
# Les fichiers modifiÃ©s :
app/main.py                  # Logs amÃ©liorÃ©s + endpoint /ws-metrics
app/ws_metrics.py            # Nouveau module de mÃ©triques
app/listeners_manager.py     # DÃ©lai 5s avec annulation
```

**DÃ©ploiement automatique** via GitHub Actions sur push vers `master`.

### Frontend (pinnokio_app)

```bash
# Les fichiers modifiÃ©s :
pinnokio_app/listeners/bus_consumer.py  # ping_timeout: 20â†’60s
```

**RedÃ©marrage nÃ©cessaire** de l'application Reflex.

## ğŸ“ˆ MÃ©triques Ã  Surveiller Post-DÃ©ploiement

1. **ECS Task Stability**
   - Tasks arrÃªtÃ©s (ServiceSchedulerInitiated) â†’ Devrait Ãªtre 0
   - Health check failures â†’ Devrait Ãªtre 0

2. **CloudWatch Logs**
   - FrÃ©quence de `ws_disconnect code=1006`
   - Ratio `user_detach_cancelled` / `user_detach_executing`
   - Temps de cleanup (`REGISTRY_CLEANUP_SUCCESS`)

3. **Application Metrics**
   - Latence des listeners
   - Nombre de reconnexions
   - Taux d'erreur des RPC calls

## ğŸ”„ Rollback Rapide

Si les changements causent des problÃ¨mes :

### Backend
```bash
git revert HEAD
git push origin master
# Attendre le redÃ©ploiement automatique
```

### Frontend
```python
# Remettre ping_timeout=20 dans bus_consumer.py
websockets.connect(ws_full, ping_interval=20, ping_timeout=20)
```

## ğŸ“ Notes Importantes

1. **Le dÃ©lai de 5 secondes** peut lÃ©gÃ¨rement retarder le cleanup en production, mais c'est un compromis acceptable pour Ã©viter les race conditions.

2. **Le ping_timeout de 60 secondes** est temporaire pour le diagnostic. Une fois la cause identifiÃ©e, on peut le rÃ©duire Ã  30-40 secondes.

3. **Les mÃ©triques WebSocket** consomment de la mÃ©moire. Le nettoyage automatique sera ajoutÃ© si nÃ©cessaire.

4. **Logs avec emojis** : Assurez-vous que CloudWatch affiche correctement les caractÃ¨res UTF-8.

## ğŸ¯ Prochaines Ã‰tapes

1. âœ… DÃ©ployer les changements
2. ğŸ” Surveiller les logs pendant 24h
3. ğŸ“Š Analyser les mÃ©triques `/ws-metrics`
4. ğŸ”§ Ajuster `ping_timeout` selon les rÃ©sultats
5. ğŸ§¹ ImplÃ©menter un nettoyage automatique des mÃ©triques si nÃ©cessaire
6. ğŸ“ˆ CrÃ©er un dashboard CloudWatch pour visualiser les mÃ©triques

---

**Date :** 20 novembre 2025  
**Auteur :** Assistant IA + Cedric  
**RÃ©fÃ©rence :** ServiceSchedulerInitiated / ELB Health Check Failures

