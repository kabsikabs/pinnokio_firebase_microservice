"""
Test des diff√©rents modes d'utilisation des outils avec GROQ
Tests : auto, required (pr√©cis√©), none (sans outils)
"""

import json
from app.llm.klk_agents import BaseAIAgent, ModelProvider, ModelSize
from app.llm.klk_agents import NEW_GROQ_AGENT

# ============================================================================
# CONFIGURATION DES OUTILS
# ============================================================================

TOOLS = [
    {
        "name": "calculate_sum",
        "description": "Additionne deux nombres entiers ou d√©cimaux",
        "input_schema": {
            "type": "object",
            "properties": {
                "a": {
                    "type": "number",
                    "description": "Premier nombre √† additionner"
                },
                "b": {
                    "type": "number",
                    "description": "Deuxi√®me nombre √† additionner"
                }
            },
            "required": ["a", "b"]
        }
    },
    {
        "name": "get_weather",
        "description": "Obtient les informations m√©t√©orologiques pour une ville donn√©e",
        "input_schema": {
            "type": "object",
            "properties": {
                "city": {
                    "type": "string",
                    "description": "Nom de la ville"
                },
                "unit": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "Unit√© de temp√©rature",
                    "default": "celsius"
                }
            },
            "required": ["city"]
        }
    }
]

# Fonctions dummy pour le mapping
def calculate_sum(a: float, b: float) -> float:
    """Additionne deux nombres"""
    result = a + b
    print(f"   üî¢ Calcul : {a} + {b} = {result}")
    return result

def get_weather(city: str, unit: str = "celsius") -> dict:
    """Retourne la m√©t√©o simul√©e"""
    weather_data = {
        "city": city,
        "temperature": 22 if unit == "celsius" else 72,
        "unit": unit,
        "conditions": "Ensoleill√©",
        "humidity": 65
    }
    print(f"   üå§Ô∏è  M√©t√©o pour {city} : {weather_data['temperature']}¬∞{unit[0].upper()} - {weather_data['conditions']}")
    return weather_data

TOOL_MAPPING = {
    "calculate_sum": calculate_sum,
    "get_weather": get_weather
}

# ============================================================================
# TESTS
# ============================================================================

def test_1_mode_auto():
    """
    TEST 1 : MODE AUTO
    Le mod√®le d√©cide s'il utilise un outil ou non
    """
    print("\n" + "="*80)
    print("üìù TEST 1 : MODE AUTO - Le mod√®le d√©cide")
    print("="*80)
    print("Configuration : tool_choice={'type': 'auto'}")
    print("Question : Calcul math√©matique (devrait utiliser calculate_sum)")
    
    base_agent = BaseAIAgent()
    groq_instance = NEW_GROQ_AGENT()
    base_agent.register_provider(
        ModelProvider.GROQ,
        groq_instance,
        ModelSize.REASONING_MEDIUM
    )
    
    try:
        response = base_agent.process_tool_use(
            content="Combien font 25 + 37 ?",
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            tool_choice={"type": "auto"},  # Le mod√®le d√©cide
            provider=ModelProvider.GROQ,
            size=ModelSize.REASONING_MEDIUM  # Kimi K2
        )
        
        print(f"\n‚úÖ R√©sultat :")
        if 'tool_calls' in response:
            print(f"  üîß Outils appel√©s : {len(response['tool_calls'])}")
            for tool_call in response['tool_calls']:
                print(f"     - Outil : {tool_call.function.name}")
                print(f"     - Arguments : {tool_call.function.arguments}")
            
            if 'tool_results' in response:
                print(f"\n  üìä R√©sultats des outils :")
                for result in response['tool_results']:
                    print(f"     - {result['name']} : {result['content']}")
        elif 'text_output' in response:
            print(f"  üìù R√©ponse textuelle : {response['text_output']}")
        else:
            print(f"  ‚ÑπÔ∏è  Type de r√©ponse : {type(response)}")
        
        print("\nüí° Analyse : Le mod√®le a d√©cid√© d'utiliser un outil (calculate_sum)")
        
    except Exception as e:
        print(f"\n‚ùå Erreur : {str(e)}")
    
    print("\n" + "-"*80)

def test_2_mode_required():
    """
    TEST 2 : MODE REQUIRED (PR√âCIS√â)
    Le mod√®le DOIT utiliser un outil parmi ceux disponibles
    """
    print("\n" + "="*80)
    print("üìù TEST 2 : MODE REQUIRED - Le mod√®le DOIT utiliser un outil")
    print("="*80)
    print("Configuration : tool_choice={'type': 'any'}")
    print("Question : Question g√©n√©rale (doit quand m√™me utiliser un outil)")
    
    base_agent = BaseAIAgent()
    groq_instance = NEW_GROQ_AGENT()
    base_agent.register_provider(
        ModelProvider.GROQ,
        groq_instance,
        ModelSize.REASONING_MEDIUM
    )
    
    try:
        response = base_agent.process_tool_use(
            content="Quelle est la m√©t√©o √† Paris aujourd'hui ?",
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            tool_choice={"type": "any"},  # DOIT utiliser un outil (any ‚Üí required pour Groq)
            provider=ModelProvider.GROQ,
            size=ModelSize.REASONING_MEDIUM  # Kimi K2
        )
        
        print(f"\n‚úÖ R√©sultat :")
        if 'tool_calls' in response:
            print(f"  üîß Outils appel√©s : {len(response['tool_calls'])}")
            for tool_call in response['tool_calls']:
                print(f"     - Outil : {tool_call.function.name}")
                print(f"     - Arguments : {tool_call.function.arguments}")
            
            if 'tool_results' in response:
                print(f"\n  üìä R√©sultats des outils :")
                for result in response['tool_results']:
                    print(f"     - {result['name']} : {result['content']}")
        elif 'text_output' in response:
            print(f"  üìù R√©ponse textuelle : {response['text_output']}")
        else:
            print(f"  ‚ÑπÔ∏è  Type de r√©ponse : {type(response)}")
        
        print("\nüí° Analyse : Le mod√®le a √©t√© forc√© d'utiliser un outil (probablement get_weather)")
        
    except Exception as e:
        print(f"\n‚ùå Erreur : {str(e)}")
    
    print("\n" + "-"*80)

def test_3_mode_none():
    """
    TEST 3 : MODE NONE (SANS OUTILS)
    Le mod√®le NE DOIT PAS utiliser d'outils
    """
    print("\n" + "="*80)
    print("üìù TEST 3 : MODE NONE - Le mod√®le NE DOIT PAS utiliser d'outils")
    print("="*80)
    print("Configuration : tool_choice={'type': 'none'}")
    print("Question : Calcul math√©matique (ne doit PAS utiliser calculate_sum)")
    
    base_agent = BaseAIAgent()
    groq_instance = NEW_GROQ_AGENT()
    base_agent.register_provider(
        ModelProvider.GROQ,
        groq_instance,
        ModelSize.REASONING_MEDIUM
    )
    
    try:
        response = base_agent.process_tool_use(
            content="Combien font 15 multipli√© par 8 ?",
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            tool_choice={"type": "none"},  # NE DOIT PAS utiliser d'outils
            provider=ModelProvider.GROQ,
            size=ModelSize.REASONING_MEDIUM  # Kimi K2
        )
        
        print(f"\n‚úÖ R√©sultat :")
        if 'tool_calls' in response:
            print(f"  ‚ö†Ô∏è  ERREUR : Le mod√®le a utilis√© un outil alors qu'il ne devrait pas !")
            for tool_call in response['tool_calls']:
                print(f"     - Outil : {tool_call.function.name}")
        elif 'text_output' in response:
            print(f"  üìù R√©ponse textuelle : {response['text_output']}")
        elif hasattr(response, 'choices') and response.choices:
            # Si c'est un objet ChatCompletion brut
            text = response.choices[0].message.content
            print(f"  üìù R√©ponse textuelle : {text}")
        else:
            print(f"  ‚ÑπÔ∏è  Type de r√©ponse : {type(response)}")
        
        print("\nüí° Analyse : Le mod√®le a r√©pondu directement sans utiliser d'outil")
        
    except Exception as e:
        print(f"\n‚ùå Erreur : {str(e)}")
    
    print("\n" + "-"*80)

def test_4_mode_forced_tool():
    """
    TEST 4 : MODE OUTIL FORC√â (BONUS)
    Le mod√®le DOIT utiliser un outil sp√©cifique
    """
    print("\n" + "="*80)
    print("üìù TEST 4 : MODE OUTIL FORC√â - Force l'utilisation de calculate_sum")
    print("="*80)
    print("Configuration : tool_choice={'type': 'tool', 'name': 'calculate_sum'}")
    print("Question : Question ambigu√´ (pourrait calculer mentalement ou utiliser l'outil)")
    
    base_agent = BaseAIAgent()
    groq_instance = NEW_GROQ_AGENT()
    base_agent.register_provider(
        ModelProvider.GROQ,
        groq_instance,
        ModelSize.REASONING_MEDIUM
    )
    
    try:
        response = base_agent.process_tool_use(
            content="J'ai 25 pommes et j'en ach√®te 37 de plus. Combien j'en ai maintenant ?",
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            tool_choice={
                "type": "tool",
                "name": "calculate_sum"
            },  # Force calculate_sum
            provider=ModelProvider.GROQ,
            size=ModelSize.REASONING_MEDIUM  # Kimi K2
        )
        
        print(f"\n‚úÖ R√©sultat :")
        if 'error' in response:
            print(f"  ‚ùå Erreur inattendue : {response['error']}")
            print(f"  üí° Note : Cette erreur est inattendue car la question est pertinente pour calculate_sum")
        elif 'tool_calls' in response:
            print(f"  üîß Outils appel√©s : {len(response['tool_calls'])}")
            for tool_call in response['tool_calls']:
                print(f"     - Outil : {tool_call.function.name}")
                print(f"     - Arguments : {tool_call.function.arguments}")
            
            if 'tool_results' in response:
                print(f"\n  üìä R√©sultats des outils :")
                for result in response['tool_results']:
                    print(f"     - {result['name']} : {result['content']}")
            
            print(f"\n  ‚úÖ SUCCESS : Le mod√®le a bien utilis√© calculate_sum comme forc√©")
        elif 'text_output' in response:
            print(f"  üìù R√©ponse textuelle : {response['text_output']}")
            print(f"  ‚ö†Ô∏è  Le mod√®le n'a pas utilis√© l'outil (comportement inattendu)")
        else:
            print(f"  ‚ÑπÔ∏è  Type de r√©ponse : {type(response)}")
        
        print("\nüí° Analyse : Le mod√®le est forc√© d'utiliser calculate_sum m√™me s'il pourrait calculer mentalement")
        
    except Exception as e:
        print(f"\n‚ùå Erreur : {str(e)}")
    
    print("\n" + "-"*80)

def test_5_structured_output():
    """
    TEST 5 : STRUCTURED OUTPUT (SORTIE STRUCTUR√âE)
    Force un outil pour obtenir une r√©ponse dans un format JSON structur√©
    Simule audit_agent_loggeur : forcer le mod√®le √† r√©pondre dans un format pr√©cis
    Utilise GPT OSS 20B au lieu de Kimi K2 pour tester le comportement
    """
    print("\n" + "="*80)
    print("üìù TEST 5 : STRUCTURED OUTPUT - Force une r√©ponse structur√©e JSON")
    print("="*80)
    print("üß† Mod√®le : GPT OSS 20B (openai/gpt-oss-20b) - 1000 TPS")
    print("Configuration : tool_choice={'type': 'tool', 'name': 'send_message_tool'}")
    print("Usage : Garantir que la r√©ponse est dans un format JSON pr√©cis")
    print("Note : L'outil n'ex√©cute RIEN, il sert juste √† structurer la sortie")
    
    # D√©finition de l'outil pour structured output (format OpenAI/Groq)
    tool_message = [
        {
            "type": "function",
            "function": {
                "name": "send_message_tool",
                "description": "Schema pour assurer la r√©ponse √† l'utilisateur dans un format structur√©",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "user_message": {
                            "type": "string",
                            "description": "Message √† envoyer √† l'utilisateur"
                        }
                    },
                    "required": ["user_message"]
                }
            }
        }
    ]
    
    # Pas de mapping r√©el (on veut juste la structure)
    tool_map = {'send_message_tool': None}
    
    # Force l'utilisation de l'outil
    tool_choice = {"type": "function", "function": {"name": "send_message_tool"}}
    
    try:
        # Utilisation directe de NEW_GROQ_AGENT pour sp√©cifier le mod√®le exact
        groq_instance = NEW_GROQ_AGENT()
        
        # Contenu du prompt - Reformul√© pour demander explicitement une structure
        user_language = "fran√ßais"
        content = f"""G√©n√®re un message informatif pour l'utilisateur concernant l'analyse de document :
        
        Informations √† communiquer :
        - 42 pages ont √©t√© extraites
        - 15 sections principales ont √©t√© identifi√©es
        - Le traitement est √† 75% de compl√©tion
        
        Important : 
        - R√©ponds toujours dans la langue de l'utilisateur ({user_language})
        - Ne pose jamais de question
        - Le message est purement informatif sur l'avanc√©e du traitement
        
        Utilise send_message_tool pour formater ta r√©ponse."""
        
        print(f"\nüìù Prompt : G√©n√©ration de message informatif structur√©")
        print(f"üåê Langue : {user_language}")
        
        # Appel direct avec le nom exact du mod√®le
        response = groq_instance.groq_agent(
            content=content,
            model_name="openai/gpt-oss-20b",  # Force GPT OSS 20B
            tools=tool_message,
            tool_mapping=tool_map,
            tool_choice=tool_choice,
            max_tokens=500
        )
        
        print(f"\n‚úÖ R√©sultat :")
        
        # Gestion d'erreur comme dans audit_agent_loggeur
        if isinstance(response, dict) and 'error' in response:
            print(f"  ‚ùå Erreur : {response.get('error', 'Erreur inconnue')}")
            raise Exception(f"Erreur lors de l'appel √† l'agent : {response['error']}")
        
        # Afficher la structure compl√®te
        if 'tool_calls' in response:
            print(f"  üîß Outil appel√© : {response['tool_calls'][0].function.name}")
            
            # Parser les arguments JSON
            arguments = json.loads(response['tool_calls'][0].function.arguments)
            
            print(f"\n  üìä Structured Output (JSON) :")
            print(f"     {json.dumps(arguments, indent=6, ensure_ascii=False)}")
            
            # Simulation de audit_agent_loggeur : extraction de user_message
            # Dans audit_agent_loggeur, on fait : logger_message = logger_message['user_message']
            # Mais avec Groq, la structure est diff√©rente, il faut extraire depuis tool_results
            
            print(f"\n  üìä Simulation audit_agent_loggeur :")
            print(f"     1Ô∏è‚É£  Le mod√®le a appel√© send_message_tool")
            print(f"     2Ô∏è‚É£  Arguments structur√©s : {json.dumps(arguments, ensure_ascii=False)}")
            
            # V√©rifier si tool_results contient les donn√©es structur√©es
            if 'tool_results' in response and len(response['tool_results']) > 0:
                # Extraire le contenu du tool_result
                tool_result_content = response['tool_results'][0]['content']
                print(f"     3Ô∏è‚É£  tool_results[0]['content'] : {tool_result_content}")
                
                # Si c'est une string JSON, la parser
                if isinstance(tool_result_content, str):
                    try:
                        parsed_content = json.loads(tool_result_content)
                        print(f"     4Ô∏è‚É£  Contenu pars√© : {json.dumps(parsed_content, ensure_ascii=False)}")
                        
                        # Extraire user_message comme dans audit_agent_loggeur
                        if 'user_message' in parsed_content:
                            user_message = parsed_content['user_message']
                            print(f"\n  üí¨ Message final extrait (user_message) :")
                            print(f"     \"{user_message}\"")
                            
                            print(f"\n  ‚úÖ SUCCESS : Structured output fonctionnel !")
                            print(f"  üí° Note : Pour extraire user_message, il faut :")
                            print(f"     ‚Üí Parser tool_results[0]['content']")
                            print(f"     ‚Üí Extraire la cl√© 'user_message'")
                        else:
                            print(f"  ‚ùå ERREUR : 'user_message' absent de parsed_content")
                    except json.JSONDecodeError as e:
                        print(f"     ‚ùå Erreur de parsing JSON : {e}")
                        print(f"     Contenu brut : {tool_result_content}")
            else:
                print(f"     ‚ö†Ô∏è  tool_results non disponible ou vide")
        else:
            print(f"  ‚ö†Ô∏è  Aucun tool_call d√©tect√© (comportement inattendu)")
        
        print("\nüí° Analyse : L'outil force le mod√®le √† r√©pondre dans un format JSON pr√©cis")
        print("   C'est utile pour garantir une structure de donn√©es coh√©rente et parsable")
        
    except Exception as e:
        print(f"\n‚ùå Erreur : {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "-"*80)

# ============================================================================
# EX√âCUTION DES TESTS
# ============================================================================

def run_all_tests():
    """Ex√©cute tous les tests dans l'ordre"""
    print("\n" + "="*80)
    print("üß™ TESTS DES MODES D'UTILISATION DES OUTILS AVEC GROQ")
    print("="*80)
    print("Mod√®le utilis√© : moonshotai/kimi-k2-instruct-0905 (Kimi K2)")
    print("Outils disponibles : calculate_sum, get_weather")
    print("="*80)
    
    # Test 1 : Auto
    test_1_mode_auto()
    
    # Test 2 : Required
    test_2_mode_required()
    
    # Test 3 : None
    test_3_mode_none()
    
    # Test 4 : Forced Tool (bonus)
    test_4_mode_forced_tool()
    
    # Test 5 : Structured Output (bonus)
    test_5_structured_output()
    
    # R√©sum√© final
    print("\n" + "="*80)
    print("üìä R√âSUM√â DES MODES")
    print("="*80)
    
    summary = [
        {
            "Mode": "AUTO",
            "Configuration": '{"type": "auto"}',
            "Comportement": "Le mod√®le d√©cide s'il utilise un outil",
            "Format Groq": '"auto"'
        },
        {
            "Mode": "REQUIRED",
            "Configuration": '{"type": "any"}',
            "Comportement": "Le mod√®le DOIT utiliser un outil (n'importe lequel)",
            "Format Groq": '"required"'
        },
        {
            "Mode": "NONE",
            "Configuration": '{"type": "none"}',
            "Comportement": "Le mod√®le NE DOIT PAS utiliser d'outils",
            "Format Groq": '"none"'
        },
        {
            "Mode": "FORCED",
            "Configuration": '{"type": "tool", "name": "X"}',
            "Comportement": "Le mod√®le DOIT utiliser l'outil X sp√©cifiquement",
            "Format Groq": '{"type": "function", "function": {"name": "X"}}'
        },
        {
            "Mode": "STRUCTURED OUTPUT",
            "Configuration": '{"type": "tool", "name": "schema_tool"}',
            "Comportement": "Force une r√©ponse dans un format JSON structur√© (pas d'ex√©cution)",
            "Format Groq": '{"type": "function", "function": {"name": "schema_tool"}}'
        }
    ]
    
    for item in summary:
        print(f"\nüîπ {item['Mode']}")
        print(f"   üì• Configuration    : {item['Configuration']}")
        print(f"   üì§ Format Groq     : {item['Format Groq']}")
        print(f"   ‚ÑπÔ∏è  Comportement    : {item['Comportement']}")
    
    print("\n" + "="*80)
    print("‚úÖ TOUS LES TESTS TERMIN√âS")
    print("="*80)

if __name__ == "__main__":
    run_all_tests()

