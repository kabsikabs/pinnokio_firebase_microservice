"""
Test de l'int√©gration OpenAI Agent via BaseAIAgent
Ce fichier teste l'utilisation d'OpenAI via BaseAIAgent (wrapper utilis√© dans l'application)
"""

import json
import asyncio
from app.llm.klk_agents import (
    NEW_OpenAiAgent, 
    BaseAIAgent, 
    ModelProvider, 
    ModelSize
)

# ============================================================================
# CONFIGURATION GLOBALE
# ============================================================================

def setup_base_agent():
    """
    Configure un BaseAIAgent avec OpenAI (comme dans l'application r√©elle)
    """
    base_agent = BaseAIAgent()
    openai_instance = NEW_OpenAiAgent()
    
    # Enregistrer le provider OpenAI
    base_agent.register_provider(
        provider=ModelProvider.OPENAI,
        instance=openai_instance,
        default_model_size=ModelSize.MEDIUM
    )
    
    # Configurer comme provider par d√©faut
    base_agent.default_provider = ModelProvider.OPENAI
    base_agent.default_model_size = ModelSize.MEDIUM
    
    return base_agent, openai_instance


# ============================================================================
# FONCTIONS DUMMY POUR LES TESTS D'OUTILS
# ============================================================================

def get_weather(location: str, unit: str = "celsius") -> dict:
    """
    Fonction dummy pour tester l'appel d'outils.
    
    Args:
        location: Ville pour laquelle obtenir la m√©t√©o
        unit: Unit√© de temp√©rature (celsius ou fahrenheit)
    
    Returns:
        dict: Informations m√©t√©o simul√©es
    """
    print(f"\nüå§Ô∏è  Appel de get_weather pour {location} en {unit}")
    
    # Simulation de donn√©es m√©t√©o
    weather_data = {
        "location": location,
        "temperature": 22 if unit == "celsius" else 72,
        "unit": unit,
        "condition": "Ensoleill√©",
        "humidity": 65,
        "wind_speed": 15
    }
    
    return weather_data


def calculate_sum(a: float, b: float) -> dict:
    """
    Fonction dummy pour calculer une somme.
    
    Args:
        a: Premier nombre
        b: Deuxi√®me nombre
    
    Returns:
        dict: R√©sultat du calcul
    """
    print(f"\nüßÆ Calcul de {a} + {b}")
    return {
        "operation": "addition",
        "a": a,
        "b": b,
        "result": a + b
    }


# ============================================================================
# D√âFINITION DES OUTILS (FORMAT ANTHROPIC - attendu par BaseAIAgent)
# ============================================================================

TOOLS = [
    {
        "name": "get_weather",
        "description": "Obtenir les informations m√©t√©o actuelles pour une ville donn√©e",
        "input_schema": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "La ville et le pays, ex: Paris, France"
                },
                "unit": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "L'unit√© de temp√©rature"
                }
            },
            "required": ["location"]
        }
    },
    {
        "name": "calculate_sum",
        "description": "Calculer la somme de deux nombres",
        "input_schema": {
            "type": "object",
            "properties": {
                "a": {
                    "type": "number",
                    "description": "Premier nombre"
                },
                "b": {
                    "type": "number",
                    "description": "Deuxi√®me nombre"
                }
            },
            "required": ["a", "b"]
        }
    }
]

# Mapping des outils vers les fonctions
# ‚≠ê IMPORTANT: BaseAIAgent attend une LISTE de dicts (pas un dict simple)
TOOL_MAPPING = [
    {
        "get_weather": get_weather,
        "calculate_sum": calculate_sum
    }
]


# ============================================================================
# TESTS
# ============================================================================

def test_1_generation_texte_simple():
    """
    Test 1: G√©n√©ration de texte simple via BaseAIAgent.process_text()
    Utilise GPT-4o-mini
    """
    print("\n" + "="*80)
    print("TEST 1: G√âN√âRATION DE TEXTE VIA BaseAIAgent (GPT-4o-mini)")
    print("="*80)
    
    try:
        # Setup comme dans l'application r√©elle
        base_agent, openai_instance = setup_base_agent()
        
        # Test avec g√©n√©ration simple
        prompt = "Explique en 2 phrases ce qu'est l'intelligence artificielle."
        print(f"\nüìù Prompt: {prompt}")
        print(f"üß† Provider: {base_agent.default_provider.value}")
        print(f"üß† Size: {base_agent.default_model_size.value}")
        
        response = base_agent.process_text(
            content=prompt,
            provider=ModelProvider.OPENAI,
            size=ModelSize.MEDIUM,
            max_tokens=200
        )
        
        # process_text() peut retourner une string ou un dict
        if isinstance(response, str):
            print(f"\n‚úÖ R√©ponse: {response}")
        else:
            print(f"\n‚úÖ R√©ponse: {response.get('text_output', response)}")
        
        print(f"\nüìä Utilisation des tokens:")
        print(json.dumps(openai_instance.get_total_tokens(), indent=2))
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_2_streaming_simple():
    """
    Test 2: Streaming de texte via BaseAIAgent.process_text_streaming()
    """
    print("\n" + "="*80)
    print("TEST 2: STREAMING DE TEXTE VIA BaseAIAgent")
    print("="*80)
    
    try:
        base_agent, openai_instance = setup_base_agent()
        
        prompt = "Raconte une tr√®s courte histoire sur un robot en 3 phrases."
        print(f"\nüìù Prompt: {prompt}")
        print(f"üß† Provider: OpenAI - Size: MEDIUM")
        print("\nüîÑ Streaming en cours...\n")
        
        full_text = ""
        async for chunk in base_agent.process_text_streaming(
            content=prompt,
            provider=ModelProvider.OPENAI,
            size=ModelSize.MEDIUM,
            max_tokens=200
        ):
            # OpenAI retourne {"content": str, "is_final": bool, "model": str}
            if isinstance(chunk, dict):
                content = chunk.get("content", "")
                if content:  # Afficher seulement si non-vide
                    print(content, end='', flush=True)
                    full_text += content
            elif isinstance(chunk, str):
                print(chunk, end='', flush=True)
                full_text += chunk
        
        print(f"\n\n‚úÖ Streaming termin√©. Texte complet re√ßu: {len(full_text)} caract√®res")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_3_streaming_tools():
    """
    Test 3: Streaming avec outils via BaseAIAgent.process_text_tool_streaming()
    ‚≠ê M√âTHODE CL√â UTILIS√âE DANS L'APPLICATION
    """
    print("\n" + "="*80)
    print("TEST 3: STREAMING AVEC OUTILS VIA BaseAIAgent")
    print("‚≠ê M√©thode utilis√©e dans pinnokio_brain.py")
    print("="*80)
    
    try:
        base_agent, openai_instance = setup_base_agent()
        
        prompt = "Quelle est la m√©t√©o √† Paris en celsius?"
        print(f"\nüìù Prompt: {prompt}")
        print(f"üß† Provider: OpenAI - Size: MEDIUM")
        print("\nüîÑ Streaming en cours...\n")
        
        accumulated_text = ""
        tool_calls_detected = []
        tool_results_detected = []
        
        # ‚≠ê M√âTHODE UTILIS√âE DANS L'APPLICATION R√âELLE
        async for event in base_agent.process_text_tool_streaming(
            content=prompt,
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            provider=ModelProvider.OPENAI,
            size=ModelSize.MEDIUM,
            max_tokens=500
        ):
            event_type = event.get("type")
            
            if event_type == "text":
                text = event.get("content", "")
                print(text, end='', flush=True)
                accumulated_text += text
            
            elif event_type == "tool_use":
                tool_name = event.get("tool_name")
                tool_input = event.get("tool_input")
                tool_calls_detected.append({
                    "name": tool_name,
                    "input": tool_input
                })
                print(f"\n\nüîß Outil appel√©: {tool_name}")
                print(f"   Arguments: {json.dumps(tool_input, indent=2)}")
            
            elif event_type == "tool_result":
                tool_name = event.get("tool_name")
                result = event.get("tool_output")
                tool_results_detected.append({
                    "name": tool_name,
                    "result": result
                })
                print(f"\n‚úÖ R√©sultat de {tool_name}:")
                print(f"   {json.dumps(result, indent=2)}")
            
            elif event_type == "final":
                print(f"\n\nüìã √âv√©nement final re√ßu")
        
        print(f"\n\n‚úÖ Streaming termin√©")
        print(f"   - Texte g√©n√©r√©: {len(accumulated_text)} caract√®res")
        print(f"   - Outils appel√©s: {len(tool_calls_detected)}")
        print(f"   - R√©sultats re√ßus: {len(tool_results_detected)}")
        
        print(f"\nüìä Utilisation des tokens:")
        print(json.dumps(openai_instance.get_total_tokens(), indent=2))
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_4_process_tool_use():
    """
    Test 4: process_tool_use (non-streaming) via BaseAIAgent
    """
    print("\n" + "="*80)
    print("TEST 4: process_tool_use (non-streaming)")
    print("="*80)
    
    try:
        base_agent, openai_instance = setup_base_agent()
        
        # Test utilisation d'outils sans streaming
        print("\nüîß Test utilisation d'outils via BaseAIAgent (non-streaming):")
        response_tool = base_agent.process_tool_use(
            content="Calcule la somme de 42 et 58",
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            provider=ModelProvider.OPENAI,
            size=ModelSize.MEDIUM,
            max_tokens=500
        )
        
        print(f"\nR√©ponse outil:")
        if 'tool_calls' in response_tool:
            print(f"  - Outils appel√©s: {len(response_tool['tool_calls'])}")
            if 'tool_results' in response_tool:
                for result in response_tool['tool_results']:
                    print(f"  - R√©sultat de {result['name']}: {result['content']}")
        
        if 'text_output' in response_tool:
            print(f"  - Texte: {response_tool['text_output']}")
        
        print(f"\nüìä Utilisation totale des tokens:")
        print(json.dumps(openai_instance.get_total_tokens(), indent=2))
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_5_multiple_tools_same_request():
    """
    Test 5: Appels multiples d'outils via BaseAIAgent
    """
    print("\n" + "="*80)
    print("TEST 5: APPELS MULTIPLES D'OUTILS")
    print("="*80)
    
    try:
        base_agent, openai_instance = setup_base_agent()
        
        prompt = "Quelle est la temp√©rature √† Lyon et calcule 15 + 27?"
        print(f"\nüìù Prompt: {prompt}")
        print(f"üß† Provider: OpenAI - Size: MEDIUM")
        print("\nüîÑ Streaming en cours...\n")
        
        accumulated_text = ""
        tools_executed = []
        
        async for event in base_agent.process_text_tool_streaming(
            content=prompt,
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            provider=ModelProvider.OPENAI,
            size=ModelSize.MEDIUM,
            max_tokens=1000
        ):
            event_type = event.get("type")
            
            if event_type == "text":
                text = event.get("content", "")
                print(text, end='', flush=True)
                accumulated_text += text
            
            elif event_type == "tool_use":
                tool_name = event.get("tool_name")
                tools_executed.append(tool_name)
                print(f"\n\nüîß Outil #{len(tools_executed)}: {tool_name}")
            
            elif event_type == "tool_result":
                tool_name = event.get("tool_name")
                result = event.get("tool_output")
                print(f"‚úÖ R√©sultat {tool_name}: {result}")
        
        print(f"\n\n‚úÖ Streaming termin√©")
        print(f"   - Outils ex√©cut√©s: {len(tools_executed)}")
        print(f"   - Texte: {len(accumulated_text)} caract√®res")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_6_message_cleaning():
    """
    Test 6: V√©rifier que le nettoyage des messages fonctionne
    ‚≠ê TESTE LE FIX PRINCIPAL (nettoyage format Anthropic)
    """
    print("\n" + "="*80)
    print("TEST 6: NETTOYAGE DES MESSAGES (FIX PRINCIPAL)")
    print("‚≠ê Teste que les messages Anthropic sont bien nettoy√©s")
    print("="*80)
    
    try:
        base_agent, openai_instance = setup_base_agent()
        
        # Simuler un historique avec format Anthropic
        print("\nüß™ Ajout de messages au format Anthropic dans l'historique...")
        openai_instance.chat_history.append({
            "role": "user",
            "content": "Test message"
        })
        openai_instance.chat_history.append({
            "role": "assistant",
            "content": [
                {"type": "text", "text": "Voici ma r√©ponse"},
                {"type": "tool_use", "id": "tool_123", "name": "test_tool", "input": {}}
            ]
        })
        
        print(f"‚úÖ Historique simul√© avec {len(openai_instance.chat_history)} messages")
        print(f"   - Message 2 a un format Anthropic (liste avec type)")
        
        # Maintenant faire un appel - le nettoyage devrait emp√™cher l'erreur 400
        prompt = "Continue la conversation"
        print(f"\nüìù Prompt: {prompt}")
        print("üîÑ Test avec nettoyage des messages...\n")
        
        response_received = False
        async for event in base_agent.process_text_tool_streaming(
            content=prompt,
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            provider=ModelProvider.OPENAI,
            size=ModelSize.MEDIUM,
            max_tokens=300
        ):
            event_type = event.get("type")
            
            if event_type == "text":
                response_received = True
                text = event.get("content", "")
                print(text, end='', flush=True)
        
        print(f"\n\n‚úÖ Test termin√©")
        if response_received:
            print("‚úÖ SUCC√àS: Aucune erreur 400 - Le nettoyage fonctionne!")
        else:
            print("‚ö†Ô∏è  Pas de texte re√ßu, mais pas d'erreur 400")
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        if "400" in error_msg and "type" in error_msg.lower():
            print(f"\n‚ùå √âCHEC: Erreur 400 d√©tect√©e - Le nettoyage ne fonctionne pas")
            print(f"   Erreur: {error_msg}")
            return False
        else:
            print(f"\n‚ö†Ô∏è  Autre erreur: {e}")
            import traceback
            traceback.print_exc()
            return False


async def test_7_vision_pdf():
    """
    Test 7: Analyse d'image/PDF avec BaseAIAgent.process_vision()
    Utilise GPT-4o (Vision) via OpenAI
    """
    print("\n" + "="*80)
    print("TEST 7: ANALYSE D'IMAGE/PDF avec process_vision()")
    print("="*80)
    
    try:
        import os
        
        pdf_path = "compte_attente_fim.pdf"
        
        # V√©rifier si le fichier existe
        if not os.path.exists(pdf_path):
            print(f"\n‚ö†Ô∏è  Fichier {pdf_path} introuvable. Test ignor√©.")
            return True
        
        print(f"\nüìÑ Fichier: {pdf_path}")
        print(f"üìè Taille: {os.path.getsize(pdf_path) / 1024:.2f} KB")
        
        # Initialiser BaseAIAgent
        print("\nüîÑ Initialisation de BaseAIAgent avec OpenAI...")
        base_agent, openai_instance = setup_base_agent()
        
        # Test avec process_vision
        print("\nüñºÔ∏è  Analyse du PDF avec GPT-4o (Vision)...")
        prompt = "D√©cris le contenu de ce document. Quelles sont les principales informations visibles?"
        print(f"ü§ñ Mod√®le: GPT-4o (MEDIUM - vision)")
        
        try:
            response = base_agent.process_vision(
                text=prompt,
                provider=ModelProvider.OPENAI,
                size=ModelSize.MEDIUM,  # GPT-4o pour vision
                local_files=[pdf_path],
                method='batch',
                max_tokens=1000,
                final_resume=True
            )
            
            print(f"\n‚úÖ R√©ponse du mod√®le vision:")
            if isinstance(response, str):
                print(response[:500] + "..." if len(response) > 500 else response)
            elif isinstance(response, dict):
                if 'text_output' in response:
                    print(response['text_output'][:500] + "...")
                else:
                    print(json.dumps({k: v for k, v in response.items() if k != 'raw_response'}, 
                                   indent=2, ensure_ascii=False)[:500])
            else:
                print(response)
            
            print(f"\nüìä Utilisation des tokens:")
            print(json.dumps(openai_instance.get_total_tokens(), indent=2))
            
            return True
            
        except ImportError as import_err:
            if "pdf2image" in str(import_err):
                print(f"\n‚ö†Ô∏è  Module manquant: {import_err}")
                print("üí° Pour installer: pip install pdf2image")
                print("   (N√©cessite aussi poppler: https://github.com/oschwartz10612/poppler-windows/releases/)")
                print("\n‚úÖ Test ignor√© (d√©pendance manquante)")
                return True
            else:
                raise
        
        except Exception as vision_error:
            print(f"\n‚ùå Erreur lors de l'analyse vision: {vision_error}")
            import traceback
            traceback.print_exc()
            return False
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_8_default_provider():
    """
    Test 8: V√©rifier que le provider par d√©faut est bien utilis√©
    ‚≠ê SIMULE L'UTILISATION DANS PINNOKIO_BRAIN
    """
    print("\n" + "="*80)
    print("TEST 8: PROVIDER PAR D√âFAUT (comme pinnokio_brain)")
    print("‚≠ê Simule l'initialisation dans pinnokio_brain.py")
    print("="*80)
    
    try:
        # Simuler l'initialisation de pinnokio_brain
        print("\nüß† Simulation de l'initialisation dans pinnokio_brain...")
        base_agent, openai_instance = setup_base_agent()
        
        print(f"‚úÖ Provider par d√©faut: {base_agent.default_provider.value}")
        print(f"‚úÖ Size par d√©faut: {base_agent.default_model_size.value}")
        
        # Test sans sp√©cifier le provider (utilise le d√©faut)
        print("\nüìù Test sans sp√©cifier le provider (utilise d√©faut):")
        
        accumulated_text = ""
        async for event in base_agent.process_text_tool_streaming(
            content="Calcule 10 + 20",
            tools=TOOLS,
            tool_mapping=TOOL_MAPPING,
            # PAS de provider/size sp√©cifi√© - utilise les d√©fauts
            max_tokens=300
        ):
            if event.get("type") == "text":
                text = event.get("content", "")
                print(text, end='', flush=True)
                accumulated_text += text
            elif event.get("type") == "tool_use":
                print(f"\nüîß Outil: {event.get('tool_name')}")
            elif event.get("type") == "tool_result":
                print(f"\n‚úÖ R√©sultat: {event.get('tool_output')}")
        
        print(f"\n\n‚úÖ Test termin√© - Provider par d√©faut fonctionne!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# FONCTION PRINCIPALE
# ============================================================================

async def run_all_tests():
    """
    Ex√©cute tous les tests
    """
    print("\n" + "üöÄ"*40)
    print("TESTS OPENAI via BaseAIAgent (comme dans l'application)")
    print("üöÄ"*40)
    
    tests = [
        ("G√©n√©ration texte via BaseAIAgent", test_1_generation_texte_simple, False),
        ("Streaming texte via BaseAIAgent", test_2_streaming_simple, True),
        ("‚≠ê Streaming + outils (m√©thode cl√©)", test_3_streaming_tools, True),
        ("process_tool_use (non-streaming)", test_4_process_tool_use, True),
        ("Appels multiples d'outils", test_5_multiple_tools_same_request, True),
        ("‚≠ê Nettoyage messages (FIX principal)", test_6_message_cleaning, True),
        ("Analyse d'image/PDF avec process_vision (GPT-4o)", test_7_vision_pdf, True),
        ("‚≠ê Provider par d√©faut (pinnokio_brain)", test_8_default_provider, True),
    ]
    
    results = {}
    
    for test_name, test_func, is_async in tests:
        try:
            if is_async:
                result = await test_func()
            else:
                result = test_func()
            results[test_name] = "‚úÖ R√âUSSI" if result else "‚ùå √âCHOU√â"
        except Exception as e:
            results[test_name] = f"‚ùå ERREUR: {str(e)}"
    
    # R√©sum√©
    print("\n" + "="*80)
    print("R√âSUM√â DES TESTS")
    print("="*80)
    
    for test_name, result in results.items():
        print(f"{result} - {test_name}")
    
    # Statistiques
    success_count = sum(1 for r in results.values() if "‚úÖ" in r)
    total_count = len(results)
    
    print(f"\nüìä R√©sultat global: {success_count}/{total_count} tests r√©ussis")
    print("="*80 + "\n")


if __name__ == "__main__":
    # V√©rifier que la cl√© API est configur√©e
    try:
        from app.tools.g_cred import get_secret
        api_key = get_secret('openai_pinnokio')
        if not api_key:
            print("‚ùå ERREUR: La cl√© API OpenAI n'est pas configur√©e!")
            print("üí° Configurez 'openai_pinnokio' dans votre syst√®me de secrets")
            exit(1)
    except Exception as e:
        print(f"‚ùå ERREUR lors de la r√©cup√©ration de la cl√© API: {e}")
        exit(1)
    
    # Lancer tous les tests
    asyncio.run(run_all_tests())

